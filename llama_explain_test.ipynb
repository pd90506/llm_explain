{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "# Load the environment configuration JSON data\n",
    "json_path = 'env_config.json'\n",
    "with open(json_path, 'r') as file:\n",
    "    env_config = json.load(file)\n",
    "\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ['HF_HOME'] = env_config['HF_HOME']\n",
    "# Set the access token to huggingface hub\n",
    "access_token = env_config['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  9.20it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  \n",
      "What is shown in this image? [/INST] The image shows a medical consultation document from a hospital. It appears to be a record of a patient's visit, with various sections filled out by a healthcare professional. The document includes the patient's personal information, medical history, and notes from the consultation. The text is in Spanish, and the document includes a section for the patient's signature, which is typically used to confirm that the information provided is accurate. The document also includes a section for the healthcare provider's signature, which\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", torch_dtype=torch.float16, low_cpu_mem_usage=True) \n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "# prepare image and text prompt, using the appropriate prompt template\n",
    "# url = \"https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  \n",
      "Reformat this document[/INST] The image you've provided appears to be a medical consultation document from a hospital in Mexico. The document is written in Spanish and includes various sections with handwritten notes. Here's a translation of the visible text:\n",
      "\n",
      "```\n",
      "HOSPITAL INFANTIL DE MÉXICO\n",
      "FEDERICO GÓMEZ\n",
      "\n",
      "CONSULTA EXTERIORA\n",
      "REG. NUM. 849138\n",
      "\n",
      "PACIENTE:\n",
      "Nombre:\n",
      "Edad: 5 años\n",
      "Sexo: Femenino\n",
      "\n",
      "HISTORIA CLÍNICA:\n",
      "\n",
      "- Peso: 11,5 kg\n",
      "- Talla: 134 cm\n",
      "- FC: 62\n",
      "- T°: 35,6°\n",
      "\n",
      "OBSERVACIONES:\n",
      "\n",
      "- En la cabeza se observa una lesión en la frente derecha.\n",
      "- En la mano derecha se observa una lesión en la palma.\n",
      "- En la mano izquierda se observa una lesión en la palma.\n",
      "- En la pierna derecha se observa una lesión en la pantorrilla.\n",
      "- En la pierna izquierda se observa una lesión en la pantorrilla.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espalda.\n",
      "- En la espalda se observa una lesión en la espal\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"handwritten_prescription.jpg\")\n",
    "prompt = \"[INST] <image>\\nReformat this document[/INST]\"\n",
    "\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\n",
    "# autoregressively complete prompt\n",
    "output = model.generate(**inputs, max_new_tokens=512)\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to prompt Llama 3\n",
    "The base models have no prompt format. Like other base models, they can be used to continue an input sequence with a plausible continuation or for zero-shot/few-shot inference. They are also a great foundation for fine-tuning your own use cases. The Instruct versions use the following conversation structure:\n",
    "```bash\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{{ system_prompt }}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{{ user_msg_1 }}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{{ model_answer_1 }}<|eot_id|>\n",
    "\n",
    "```\n",
    "\n",
    "This format has to be exactly reproduced for effective use. We’ll later show how easy it is to reproduce the instruct prompt with the chat template available in transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/crc/c/conda/23.5.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "print(transformers.__version__)\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = r\"\"\"\n",
    "This document appears to be a medical record from a hospital visit at \"Hospital Infantil de México Federico Gómez.\" It includes patient details and notes from an oncology consultation. Here’s a detailed explanation:\n",
    "Header Information\n",
    "Hospital Name: Hospital Infantil de México Federico Gómez\n",
    "Department: Oncología (Oncology)\n",
    "Consultation Type: Consulta Externa (Outpatient Consultation)\n",
    "Date: 15 Aug 2021\n",
    "Record Number: 847388\n",
    "Patient Information\n",
    "Age: 18 years\n",
    "Weight: 110.5 kg\n",
    "Height: 174 cm\n",
    "Heart Rate (FC): 66 bpm\n",
    "Respiratory Rate (FR): (not clearly mentioned)\n",
    "Blood Pressure (TA): 119/84 mmHg\n",
    "Temperature: 35.6°C\n",
    "Clinical Notes\n",
    "The patient is known for their age.\n",
    "Currently in maintenance (sem S6, likely week 6 of a treatment regimen).\n",
    "Attended an asymptomatic review.\n",
    "Physical examination showed no signs of active neoplastic (cancerous) or infectious diseases.\n",
    "The proposed treatment includes maintaining the current plan and additional measures (likely related to a catheter, port, and chemotherapy drugs).\n",
    "Treatment Plan\n",
    "Current Medications and Dosages:\n",
    "Methotrexate (MTX): 90 mg IM weekly\n",
    "Purineethol (Mercaptopurine): 150 mg/m² daily\n",
    "Methotrexate (MTX): 90 mg IM weekly\n",
    "Ara-C (Cytarabine): 1000 mg intrathecally\n",
    "VCR (Vincristine): 2 mg IV\n",
    "L-asparaginase (L-ASP): 173,000 UI IM daily\n",
    "Dexamethasone (DEXA): 1.8 mg/m²/day for 6 days weekly\n",
    "Ondansetron: 8 mg for nausea prophylaxis\n",
    "TMP/SMX (Trimethoprim/Sulfamethoxazole): Prophylactic dose\n",
    "Additional Notes\n",
    "The next important date for the patient (likely a significant treatment or appointment) is scheduled for August 9.\n",
    "Other unspecified medical or supportive measures.\n",
    "Prescribing Doctors\n",
    "Signatures or names of doctors involved in the treatment (Dr. Rafael Ballon).\n",
    "Instructions\n",
    "Use a new sheet for further progress notes.\n",
    "Number the evolution sheets for easier review.\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": prompt2},\n",
    "    {\"role\": \"user\", \"content\": \"What is the phase of the current treatment?\"},\n",
    "]\n",
    "\n",
    "chat_template = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "input_dict = tokenizer.encode_plus(chat_template)\n",
    "\n",
    "input_ids = torch.tensor(input_dict[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "attention_mask = torch.tensor(input_dict[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "# input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# ).to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "([[611, 137], [1817, 137], [1817, 257], [611, 257]], 'HOSPITAL INFANTIL DE MEXICO', 0.6590712628819553) ([[853, 252], [1578, 252], [1578, 353], [853, 353]], 'FEDERICO GOMEZ', 0.8388057948285695) ([[1034, 380], [1206, 380], [1206, 411], [1034, 411]], '[rmkab', 0.0216942246446568) ([[188, 413], [631, 413], [631, 461], [188, 461]], 'COHSULTA EXTERnA', 0.3550443526218151) ([[1231, 391], [2058, 391], [2058, 483], [1231, 483]], 'Consultdpe EVOLUCION NUM ', 0.5406709292370818) ([[51, 511], [265, 511], [265, 555], [51, 555]], 'NOMOKE1', 0.03334764095554496) ([[1066, 516], [1192, 516], [1192, 555], [1066, 555]], 'SUY,', 0.1393755401012198) ([[1220, 470], [1680, 470], [1680, 574], [1220, 574]], 'Oncología', 0.9659505273910377) ([[1902, 493], [2119, 493], [2119, 547], [1902, 547]], 'REC, NuM.', 0.24361094081855053) ([[2102, 440], [2435, 440], [2435, 550], [2102, 550]], '841138', 0.9136440389702557) ([[135, 608], [793, 608], [793, 656], [135, 656]], 'S0Lloy, Oadenes Y TRATAMIENTO', 0.06737827252621427) ([[1362, 599], [1985, 599], [1985, 653], [1362, 653]], 'Nota $ DE Evolucion', 0.2920903125531863) ([[1021, 624], [1274, 624], [1274, 687], [1021, 687]], '15 Af1 2021', 0.05498115673934557) ([[259, 765], [506, 765], [506, 851], [259, 851]], 'Edad 12a', 0.28401981478708893) ([[535, 755], [674, 755], [674, 846], [535, 846]],'sL2', 0.2998494733703957) ([[1125, 800], [1230, 800], [1230, 848], [1125, 848]], '1', 0.30973088070357235) ([[1220, 748], [1952, 748], [1952, 860], [1220, 860]], '1poñ05(mocido', 0.1371826733840023) ([[1993, 761], [2159, 761], [2159, 859], [1993, 859]], '+wx', 0.15890253071213048) ([[365, 855], [600, 855], [600, 930], [365, 930]], 'LLQ 5', 0.6776650118845482) ([[930, 838], [1058, 838], [1058, 917], [930, 917]], 'Lla', 0.37005784869831493) ([[1089, 851], [1209, 851], [1209, 919], [1089, 919]], 'a2', 0.35554741109051696) ([[1288, 860], [1405, 860], [1405, 940], [1288, 940]], '20i', 0.1721872188601765) ([[1433, 865], [1639, 865], [1639, 942], [1433, 942]], 'edad', 0.9536293148994446) ([[253, 912], [526, 912], [526, 1015], [253, 1015]], '\"na1Y', 0.036340066238829474) ([[940, 928], [1060, 928], [1060, 1002], [940, 1002]], 'En', 0.9455766528531195) ([[1188, 918], [1822, 918], [1822, 1034], [1188, 1034]],'mantnimient', 0.6374378697294227) ([[1925, 938], [2104, 938], [2104, 1007], [1925, 1007]], 'Sm', 0.8225436300621535) ([[2127, 918], [2234, 918], [2234, 995], [2127, 995]], '56', 0.9647164647857324) ([[256, 1008], [479, 1008], [479, 1084], [256, 1084]], 'FC_ Lc', 0.11196613736561771) ([[944, 1009], [1193, 1009], [1193, 1093], [944, 1093]], 'Oudc', 0.3089796808354948) ([[1225, 1015], [1595, 1015], [1595, 1101], [1225, 1101]], '@IcvSIY', 0.3142997721409729) ([[1694, 992], [2243, 992], [2243, 1076], [1694, 1076]], 'asinlomance', 0.5818503590997596) ([[255, 1087], [331, 1087], [331, 1140], [255, 1140]], 'FR', 0.3709393172174497) ([[974, 1101], [1044, 1101], [1044, 1166], [974, 1166]], '0', 0.9878061700155492) ([[1369, 1114], [1509, 1114], [1509, 1174], [1369, 1174]], 'Sin', 0.4368106341586047) ([[1547, 1089], [1804, 1089], [1804, 1177], [1547, 1177]], 'datos', 0.948171600662618) ([[1837, 1093], [1942, 1093], [1942, 1172], [1837, 1172]], 'de', 0.26256875501720117) ([[1975, 1074], [2404, 1074], [2404, 1172], [1975, 1172]], 'øcg9', 0.05178799852728844) ([[252, 1152], [486, 1152], [486, 1236], [252, 1236]], 'TID', 0.3386594665891722) ([[986, 1171], [2074, 1171], [2074, 1284], [986, 1284]], 'neqplisìccninteccosa', 0.2225744654554641) ([[245, 1232], [344, 1232], [344, 1293], [245, 1293]], 'SC', 0.3619868602615647) ([[991, 1255], [1360, 1255], [1360, 1368], [991, 1368]], 'cpauent', 0.2884338297997176) ([[398, 1352], [448, 1352], [448, 1418], [398, 1418]], 'p', 0.6024982784524333) ([[517, 1336], [694, 1336], [694, 1401], [517, 1401]], '35.6', 0.4435056746006012) ([[1212, 1348], [1534, 1348], [1534, 1452], [1212, 1452]], 'piopane', 0.5476282134665228) ([[1598, 1331], [1865, 1331], [1865, 1421], [1598, 1421]], 'cCEI', 0.04718267545104027) ([[2226, 1349], [2410, 1349], [2410, 1441], [2226, 1441]], '4', 0.9890821401855057) ([[1010, 1420], [1252, 1420], [1252, 1500], [1010, 1500]], 'Lehuss', 0.34314827356548855) ([[69, 1511], [244, 1511], [244, 1571], [69, 1571]], '~e', 0.3551992032541642) ([[314, 1504], [404, 1504], [404, 1566], [314, 1566]], '53', 0.8018631915969404) ([[440, 1502], [536, 1502], [536, 1563], [440, 1563]], '60', 0.9906864155272103) ([[1052, 1492], [1226, 1492], [1226, 1576], [1052, 1576]], 'Plcu', 0.25301069021224976) ([[1372, 1488], [1702, 1488], [1702, 1588], [1372, 1588]], '(mhog', 0.2921067896831475) ([[1739, 1499], [2311, 1499], [2311, 1597], [1739, 1597]],'muknimlen', 0.3852707627449297) ([[80, 1588], [319, 1588], [319, 1662], [80, 1662]],'mIX', 0.272793512500242) ([[380, 1577], [536, 1577], [536, 1665], [380, 1665]], '90m', 0.26358455419540405) ([[590, 1567], [1001, 1567], [1001, 1655], [590, 1655]], 'Ixmand?', 0.4164876330744719) ([[1075, 1573], [1175, 1573], [1175, 1649], [1075, 1649]], '1v', 0.23128140000958866) ([[1276, 1593], [1649, 1593], [1649, 1661], [1276, 1661]],'snauas', 0.261650731429944) ([[1670, 1583], [1895, 1583], [1895, 1660], [1670, 1660]], '52-6', 0.12370090186595917) ([[190, 1651], [491, 1651], [491, 1735], [190, 1735]], 'lunetho', 0.5379239211762517) ([[556, 1657], [957, 1657], [957, 1744], [556, 1744]], '1SOmXZsy', 0.34068398122212395) ([[1399, 1652], [1688, 1652], [1688, 1744], [1399, 1744]], 'Poim', 0.8769908432860645) ([[1755, 1661], [1942, 1661], [1942, 1742], [1755, 1742]], '@DT', 0.6473917570209774) ([[1998, 1673], [2088, 1673], [2088, 1741], [1998, 1741]], 'cl', 0.6334239937883913) ([[189, 1751], [322, 1751], [322, 1813], [189, 1813]], 'MIX', 0.6229786634290231) ([[621, 1732], [832, 1732], [832, 1807], [621, 1807]],'m xA', 0.24384522438049316) ([[1284, 1746], [1371, 1746], [1371, 1808], [1284, 1808]], 'C', 0.15797758958975638) ([[1415, 1752], [1687, 1752], [1687, 1827], [1415, 1827]], 'acoslZ', 0.1487708441475716) ([[182, 1822], [362, 1822], [362, 1897], [182, 1897]], 'Gbc', 0.12359227422619229) ([[400, 1822], [566, 1822], [566, 1895], [400, 1895]], 'ACO)', 0.25275877118110657) ([[699, 1812], [1039, 1812], [1039, 1900], [699, 1900]], 'Judossgic', 0.08850386133746094) ([[1483, 1825], [1717, 1825], [1717, 1909], [1483, 1909]], 'cvclas', 0.05515120471569461) ([[1772, 1842], [1855, 1842], [1855, 1895], [1772, 1895]], 'c', 0.26456364524267784) ([[1877, 1827], [2257, 1827], [2257, 1907], [1877, 1907]], 'Glame', 0.28313825105501433) ([[198, 1896], [339, 1896], [339, 1977], [198, 1977]], 'Lr', 0.1023103772807911) ([[211, 1970], [395, 1970], [395, 2047], [211, 2047]], 'Lasp', 0.8038960099220276) ([[422, 1974], [654, 1974], [654, 2054], [422, 2054]], '132000', 0.19281597487416796) ([[677, 1972], [945, 1972], [945, 2045], [677, 2045]], \"UI' Du7\", 0.1592519541081671) ([[1018, 1975], [1358, 1975], [1358, 2062], [1018, 2062]], 'Da {E', 0.06375793634574554) ([[217, 2058], [374, 2058], [374, 2126], [217, 2126]], 'Dexg', 0.2772224545478821) ([[407, 2050], [826, 2050], [826, 2153], [407, 2153]], 'Lmnyøn', 0.027637995975309238) ([[1018, 2062], [1392, 2062], [1392, 2151], [1018, 2151]], 'Quauls', 0.5843692128654712) ([[1663, 2058], [1940, 2058], [1940, 2169], [1663, 2169]], 'Bauar', 0.6410199075820295) ([[358, 2139], [411, 2139], [411, 2195], [358, 2195]], 'X', 0.8329641650618669) ([[421, 2122], [750, 2122], [750, 2208], [421, 2208]], 'TYmana', 0.3259442441827077) ([[159, 2206], [665, 2206], [665, 2314], [159, 2314]], '@Hdaussvon', 0.11220033799144347) ([[360, 2285], [950, 2285], [950, 2419], [360, 2419]], 'Mprno clapod', 0.10948953448434538) ([[115, 2373], [466, 2373], [466, 2453], [115, 2453]], 'Imp/mx', 0.4109043062793637) ([[467, 2362], [866, 2362], [866, 2501], [467, 2501]], 'popkchco', 0.38581928590048997) ([[526, 2961], [1838, 2961], [1838, 3023], [526, 3023]], 'Uuncose una nueye hole de evolurlon haele haborus cerclorudo que le unlerior 8ata', 0.02416930454394009) ([[646, 3001], [1809, 3001], [1809, 3066], [646, 3066]], 'Mumoronao les holes 0o Dvolucion pars tochner |e rovlclon dol arpodionio', 0.015417777120689459) ([[266.101167723432, 854.0677069746514], [389.84476706781436, 876.644014040267], [376.898832276568, 931.9322930253486], [253.15523293218564, 908.355985959733]], 'Paso', 0.6455654501914978) ([[1228.3005628453516, 1098.1825890886175], [1340.5727049087313, 1090.4393476143496], [1341.6994371546484, 1159.8174109113825], [1229.4272950912687, 1167.5606523856504]], '6f', 0.3954468375035314) ([[1107.8853729282278, 1094.0893121550114], [1197.357804887122, 1108.0711235913259], [1185.1146270717722, 1169.9106878449886], [1095.642195112878, 1154.9288764086741]], 'La', 0.5765821820346624) ([[272.09672249564574, 1323.0511579616823], [411.7706346431434, 1355.098096416014], [392.90327750435426, 1426.9488420383177], [253.2293653568566, 1393.901903583986]], 'Tew', 0.10708464168973982) ([[1008.9950874933648, 1331.056278690947], [1202.782442687741, 1361.033098773058], [1187.0049125066353, 1437.943721309053], [993.217557312259, 1407.966901226942]], '4k', 0.21164730378668858) ([[1915.5083515587369, 1358.285911702569], [2194.1065068523376, 1331.657360336886], [2196.491648441263, 1422.714088297431], [1917.8934931476622, 1450.342639663114]], 'puitu', 0.3516363099701634) ([[355.9421394540648, 1730.0561108682089], [584.7618706018395, 1759.8306954218135], [569.0578605459352, 1843.9438891317911], [340.2381293981605, 1814.1693045781865]], '90m9', 0.25019383430480957) ([[580.9815420665362, 1824.074486052446], [689.6098397286374, 1843.6956522046953], [676.0184579334638, 1905.925513947554], [567.3901602713626, 1886.3043477953047]], 'na', 0.5491692530592707) ([[564.1470357815517, 1905.217550282517], [657.8843608412727, 1893.5801939619857], [662.8529642184483, 1962.782449717483], [570.1156391587273, 1974.4198060380143]], 'JU', 0.6062583546542698) ([[378.93608399193397, 1894.0631055322456], [557.6828743911395, 1918.6319433478711], [543.063916008066, 1995.9368944677544], [364.3171256088604, 1971.3680566521289]], '2m', 0.7195435216445037) ([[1818.9135710474898, 1977.0492815223874], [2090.726512610895, 2012.4526676725397], [2072.0864289525102, 2110.9507184776126], [1800.2734873891052, 2075.5473323274605]], '@ajao', 0.3959050378066369) ([[191.01471854987147, 2279.048657353702], [377.7810592898484, 2316.9189235553513], [356.9852814501285, 2399.951342646298], [170.21894071015166, 2361.0810764446487]], '8m', 0.5334824986614956) ([[1836.052175279236, 2982.1139186448677], [1931.9057131735499, 2995.136631824794], [1925.947824720764, 3030.8860813551323], [1829.0942868264501, 3017.863368175206]], 'Ilonn', 0.49713954599437027)<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "This is an OCR result, for example, in tuple([[611, 137], [1817, 137], [1817, 257], [611, 257]], 'HOSPITAL INFANTIL DE MEXICO', 0.6590712628819553), the first element denote the location, the second describe the text in this location, and the last is the confidence of the recongnition, convert it to an understandable document.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I can help you with that. It seems like you have a list of tuples, where each tuple contains three elements:\n",
      "\n",
      "1. A list of coordinates (x1, y1, x2, y2) representing the bounding box of a text region.\n",
      "2. The recognized text within that region.\n",
      "3. A confidence score indicating how confident the OCR engine is in its recognition.\n",
      "\n",
      "To convert this into a more understandable document, I'll assume that the coordinates are in the format (x1, y1, x2, y2) where (x1, y1) is the top-left corner and (x2, y2) is the bottom-right corner of the bounding box.\n",
      "\n",
      "Here's a Python script that can help you convert the data into a more readable format:\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Assuming the input data is a list of tuples\n",
      "data = [...your input data...]\n",
      "\n",
      "# Create an empty dictionary to store the converted data\n",
      "document = {}\n",
      "\n",
      "# Loop through each tuple in the input data\n",
      "for coords, text, confidence in data:\n",
      "    # Extract the bounding box coordinates\n",
      "    x1, y1, x2, y2 = coords\n",
      "    \n",
      "    # Extract the text and confidence score\n",
      "    text = text.strip()\n",
      "    confidence = float(confidence)\n",
      "    \n",
      "    # Create a dictionary to store the page information\n",
      "    page_info = {}\n",
      "    \n",
      "    # Add the text and confidence score to the page information\n",
      "    page_info['text'] = text\n",
      "    page_info['confidence'] = confidence\n",
      "    \n",
      "    # Add the page information to the document\n",
      "    if text not in document:\n",
      "        document[text] = []\n",
      "    document[text].append(page_info)\n",
      "\n",
      "# Print the converted document\n",
      "for text, pages in document.items():\n",
      "    print(f\"{text}:\")\n",
      "    for page in pages:\n",
      "        print(f\"  Page {page['confidence']:.2f}: {page['text']}\")\n",
      "    print()\n",
      "```\n",
      "This script will output a document with each text segment as a key, and a list of page information (text and confidence score) as values. The page information is sorted by confidence score, with the most confident page first.\n",
      "\n",
      "For example, the output for the first tuple in your input data would be:\n",
      "```\n",
      "HOSPITAL INFANTIL DE MEXICO:\n",
      "  Page 0.66: HOSPITAL INFANTIL DE MEXICO\n",
      "```\n",
      "Note that the confidence score is rounded to two decimal places. You can adjust the formatting as needed to suit your requirements.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "assistant_response = tokenizer.decode(outputs[0])\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling explanation for Llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from models import MLP\n",
    "\n",
    "class SimilarityMeasure(nn.Module):\n",
    "    def __init__(self, input_ids, attention_mask, embed_size=512):\n",
    "        super(SimilarityMeasure, self).__init__()\n",
    "\n",
    "        self.pred_map = MLP(pred_hidden_size, 128, embed_size, num_blocks=2, bottleneck_dim=64)\n",
    "        self.explain_map = MLP(explain_hidden_size, 128, embed_size, num_blocks=2, bottleneck_dim=64)\n",
    "\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(1.0))\n",
    "    \n",
    "    def forward(self, pred_feature, explain_features):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            q (torch.Tensor): Query tensor of shape [N, pred_hidden_size].\n",
    "            k (torch.Tensor): Key tensor of shape [N, L, explain_hidden_size].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Similarity tensor of shape [N, L].\n",
    "        \"\"\"\n",
    "        pred_feature = F.normalize(self.pred_map(pred_feature), p=2, dim=-1).unsqueeze(1)  # [N, 1, embed_size]\n",
    "        explain_features = F.normalize(self.explain_map(explain_features), p=2, dim=-1)  # [N, L, embed_size]\n",
    "\n",
    "\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "\n",
    "        similarity = torch.matmul(explain_features, pred_feature.transpose(-1, -2)).squeeze(-1) * logit_scale  # [N, L]\n",
    "\n",
    "        return similarity  # [N, L]\n",
    "\n",
    "\n",
    "class MaskGeneratingModel(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        \"\"\" \n",
    "        hidden_size: int\n",
    "            The hidden size of the output of the generative model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.similarity_measure = SimilarityMeasure()\n",
    "        self.explain_map = MLP(input_dim=hidden_size, \n",
    "                               hidden_dim=128, \n",
    "                               output_dim=1, \n",
    "                               num_blocks=2, \n",
    "                               bottleneck_dim=64) # takes [N, L, hidden_size] outputs [N, L, 1]\n",
    "        \n",
    "        self.similarity = MLP(input_dim=hidden_size, \n",
    "                               hidden_dim=128, \n",
    "                               output_dim=1, \n",
    "                               num_blocks=2, \n",
    "                               bottleneck_dim=64) # takes [N, hidden_size] outputs [N, 1]\n",
    "\n",
    "        self.bce_loss = nn.BCELoss(reduction='none')\n",
    "    \n",
    "    def forward(self, pred_features):\n",
    "        \"\"\" \n",
    "        pred_features: torch.Tensor of shape [N, L, hidden_size]\n",
    "        \"\"\"\n",
    "        mask_logits = self.explain_map(pred_features) # [N, L, 1]\n",
    "        return mask_logits \n",
    "    \n",
    "    def compute_similarity(self, masked_concat_features):\n",
    "        \"\"\" \n",
    "        masked_concat_features: torch.Tensor of shape [N, hidden_size]\n",
    "        \"\"\"\n",
    "        similarity_logit = self.similarity(masked_concat_features) # [N, 1]\n",
    "        return similarity_logit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [128000, 27, 11508, 29], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\"<mask>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['es','en']) # this needs to run only once to load the model into memory\n",
    "result = reader.readtext('handwritten_prescription.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ' '.join([str(result[i]) for i in range(len(result))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOSPITAL INFANTIL DE MEXICO FEDERICO GOMEZ [rmkab COHSULTA EXTERnA Consultdpe EVOLUCION NUM  NOMOKE1 SUY , Oncología REC, NuM. 841138 S0Lloy, Oadenes Y TRATAMIENTO Nota $ DE Evolucion 15 Af1 2021 Edad 12a sL2 1 1poñ05(mocido +wx LLQ 5 Lla a2 20i edad \"na1Y En mantnimient Sm 56 FC_ Lc Oudc @IcvSIY asinlomance FR 0 Sin datos de øcg9 TID neqplisìccninteccosa SC cpauent p 35.6 piopane cCEI 4 Lehuss ~e 53 60 Plcu (mhog muknimlen mIX 90m Ixmand? 1v snauas 52-6 lunetho 1SOmXZsy Poim @DT cl MIX m xA C acoslZ Gbc ACO) Judossgic cvclas c Glame Lr Lasp 132000 UI\\' Du7 Da {E Dexg Lmnyøn Quauls Bauar X TYmana @Hdaussvon Mprno clapod Imp/mx popkchco Uuncose una nueye hole de evolurlon haele haborus cerclorudo que le unlerior 8ata Mumoronao les holes 0o Dvolucion pars tochner |e rovlclon dol arpodionio Paso 6f La Tew 4k puitu 90m9 na JU 2m @ajao 8m Ilonn'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
