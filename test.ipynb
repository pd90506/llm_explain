{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llmexp.llm.smollm import LLMWrapper\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "checkpoint = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# checkpoint = \"HuggingFaceTB/SmolLM-1.7B-Instruct\"\n",
    "\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "\n",
    "llm = LLMWrapper(checkpoint, device=device)\n",
    "tokenizer = llm.tokenizer\n",
    "llm.hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.<|eot_id|><|start_header_id|>sentence<|end_header_id|>\n",
      "\n",
      "I hate this movie.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "negative<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# instruction = \"Analyze the sentiment of the following sentence. Be brief.\"\n",
    "instruction = \"Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.\"\n",
    "user_input = \"I hate this movie.\"\n",
    "\n",
    "content = [\n",
    "            {\"role\": \"system\", \n",
    "            \"content\": instruction\n",
    "            },\n",
    "\n",
    "            {\"role\": \"sentence\", \n",
    "            \"content\": user_input\n",
    "            }\n",
    "        ]\n",
    "template = tokenizer.apply_chat_template(content, tokenize=False, add_generation_prompt=True)\n",
    "# print(template)\n",
    "\n",
    "# The generated outputs \n",
    "gen_output = llm.generate_from_texts(template)\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        ...,\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llmexp.utils.data_utils import LLMDataset, create_dataloader\n",
    "dataloader = create_dataloader('sst2', tokenizer, instruction=instruction)\n",
    "# batch = collate_fun(dataset[:10])\n",
    "inputs = next(iter(dataloader)).to(device)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128009, 128009, 128009,  ...,    271,  36590, 128009],\n",
       "         [128009, 128009, 128009,  ...,    271,  31587, 128009],\n",
       "         [128009, 128009, 128009,  ...,    271,  31587, 128009],\n",
       "         ...,\n",
       "         [128009, 128009, 128009,  ...,    271,  31587, 128009],\n",
       "         [128009, 128009, 128009,  ...,    271,  31587, 128009],\n",
       "         [128009, 128009, 128009,  ...,    271,  31587, 128009]],\n",
       "        device='cuda:0'),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_outputs = llm.generate(inputs,  max_new_tokens=50)\n",
    "generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "a minor miracle<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "from llmexp.utils import decode_batch_outputs\n",
    "\n",
    "decoded_outputs = decode_batch_outputs(**generated_outputs, tokenizer=tokenizer)\n",
    "print(decoded_outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -6.0502,  -9.7437,  -8.4180,  ...,   9.6519,   9.6512,   9.6513],\n",
      "         [ -7.5367,  -9.8883,  -7.2537,  ...,   9.1260,   9.1252,   9.1252],\n",
      "         [ -7.0737,  -9.6388,  -6.2391,  ...,   9.5185,   9.5179,   9.5182],\n",
      "         ...,\n",
      "         [  7.4884,  16.6444,  12.5971,  ...,   3.8764,   3.8753,   3.8754],\n",
      "         [ 12.2231,  10.0633,   1.0912,  ...,   2.6447,   2.6436,   2.6442],\n",
      "         [ -1.7467,  -4.1949,  -4.9134,  ...,   8.8656,   8.8649,   8.8649]],\n",
      "\n",
      "        [[ -6.4945, -10.2150,  -8.4819,  ...,   9.8243,   9.8233,   9.8233],\n",
      "         [ -8.9331, -11.6798,  -8.0162,  ...,   9.9392,   9.9385,   9.9382],\n",
      "         [ -7.6666, -10.0353,  -6.7793,  ...,  10.0226,  10.0221,  10.0221],\n",
      "         ...,\n",
      "         [  8.1064,  15.2264,  13.7822,  ...,   5.4619,   5.4608,   5.4613],\n",
      "         [ 11.7456,  10.9452,   1.7162,  ...,   3.1175,   3.1164,   3.1170],\n",
      "         [ -2.6772,  -7.5897,  -5.3533,  ...,   9.3135,   9.3124,   9.3125]],\n",
      "\n",
      "        [[ -6.5032,  -8.3647,  -8.1158,  ...,   9.6742,   9.6731,   9.6732],\n",
      "         [ -8.2497, -10.3459,  -8.3313,  ...,   9.4715,   9.4709,   9.4708],\n",
      "         [ -7.7183,  -9.1067,  -7.5906,  ...,   9.5321,   9.5317,   9.5320],\n",
      "         ...,\n",
      "         [  8.0554,  17.0699,  13.5888,  ...,   4.0589,   4.0580,   4.0586],\n",
      "         [ 12.1119,  10.7101,   2.3401,  ...,   3.1737,   3.1726,   3.1734],\n",
      "         [ -2.8501,  -5.5048,  -5.4820,  ...,   9.0517,   9.0508,   9.0509]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.9940,  -9.7569,  -8.3702,  ...,   9.5702,   9.5692,   9.5693],\n",
      "         [ -9.3157, -11.9396,  -8.8739,  ...,   9.4078,   9.4073,   9.4070],\n",
      "         [ -7.9731, -10.2143,  -7.4524,  ...,  10.0004,  10.0001,  10.0001],\n",
      "         ...,\n",
      "         [  8.2237,  14.2282,  12.7251,  ...,   4.6681,   4.6671,   4.6677],\n",
      "         [ 11.0303,   9.2180,  -0.2849,  ...,   2.9902,   2.9892,   2.9899],\n",
      "         [ -3.3504,  -8.9320,  -6.2993,  ...,   9.8177,   9.8167,   9.8169]],\n",
      "\n",
      "        [[ -5.8792,  -7.6956,  -8.3241,  ...,   9.9320,   9.9314,   9.9313],\n",
      "         [ -7.8983,  -8.5761,  -8.5490,  ...,  10.0231,  10.0227,  10.0227],\n",
      "         [ -8.0954,  -9.3003,  -8.9953,  ...,  10.8826,  10.8824,  10.8828],\n",
      "         ...,\n",
      "         [  8.6895,  15.4320,  13.6028,  ...,   4.8386,   4.8375,   4.8381],\n",
      "         [ 10.8270,   9.4972,  -0.4262,  ...,   2.8259,   2.8252,   2.8258],\n",
      "         [ -3.5896,  -9.4353,  -6.7606,  ...,   9.8566,   9.8556,   9.8558]],\n",
      "\n",
      "        [[ -5.4583,  -9.8569,  -8.3007,  ...,   9.4310,   9.4301,   9.4302],\n",
      "         [ -8.7559, -11.3434,  -8.2541,  ...,   9.5213,   9.5209,   9.5207],\n",
      "         [ -7.5737,  -9.8480,  -6.8407,  ...,   9.9271,   9.9268,   9.9269],\n",
      "         ...,\n",
      "         [  7.6882,  14.4787,  12.4847,  ...,   4.7189,   4.7175,   4.7179],\n",
      "         [ 11.4118,  10.3536,   0.8518,  ...,   3.1524,   3.1512,   3.1518],\n",
      "         [ -2.7543,  -6.5899,  -5.7148,  ...,   9.1449,   9.1440,   9.1441]]],\n",
      "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([32, 114, 128256])\n"
     ]
    }
   ],
   "source": [
    "output_logits = llm(**generated_outputs).logits\n",
    "print(output_logits)\n",
    "print(output_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128009, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.argmax(output_logits[0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
      "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
      "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
      "        ...,\n",
      "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
      "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
      "        [128009, 128009, 128009,  ...,  78191, 128007,    271]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'), 'labels': tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')}\n",
      "{'input_ids': tensor([[128009, 128009, 128009,  ..., 128009, 128009, 128009],\n",
      "        [128009, 128009, 128009,  ..., 128009, 128009, 128009],\n",
      "        [128009, 128009, 128009,  ..., 128009, 128009, 128009],\n",
      "        ...,\n",
      "        [128009, 128009, 128009,  ..., 128009, 128009, 128009],\n",
      "        [128009, 128009, 128009,  ..., 128009, 128009, 128009],\n",
      "        [128009, 128009, 128009,  ..., 128009, 128009, 128009]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(generated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmexp.trainer.mab_trainer import randomly_cut_and_pad_generations\n",
    "random_cropped_inputs =randomly_cut_and_pad_generations(inputs, generated_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0263, -0.0066, -0.0134,  ...,  0.0087, -0.0066,  0.0210],\n",
       "        [-0.0017,  0.0019, -0.0087,  ..., -0.0011,  0.0053,  0.0127],\n",
       "        [-0.0095, -0.0140, -0.0140,  ...,  0.0107, -0.0203,  0.0189],\n",
       "        ...,\n",
       "        [-0.0130, -0.0130, -0.0140,  ..., -0.0132, -0.0129,  0.0084],\n",
       "        [ 0.0066,  0.0051,  0.0033,  ...,  0.0083, -0.0102,  0.0258],\n",
       "        [-0.0003, -0.0062, -0.0081,  ..., -0.0084, -0.0175,  0.0106]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llmexp.explainer.mab_model import MABModel\n",
    "mab_model = MABModel(llm, hidden_size=2048).to(device)\n",
    "mu_logits = mab_model.forward(**random_cropped_inputs)\n",
    "mu_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 119])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cropped_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' text'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.argmax(output_logits[0,53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(0.7496, device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor(128009, device='cuda:0'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.softmax(output_logits[0,19], dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' following'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0,54])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
