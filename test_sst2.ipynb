{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmexp.llm.smollm import LLMWrapper\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "\n",
    "# checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "checkpoint = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# checkpoint = \"HuggingFaceTB/SmolLM-1.7B-Instruct\"\n",
    "# saved_mab_model = \"checkpoints/mab_model_100.pth\"\n",
    "saved_mab_model = \"checkpoints/mab_model_20.pth\"\n",
    "\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "\n",
    "llm = LLMWrapper(checkpoint, device=device)\n",
    "tokenizer = llm.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.<|eot_id|><|start_header_id|>sentence<|end_header_id|>\n",
      "\n",
      "The service at this restaurant was fantastic, and the staff were so friendly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "positive<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# instruction = \"Analyze the sentiment of the following sentence. Be brief.\"\n",
    "instruction = \"Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.\"\n",
    "# user_input = \"I am extremely disappointed with the quality; it broke after just one day.\"\n",
    "user_input = \"The service at this restaurant was fantastic, and the staff were so friendly.\"\n",
    "# user_input = \"This is a good book.\"\n",
    "\n",
    "content = [\n",
    "            {\"role\": \"system\", \n",
    "            \"content\": instruction\n",
    "            },\n",
    "\n",
    "            {\"role\": \"sentence\", \n",
    "            \"content\": user_input\n",
    "            }\n",
    "        ]\n",
    "template = tokenizer.apply_chat_template(content, tokenize=False, add_generation_prompt=True)\n",
    "# print(template)\n",
    "\n",
    "# The generated outputs \n",
    "gen_output = llm.generate_from_texts(template)\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128006,   9125, 128007,    271,   2127,  56956,    279,  27065,\n",
      "            315,    279,   2768,  11914,    323,   6013,    449,   1193,    832,\n",
      "           3492,     25,    364,  31587,   2965,    364,  43324,   2965,    477,\n",
      "            364,  60668,   2965,   3196,    389,    279,   8244,  16630,    323,\n",
      "           7438,    315,    279,  11914,     13,   3234,    539,   3493,    904,\n",
      "           5217,  16540,     13, 128009, 128006,  52989, 128007,    271,    791,\n",
      "           2532,    520,    420,  10960,    574,  14964,     11,    323,    279,\n",
      "           5687,   1051,    779,  11919,     13, 128009, 128006,  78191, 128007]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]],\n",
      "       device='cuda:0'), 'context_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]],\n",
      "       device='cuda:0'), 'labels': tensor([1], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "from llmexp.utils.data_utils import DataCollator\n",
    "data_collator = DataCollator(tokenizer, max_length=512)\n",
    "\n",
    "example = {\n",
    "    'sentence': user_input,\n",
    "    'label': 1\n",
    "}\n",
    "\n",
    "example = data_collator([example]).to(device)\n",
    "print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128006,   9125, 128007,    271,   2127,  56956,    279,  27065,\n",
      "            315,    279,   2768,  11914,    323,   6013,    449,   1193,    832,\n",
      "           3492,     25,    364,  31587,   2965,    364,  43324,   2965,    477,\n",
      "            364,  60668,   2965,   3196,    389,    279,   8244,  16630,    323,\n",
      "           7438,    315,    279,  11914,     13,   3234,    539,   3493,    904,\n",
      "           5217,  16540,     13, 128009, 128006,  52989, 128007,    271,    791,\n",
      "           2532,    520,    420,  10960,    574,  14964,     11,    323,    279,\n",
      "           5687,   1051,    779,  11919,     13, 128009, 128006,  78191, 128007,\n",
      "            271,  31587, 128009]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "         1, 1, 0]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "gen_output = llm.generate(example['input_ids'], example['attention_mask'])\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.<|eot_id|><|start_header_id|>sentence<|end_header_id|>\n",
      "\n",
      "The service at this restaurant was fantastic, and the staff were so friendly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "positive<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(gen_output['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128006,   9125, 128007,    271,   2127,  56956,    279,  27065,\n",
      "            315,    279,   2768,  11914,    323,   6013,    449,   1193,    832,\n",
      "           3492,     25,    364,  31587,   2965,    364,  43324,   2965,    477,\n",
      "            364,  60668,   2965,   3196,    389,    279,   8244,  16630,    323,\n",
      "           7438,    315,    279,  11914,     13,   3234,    539,   3493,    904,\n",
      "           5217,  16540,     13, 128009, 128006,  52989, 128007,    271,    791,\n",
      "           2532,    520,    420,  10960,    574,  14964,     11,    323,    279,\n",
      "           5687,   1051,    779,  11919,     13, 128009, 128006,  78191, 128007,\n",
      "            271,  31587]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "         1, 1]], device='cuda:0'), 'context_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "from llmexp.trainer.mab_trainer import randomly_cut_and_pad_generations\n",
    "cut_and_pad_gen_output = randomly_cut_and_pad_generations(example, gen_output, tokenizer)\n",
    "print(cut_and_pad_gen_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.<|eot_id|><|start_header_id|>sentence<|end_header_id|>\n",
      "\n",
      "The service at this restaurant was fantastic, and the staff were so friendly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(cut_and_pad_gen_output['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/1121458.1.gpu/ipykernel_2906934/3922162976.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mab_model = MABModel.load_with_base_model(torch.load(saved_mab_model), llm, hidden_size=1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llmexp.explainer.mab_model import MABModel\n",
    "mab_model = MABModel.load_with_base_model(torch.load(saved_mab_model), llm, hidden_size=1024)\n",
    "mab_model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = cut_and_pad_gen_output['input_ids']\n",
    "attention_mask = cut_and_pad_gen_output['attention_mask']\n",
    "dist, values = mab_model.get_dist_value(input_ids, attention_mask)\n",
    "\n",
    "mab_values = torch.sigmoid(dist.logits)\n",
    "\n",
    "context_mask = cut_and_pad_gen_output['context_mask']\n",
    "# mab_values = dist.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0744, -0.1821, -0.2556, -0.2011, -0.1284, -0.2351, -0.2945, -0.1696,\n",
       "         -0.2390, -0.2496, -0.1985, -0.2542, -0.2859, -0.3161, -0.2718, -0.2600,\n",
       "         -0.2452, -0.2136, -0.2030, -0.2643, -0.2442, -0.3878, -0.4335, -0.2538,\n",
       "         -0.3299, -0.3185, -0.3568, -0.2413, -0.3102, -0.2797, -0.3317, -0.2492,\n",
       "         -0.2292, -0.1889, -0.2909, -0.1962, -0.2822, -0.3447, -0.3071, -0.3962,\n",
       "         -0.3263, -0.2755, -0.2171, -0.2550, -0.2422, -0.2194, -0.3607, -0.3115,\n",
       "         -0.1606, -0.1651, -0.2648, -0.2795, -0.2874, -0.3480, -0.3514, -0.2623,\n",
       "         -0.2598, -0.3774, -0.4406, -0.4785, -0.3845, -0.3791, -0.2542, -0.2363,\n",
       "         -0.3274, -0.3021, -0.4036, -0.4414, -0.2714, -0.2433, -0.0986, -0.3808,\n",
       "         -0.2739]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4814, 0.4546, 0.4365, 0.4499, 0.4680, 0.4415, 0.4269, 0.4577, 0.4405,\n",
      "         0.4379, 0.4505, 0.4368, 0.4290, 0.4216, 0.4325, 0.4354, 0.4390, 0.4468,\n",
      "         0.4494, 0.4343, 0.4393, 0.4042, 0.3933, 0.4369, 0.4183, 0.4210, 0.4117,\n",
      "         0.4400, 0.4231, 0.4305, 0.4178, 0.4380, 0.4429, 0.4529, 0.4278, 0.4511,\n",
      "         0.4299, 0.4147, 0.4238, 0.4022, 0.4191, 0.4316, 0.4459, 0.4366, 0.4397,\n",
      "         0.4454, 0.4108, 0.4227, 0.4599, 0.4588, 0.4342, 0.4306, 0.4286, 0.4139,\n",
      "         0.4130, 0.4348, 0.4354, 0.4068, 0.3916, 0.3826, 0.4050, 0.4063, 0.4368,\n",
      "         0.4412, 0.4189, 0.4251, 0.4004, 0.3914, 0.4326, 0.4395, 0.4754, 0.4059,\n",
      "         0.4319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([1, 73])\n"
     ]
    }
   ],
   "source": [
    "print(mab_values)\n",
    "print(mab_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000, 128006,   9125, 128007,    271,   2127,  56956,    279,  27065,\n",
      "            315,    279,   2768,  11914,    323,   6013,    449,   1193,    832,\n",
      "           3492,     25,    364,  31587,   2965,    364,  43324,   2965,    477,\n",
      "            364,  60668,   2965,   3196,    389,    279,   8244,  16630,    323,\n",
      "           7438,    315,    279,  11914,     13,   3234,    539,   3493,    904,\n",
      "           5217,  16540,     13, 128009, 128006,  52989, 128007,    271,    791,\n",
      "           2532,    520,    420,  10960,    574,  14964,     11,    323,    279,\n",
      "           5687,   1051,    779,  11919,     13, 128009, 128006,  78191, 128007,\n",
      "            271,  31587]], device='cuda:0')\n",
      "torch.Size([1, 74])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tokens_with_values(input_ids, mab_values, context_mask, tokenizer):\n",
    "    # Decode tokens one by one to preserve alignment\n",
    "    tokens = []\n",
    "    for i in range(input_ids.shape[1]):\n",
    "        token = tokenizer.decode(input_ids[0, i:i+1])\n",
    "        tokens.append(token)\n",
    "    \n",
    "    # Normalize MAB values to [0,1] for color intensity first\n",
    "    mab_values = mab_values * context_mask[:,:-1]\n",
    "    # Create a mask for non-zero values\n",
    "    non_zero_mask = mab_values[0] != 0\n",
    "    # normalized_values = (mab_values[0] - mab_values[0].min()) / (mab_values[0].max() - mab_values[0].min())\n",
    "    normalized_values = torch.zeros_like(mab_values[0])\n",
    "    # Only normalize non-zero values\n",
    "    if non_zero_mask.any():  # Check if there are any non-zero values\n",
    "        non_zero_values = mab_values[0][non_zero_mask]\n",
    "        normalized_non_zero = (non_zero_values - non_zero_values.min()) / (non_zero_values.max() - non_zero_values.min())\n",
    "        normalized_values[non_zero_mask] = normalized_non_zero\n",
    "    \n",
    "    # Pad normalized_values with a zero at the end\n",
    "    padded_normalized_values = torch.cat([normalized_values, torch.zeros(1, device=mab_values.device)], dim=0)\n",
    "    # Pad original mab_values with the last actual value\n",
    "    padded_mab_values = torch.cat([mab_values[0], mab_values[0][-1:]], dim=0)\n",
    "    \n",
    "    # Generate HTML with colored text and values\n",
    "    html_output = \"<div style='font-family: monospace; line-height: 2; background-color: white; padding: 10px;'>\"\n",
    "    for token, value, orig_value in zip(tokens, padded_normalized_values, padded_mab_values):\n",
    "        # Use a gradient from white to green\n",
    "        intensity = float(value)\n",
    "        green_color = int(intensity * 200)  # Control the maximum intensity\n",
    "        html_output += f'<span style=\"color: black; background-color: rgba(0, {green_color}, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: {orig_value:.3f}, Norm: {value:.3f}\">{token}</span>'\n",
    "    html_output += \"</div>\"\n",
    "    \n",
    "    # Print the values\n",
    "    print(\"Token\\tNormalized Value\\tOriginal MAB Value\")\n",
    "    print(\"-\" * 50)\n",
    "    for token, value, orig_value in zip(tokens, padded_normalized_values, padded_mab_values):\n",
    "        print(f\"{token}\\t{value:.3f}\\t\\t{orig_value:.3f}\")\n",
    "    \n",
    "    from IPython.display import HTML\n",
    "    return HTML(html_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token\tNormalized Value\tOriginal MAB Value\n",
      "--------------------------------------------------\n",
      "<|begin_of_text|>\t0.000\t\t0.000\n",
      "<|start_header_id|>\t0.000\t\t0.000\n",
      "system\t0.000\t\t0.000\n",
      "<|end_header_id|>\t0.000\t\t0.000\n",
      "\n",
      "\n",
      "\t0.000\t\t0.000\n",
      "An\t0.000\t\t0.000\n",
      "alyze\t0.000\t\t0.000\n",
      " the\t0.000\t\t0.000\n",
      " sentiment\t0.000\t\t0.000\n",
      " of\t0.000\t\t0.000\n",
      " the\t0.000\t\t0.000\n",
      " following\t0.000\t\t0.000\n",
      " sentence\t0.000\t\t0.000\n",
      " and\t0.000\t\t0.000\n",
      " respond\t0.000\t\t0.000\n",
      " with\t0.000\t\t0.000\n",
      " only\t0.000\t\t0.000\n",
      " one\t0.000\t\t0.000\n",
      " word\t0.000\t\t0.000\n",
      ":\t0.000\t\t0.000\n",
      " '\t0.000\t\t0.000\n",
      "positive\t0.000\t\t0.000\n",
      ",'\t0.000\t\t0.000\n",
      " '\t0.000\t\t0.000\n",
      "negative\t0.000\t\t0.000\n",
      ",'\t0.000\t\t0.000\n",
      " or\t0.000\t\t0.000\n",
      " '\t0.000\t\t0.000\n",
      "neutral\t0.000\t\t0.000\n",
      ",'\t0.000\t\t0.000\n",
      " based\t0.000\t\t0.000\n",
      " on\t0.000\t\t0.000\n",
      " the\t0.000\t\t0.000\n",
      " overall\t0.000\t\t0.000\n",
      " tone\t0.000\t\t0.000\n",
      " and\t0.000\t\t0.000\n",
      " meaning\t0.000\t\t0.000\n",
      " of\t0.000\t\t0.000\n",
      " the\t0.000\t\t0.000\n",
      " sentence\t0.000\t\t0.000\n",
      ".\t0.000\t\t0.000\n",
      " Do\t0.000\t\t0.000\n",
      " not\t0.000\t\t0.000\n",
      " provide\t0.000\t\t0.000\n",
      " any\t0.000\t\t0.000\n",
      " additional\t0.000\t\t0.000\n",
      " explanation\t0.000\t\t0.000\n",
      ".\t0.000\t\t0.000\n",
      "<|eot_id|>\t0.000\t\t0.000\n",
      "<|start_header_id|>\t0.000\t\t0.000\n",
      "sentence\t0.000\t\t0.000\n",
      "<|end_header_id|>\t0.000\t\t0.000\n",
      "\n",
      "\n",
      "\t0.000\t\t0.000\n",
      "The\t0.534\t\t0.414\n",
      " service\t0.520\t\t0.413\n",
      " at\t0.891\t\t0.435\n",
      " this\t0.902\t\t0.435\n",
      " restaurant\t0.412\t\t0.407\n",
      " was\t0.154\t\t0.392\n",
      " fantastic\t0.000\t\t0.383\n",
      ",\t0.383\t\t0.405\n",
      " and\t0.405\t\t0.406\n",
      " the\t0.925\t\t0.437\n",
      " staff\t1.000\t\t0.441\n",
      " were\t0.619\t\t0.419\n",
      " so\t0.725\t\t0.425\n",
      " friendly\t0.305\t\t0.400\n",
      ".\t0.151\t\t0.391\n",
      "<|eot_id|>\t0.000\t\t0.000\n",
      "<|start_header_id|>\t0.000\t\t0.000\n",
      "assistant\t0.000\t\t0.000\n",
      "<|end_header_id|>\t0.000\t\t0.000\n",
      "\n",
      "\n",
      "\t0.000\t\t0.000\n",
      "positive\t0.000\t\t0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='font-family: monospace; line-height: 2; background-color: white; padding: 10px;'><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|begin_of_text|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|start_header_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">system</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|end_header_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">\n",
       "\n",
       "</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">An</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">alyze</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> the</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> sentiment</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> of</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> the</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> following</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> sentence</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> and</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> respond</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> with</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> only</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> one</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> word</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">:</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> '</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">positive</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">,'</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> '</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">negative</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">,'</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> or</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> '</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">neutral</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">,'</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> based</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> on</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> the</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> overall</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> tone</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> and</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> meaning</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> of</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> the</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> sentence</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">.</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> Do</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> not</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> provide</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> any</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> additional</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"> explanation</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">.</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|eot_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|start_header_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">sentence</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|end_header_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">\n",
       "\n",
       "</span><span style=\"color: black; background-color: rgba(0, 106, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.414, Norm: 0.534\">The</span><span style=\"color: black; background-color: rgba(0, 103, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.413, Norm: 0.520\"> service</span><span style=\"color: black; background-color: rgba(0, 178, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.435, Norm: 0.891\"> at</span><span style=\"color: black; background-color: rgba(0, 180, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.435, Norm: 0.902\"> this</span><span style=\"color: black; background-color: rgba(0, 82, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.407, Norm: 0.412\"> restaurant</span><span style=\"color: black; background-color: rgba(0, 30, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.392, Norm: 0.154\"> was</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.383, Norm: 0.000\"> fantastic</span><span style=\"color: black; background-color: rgba(0, 76, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.405, Norm: 0.383\">,</span><span style=\"color: black; background-color: rgba(0, 81, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.406, Norm: 0.405\"> and</span><span style=\"color: black; background-color: rgba(0, 185, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.437, Norm: 0.925\"> the</span><span style=\"color: black; background-color: rgba(0, 200, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.441, Norm: 1.000\"> staff</span><span style=\"color: black; background-color: rgba(0, 123, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.419, Norm: 0.619\"> were</span><span style=\"color: black; background-color: rgba(0, 144, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.425, Norm: 0.725\"> so</span><span style=\"color: black; background-color: rgba(0, 60, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.400, Norm: 0.305\"> friendly</span><span style=\"color: black; background-color: rgba(0, 30, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.391, Norm: 0.151\">.</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|eot_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|start_header_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">assistant</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\"><|end_header_id|></span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">\n",
       "\n",
       "</span><span style=\"color: black; background-color: rgba(0, 0, 0, 0.3); padding: 0.2em; margin: 0.1em; border-radius: 3px;\" title=\"MAB: 0.000, Norm: 0.000\">positive</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usage:\n",
    "visualization = visualize_tokens_with_values(input_ids, mab_values, context_mask, tokenizer)\n",
    "display(visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
