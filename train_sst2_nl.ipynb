{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpd90506\u001b[0m (\u001b[33mpd90506-nd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/afs/crc.nd.edu/user/d/dpan/wd/llm_explain/wandb/run-20250224_151141-9qhdecyt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pd90506-nd/mab-sst2nl/runs/9qhdecyt' target=\"_blank\">silvery-bee-15</a></strong> to <a href='https://wandb.ai/pd90506-nd/mab-sst2nl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pd90506-nd/mab-sst2nl' target=\"_blank\">https://wandb.ai/pd90506-nd/mab-sst2nl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pd90506-nd/mab-sst2nl/runs/9qhdecyt' target=\"_blank\">https://wandb.ai/pd90506-nd/mab-sst2nl/runs/9qhdecyt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from llmexp.llm.smollm import LLMWrapper\n",
    "from accelerate import Accelerator\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"mab-sst2nl\")\n",
    "\n",
    "# checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "checkpoint = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# checkpoint = \"HuggingFaceTB/SmolLM-1.7B-Instruct\"\n",
    "\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "\n",
    "llm = LLMWrapper(checkpoint, device=device)\n",
    "tokenizer = llm.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmexp.utils.data_utils import LLMDataset, create_dataloader\n",
    "# instruction = \"Analyze the sentiment of the following sentence and respond with only one word: 'positive,' 'negative,' or 'neutral,' based on the overall tone and meaning of the sentence. Do not provide any additional explanation.\"\n",
    "# instruction = \"Analyze the sentiment of the following sentence and respond with only one word: 'positive', 'negative', or 'neutral', based on the overall tone and meaning of the sentence, if no enough information provided, respond with 'not clear' with an explanation.\"\n",
    "instruction = \"Analyze the sentiment of the following sentence and respond concisely.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmexp.explainer.mab_model import MABModel\n",
    "from llmexp.trainer.mab_trainer import MABTrainer\n",
    "\n",
    "mab_model = MABModel(llm, hidden_size=1024)\n",
    "\n",
    "config = {\n",
    "    'lr': 1e-4,\n",
    "    'num_pulls': 3,\n",
    "    'num_epochs': 1,\n",
    "    'batch_size': 64,\n",
    "    'clip_epsilon': 0.2,\n",
    "    'lambda_entropy': 0.0,\n",
    "    'minibatch_size': 64,\n",
    "    'ppo_epochs': 2,\n",
    "    'topk': 0.2, # number of topk tokens to select, if topk < 1, then topk is the ratio of the number of tokens to select\n",
    "    'save_interval': 20,\n",
    "}\n",
    "dataloader = create_dataloader('sst2', tokenizer, batch_size=config['batch_size'], instruction=instruction)\n",
    "\n",
    "mab_trainer = MABTrainer(mab_model, llm, tokenizer, config, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training MAB: 0it [00:00, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Training MAB: 278it [1:21:31, 17.06s/it]"
     ]
    }
   ],
   "source": [
    "mab_trainer.train(dataloader, gamma=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import torch\n",
    "torch.save(mab_model.state_dict(), f\"checkpoints/mab_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_explain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
