{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring environment parameters\n",
    "import os\n",
    "import json \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='log/app.log',            # Specify the log file name\n",
    "    level=logging.DEBUG,           # Set the log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Set the log format\n",
    ")\n",
    "\n",
    "# Load the environment configuration JSON data\n",
    "json_path = 'env_config.json'\n",
    "with open(json_path, 'r') as file:\n",
    "    env_config = json.load(file)\n",
    "\n",
    "hf_home = env_config['HF_HOME']\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ['HF_HOME'] = hf_home\n",
    "# Set the access token to huggingface hub\n",
    "access_token = env_config['access_token']\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary packages\n",
    "import transformers \n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, LlamaForTokenClassification #, LlamaRotaryEmbedding\n",
    "# from transformers import LlamaTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from llmexp.helper import DataHelper\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# TODO 注意load正确的模型\n",
    "from llmexp.imdb_model import MaskGeneratingModelForIMDB\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ds = load_dataset(\"imdb\")\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "# ds = load_dataset(\"stanfordnlp/sst2\")\n",
    "train_ds = ds['train']\n",
    "# test_ds = ds['test']\n",
    "test_ds = ds['validation']\n",
    "\n",
    "llm_exp_helper = DataHelper(tokenizer)\n",
    "# collate_fn = llm_exp_helper.get_collate_fun('imdb')\n",
    "# collate_fn = llm_exp_helper.get_collate_fun('sst2')\n",
    "collate_fn = llm_exp_helper.get_collate_fun('squad')\n",
    "\n",
    "# Define batch size here!\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff67d7ece35f42d0abe24c43ee0249ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure and load model\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B\"  # non-instruct version\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=\"auto\",\n",
    "    device_map=device,\n",
    "    token=access_token,\n",
    ")\n",
    "\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`LlamaRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.45\n"
     ]
    }
   ],
   "source": [
    "# Configure mask model and  Training parameters\n",
    "mask_gen_model = MaskGeneratingModelForIMDB()\n",
    "mask_gen_model.to(device)\n",
    "\n",
    "# Set pad_token_id if it is not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(mask_gen_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        ...,\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]]), 'context_mask': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5475 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Epoch 1, Step 1: Loss = 0.2152, Actor Loss = 0.0382, Critic Loss = 0.3664, Entropy = 0.6225, Returns = 0.3676, Value = 0.6443, mask_loss = 0.6824std_loss = 0.0299:   0%|          | 1/5475 [00:11<17:12:29, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.2526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2: Loss = 0.3135, Actor Loss = 0.0331, Critic Loss = 0.5739, Entropy = 0.6546, Returns = 0.9713, Value = 0.8912, mask_loss = 0.6213std_loss = 0.0572:   0%|          | 2/5475 [00:20<14:59:43,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.4790, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 3: Loss = 0.0569, Actor Loss = -0.0177, Critic Loss = 0.1620, Entropy = 0.6296, Returns = 0.6583, Value = 0.6174, mask_loss = 0.6658std_loss = 0.0479:   0%|          | 3/5475 [00:29<14:47:15,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 4: Loss = 0.1277, Actor Loss = -0.1087, Critic Loss = 0.4851, Entropy = 0.6173, Returns = 1.0627, Value = 1.0031, mask_loss = 0.6776std_loss = 0.0472:   0%|          | 4/5475 [00:41<16:04:25, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(2.3837, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 5: Loss = 0.0529, Actor Loss = -0.0697, Critic Loss = 0.2566, Entropy = 0.5711, Returns = 0.9155, Value = 0.6885, mask_loss = 0.7329std_loss = 0.0424:   0%|          | 5/5475 [00:52<16:08:07, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(2.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 6: Loss = 0.1645, Actor Loss = 0.0112, Critic Loss = 0.3179, Entropy = 0.5714, Returns = 1.2221, Value = 1.2876, mask_loss = 0.7253std_loss = 0.0554:   0%|          | 6/5475 [01:02<15:45:06, 10.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(2.3546, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 7: Loss = 0.1222, Actor Loss = 0.0557, Critic Loss = 0.1427, Entropy = 0.4872, Returns = 0.9836, Value = 0.9092, mask_loss = 0.7976std_loss = 0.0577:   0%|          | 7/5475 [01:11<15:23:55, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 8: Loss = 0.2102, Actor Loss = -0.0017, Critic Loss = 0.4339, Entropy = 0.5076, Returns = 1.0420, Value = 1.0413, mask_loss = 0.7892std_loss = 0.0466:   0%|          | 8/5475 [01:24<16:46:35, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(5.2578, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 9: Loss = 0.1185, Actor Loss = 0.0205, Critic Loss = 0.2071, Entropy = 0.5523, Returns = 0.8490, Value = 0.8398, mask_loss = 0.7380std_loss = 0.0786:   0%|          | 9/5475 [01:34<16:10:15, 10.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1931, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 10: Loss = 0.2199, Actor Loss = -0.0502, Critic Loss = 0.5501, Entropy = 0.4952, Returns = 0.8208, Value = 0.7287, mask_loss = 0.7920std_loss = 0.0643:   0%|          | 10/5475 [01:49<18:08:44, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.6400, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 11: Loss = 0.1730, Actor Loss = -0.0188, Critic Loss = 0.3932, Entropy = 0.4809, Returns = 0.9218, Value = 0.8201, mask_loss = 0.7981std_loss = 0.0816:   0%|          | 11/5475 [01:58<16:38:17, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 12: Loss = 0.2632, Actor Loss = 0.0383, Critic Loss = 0.4591, Entropy = 0.4632, Returns = 1.1640, Value = 1.0834, mask_loss = 0.8115std_loss = 0.0706:   0%|          | 12/5475 [02:06<15:19:18, 10.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 13: Loss = 0.1126, Actor Loss = -0.0869, Critic Loss = 0.4076, Entropy = 0.4276, Returns = 1.0812, Value = 1.0103, mask_loss = 0.8354std_loss = 0.0681:   0%|          | 13/5475 [02:16<15:19:58, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(2.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 14: Loss = 0.1069, Actor Loss = -0.0220, Critic Loss = 0.2666, Entropy = 0.4445, Returns = 1.0986, Value = 1.0591, mask_loss = 0.8274std_loss = 0.0609:   0%|          | 14/5475 [02:26<15:05:22,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1933, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 15: Loss = 0.0478, Actor Loss = -0.0591, Critic Loss = 0.2229, Entropy = 0.4484, Returns = 1.0099, Value = 0.9739, mask_loss = 0.8224std_loss = 0.0722:   0%|          | 15/5475 [02:37<15:42:21, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(5.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 16: Loss = 0.1435, Actor Loss = 0.0298, Critic Loss = 0.2361, Entropy = 0.4406, Returns = 1.0298, Value = 1.0568, mask_loss = 0.8160std_loss = 0.0893:   0%|          | 16/5475 [02:48<15:52:08, 10.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(2.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 17: Loss = 0.1157, Actor Loss = -0.0417, Critic Loss = 0.3234, Entropy = 0.4349, Returns = 1.0098, Value = 0.9579, mask_loss = 0.8184std_loss = 0.0866:   0%|          | 17/5475 [02:56<15:09:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(10.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 18: Loss = 0.1539, Actor Loss = 0.0004, Critic Loss = 0.3151, Entropy = 0.4131, Returns = 0.6547, Value = 0.5758, mask_loss = 0.8451std_loss = 0.0661:   0%|          | 18/5475 [03:07<15:13:56, 10.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.3534, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 19: Loss = 0.2449, Actor Loss = 0.0822, Critic Loss = 0.3345, Entropy = 0.4546, Returns = 0.9491, Value = 1.1001, mask_loss = 0.8158std_loss = 0.0792:   0%|          | 19/5475 [03:17<15:32:29, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(18.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 20: Loss = 0.1624, Actor Loss = -0.0038, Critic Loss = 0.3408, Entropy = 0.4209, Returns = 0.8927, Value = 1.0185, mask_loss = 0.8368std_loss = 0.0734:   0%|          | 20/5475 [03:31<16:50:56, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 21: Loss = 0.0745, Actor Loss = -0.0656, Critic Loss = 0.2879, Entropy = 0.3909, Returns = 0.9282, Value = 0.8682, mask_loss = 0.8477std_loss = 0.0795:   0%|          | 21/5475 [03:43<17:17:06, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(26.9097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 22: Loss = 0.1032, Actor Loss = 0.0029, Critic Loss = 0.2070, Entropy = 0.3207, Returns = 0.5794, Value = 0.6541, mask_loss = 0.8869std_loss = 0.0809:   0%|          | 22/5475 [03:53<16:43:45, 11.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(4.3027, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 23: Loss = 0.4312, Actor Loss = 0.0036, Critic Loss = 0.8577, Entropy = 0.1192, Returns = 0.8736, Value = 0.8771, mask_loss = 0.9715std_loss = 0.0227:   0%|          | 23/5475 [04:02<16:06:41, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 24: Loss = 0.1356, Actor Loss = 0.0090, Critic Loss = 0.2557, Entropy = 0.1192, Returns = 0.8790, Value = 0.8974, mask_loss = 0.9719std_loss = 0.0229:   0%|          | 24/5475 [04:14<16:28:48, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1990, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 25: Loss = 0.0974, Actor Loss = 0.0139, Critic Loss = 0.1688, Entropy = 0.0881, Returns = 0.8435, Value = 0.8649, mask_loss = 0.9807std_loss = 0.0162:   0%|          | 25/5475 [04:25<16:23:00, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.2367, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 26: Loss = 0.0399, Actor Loss = -0.0284, Critic Loss = 0.1386, Entropy = 0.0907, Returns = 0.9687, Value = 0.9538, mask_loss = 0.9792std_loss = 0.0202:   0%|          | 26/5475 [04:38<17:30:45, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 27: Loss = 0.1607, Actor Loss = -0.0013, Critic Loss = 0.3260, Entropy = 0.1013, Returns = 0.9627, Value = 0.9352, mask_loss = 0.9746std_loss = 0.0291:   0%|          | 27/5475 [04:47<16:27:44, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9989, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 28: Loss = 0.0929, Actor Loss = -0.0578, Critic Loss = 0.3029, Entropy = 0.0669, Returns = 1.0148, Value = 0.9685, mask_loss = 0.9867std_loss = 0.0098:   1%|          | 28/5475 [04:56<15:23:22, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.4196, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 29: Loss = 0.1363, Actor Loss = 0.0040, Critic Loss = 0.2658, Entropy = 0.0628, Returns = 1.0669, Value = 1.1076, mask_loss = 0.9871std_loss = 0.0139:   1%|          | 29/5475 [05:05<15:05:35,  9.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0658, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 30: Loss = 0.1557, Actor Loss = 0.0012, Critic Loss = 0.3101, Entropy = 0.0591, Returns = 0.9105, Value = 0.9310, mask_loss = 0.9882std_loss = 0.0115:   1%|          | 30/5475 [05:15<14:59:27,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 31: Loss = 0.0861, Actor Loss = 0.0144, Critic Loss = 0.1443, Entropy = 0.0456, Returns = 0.9374, Value = 0.9452, mask_loss = 0.9912std_loss = 0.0102:   1%|          | 31/5475 [05:27<15:51:17, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 32: Loss = 0.1243, Actor Loss = -0.0072, Critic Loss = 0.2642, Entropy = 0.0583, Returns = 0.8546, Value = 0.8156, mask_loss = 0.9857std_loss = 0.0181:   1%|          | 32/5475 [05:39<16:48:45, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(7.8846, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 33: Loss = 0.1347, Actor Loss = 0.0318, Critic Loss = 0.2070, Entropy = 0.0598, Returns = 0.7860, Value = 0.8259, mask_loss = 0.9865std_loss = 0.0204:   1%|          | 33/5475 [05:49<16:10:25, 10.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9987, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 34: Loss = 0.0849, Actor Loss = 0.0047, Critic Loss = 0.1615, Entropy = 0.0549, Returns = 0.7958, Value = 0.7911, mask_loss = 0.9878std_loss = 0.0220:   1%|          | 34/5475 [05:59<15:57:10, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 35: Loss = 0.0949, Actor Loss = -0.0091, Critic Loss = 0.2087, Entropy = 0.0404, Returns = 1.0094, Value = 0.9799, mask_loss = 0.9913std_loss = 0.0146:   1%|          | 35/5475 [06:10<15:48:03, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.2218, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 36: Loss = 0.1089, Actor Loss = 0.0014, Critic Loss = 0.2161, Entropy = 0.0524, Returns = 0.7472, Value = 0.7020, mask_loss = 0.9881std_loss = 0.0168:   1%|          | 36/5475 [06:21<16:02:00, 10.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0313, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 37: Loss = 0.0387, Actor Loss = -0.0023, Critic Loss = 0.0834, Entropy = 0.0637, Returns = 0.7902, Value = 0.7385, mask_loss = 0.9865std_loss = 0.0167:   1%|          | 37/5475 [06:30<15:20:38, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 38: Loss = 0.0604, Actor Loss = 0.0110, Critic Loss = 0.1004, Entropy = 0.0780, Returns = 0.7389, Value = 0.7788, mask_loss = 0.9826std_loss = 0.0201:   1%|          | 38/5475 [06:39<15:02:20,  9.96s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 39: Loss = 0.2345, Actor Loss = 0.0022, Critic Loss = 0.4659, Entropy = 0.0606, Returns = 0.7589, Value = 0.8150, mask_loss = 0.9876std_loss = 0.0127:   1%|          | 39/5475 [06:50<15:27:34, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9983, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 40: Loss = 0.0524, Actor Loss = -0.0096, Critic Loss = 0.1252, Entropy = 0.0525, Returns = 0.8665, Value = 0.8549, mask_loss = 0.9894std_loss = 0.0117:   1%|          | 40/5475 [06:58<14:27:43,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9806, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 41: Loss = 0.0982, Actor Loss = 0.0111, Critic Loss = 0.1752, Entropy = 0.0493, Returns = 0.8727, Value = 0.9318, mask_loss = 0.9903std_loss = 0.0115:   1%|          | 41/5475 [07:08<14:23:38,  9.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 42: Loss = 0.1392, Actor Loss = 0.0117, Critic Loss = 0.2558, Entropy = 0.0409, Returns = 1.0525, Value = 1.0531, mask_loss = 0.9922std_loss = 0.0095:   1%|          | 42/5475 [07:19<15:23:30, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 43: Loss = 0.1276, Actor Loss = 0.0021, Critic Loss = 0.2522, Entropy = 0.0571, Returns = 0.8575, Value = 0.8396, mask_loss = 0.9881std_loss = 0.0142:   1%|          | 43/5475 [07:28<14:37:34,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 44: Loss = 0.0952, Actor Loss = 0.0077, Critic Loss = 0.1761, Entropy = 0.0571, Returns = 0.8752, Value = 0.8700, mask_loss = 0.9876std_loss = 0.0160:   1%|          | 44/5475 [07:40<15:56:57, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9762, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 45: Loss = 0.0347, Actor Loss = -0.0074, Critic Loss = 0.0856, Entropy = 0.0770, Returns = 0.8371, Value = 0.8841, mask_loss = 0.9822std_loss = 0.0243:   1%|          | 45/5475 [07:51<15:53:52, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0575, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 46: Loss = 0.0840, Actor Loss = 0.0057, Critic Loss = 0.1576, Entropy = 0.0592, Returns = 1.1158, Value = 1.0713, mask_loss = 0.9873std_loss = 0.0171:   1%|          | 46/5475 [08:02<15:57:22, 10.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 47: Loss = 0.0501, Actor Loss = -0.0128, Critic Loss = 0.1270, Entropy = 0.0596, Returns = 0.9296, Value = 0.9181, mask_loss = 0.9866std_loss = 0.0178:   1%|          | 47/5475 [08:14<16:48:00, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0178, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 48: Loss = 0.0836, Actor Loss = -0.0248, Critic Loss = 0.2178, Entropy = 0.0547, Returns = 1.0336, Value = 1.0272, mask_loss = 0.9888std_loss = 0.0130:   1%|          | 48/5475 [08:26<17:24:36, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0181, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 49: Loss = 0.0322, Actor Loss = -0.0029, Critic Loss = 0.0712, Entropy = 0.0454, Returns = 0.9718, Value = 0.9800, mask_loss = 0.9908std_loss = 0.0112:   1%|          | 49/5475 [08:40<18:06:58, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0346, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 50: Loss = 0.0651, Actor Loss = -0.0151, Critic Loss = 0.1617, Entropy = 0.0640, Returns = 1.1587, Value = 1.1384, mask_loss = 0.9859std_loss = 0.0167:   1%|          | 50/5475 [08:49<17:06:19, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 51: Loss = -0.0080, Actor Loss = -0.0375, Critic Loss = 0.0601, Entropy = 0.0605, Returns = 1.0017, Value = 1.0111, mask_loss = 0.9865std_loss = 0.0176:   1%|          | 51/5475 [08:59<16:17:49, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 52: Loss = 0.0894, Actor Loss = -0.0048, Critic Loss = 0.1898, Entropy = 0.0707, Returns = 0.9521, Value = 1.0256, mask_loss = 0.9847std_loss = 0.0173:   1%|          | 52/5475 [09:12<17:15:50, 11.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 53: Loss = 0.0718, Actor Loss = 0.0114, Critic Loss = 0.1223, Entropy = 0.0784, Returns = 1.0964, Value = 1.1285, mask_loss = 0.9814std_loss = 0.0258:   1%|          | 53/5475 [09:22<16:31:25, 10.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(1.2778, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 54: Loss = 0.0491, Actor Loss = -0.0053, Critic Loss = 0.1098, Entropy = 0.0546, Returns = 1.2333, Value = 1.2989, mask_loss = 0.9882std_loss = 0.0161:   1%|          | 54/5475 [09:30<15:15:43, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 55: Loss = 0.0992, Actor Loss = 0.0052, Critic Loss = 0.1889, Entropy = 0.0489, Returns = 1.1148, Value = 1.1190, mask_loss = 0.9896std_loss = 0.0157:   1%|          | 55/5475 [09:40<15:25:44, 10.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.9564, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 56: Loss = 0.1779, Actor Loss = 0.0083, Critic Loss = 0.3400, Entropy = 0.0437, Returns = 1.1554, Value = 1.0882, mask_loss = 0.9907std_loss = 0.0144:   1%|          | 56/5475 [09:54<16:46:57, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 56: Loss = 0.1779, Actor Loss = 0.0083, Critic Loss = 0.3400, Entropy = 0.0437, Returns = 1.1554, Value = 1.0882, mask_loss = 0.9907std_loss = 0.0144:   1%|          | 56/5475 [09:55<16:00:24, 10.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m context_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# get generated texts\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m gen_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mterminators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m gen_tokens \u001b[38;5;241m=\u001b[39m gen_outputs\u001b[38;5;241m.\u001b[39msequences\n\u001b[1;32m     22\u001b[0m pad_length \u001b[38;5;241m=\u001b[39m gen_tokens\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:977\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    974\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n\u001b[0;32m--> 977\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# decoder layers\u001b[39;00m\n\u001b[1;32m    980\u001b[0m all_hidden_states \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:210\u001b[0m, in \u001b[0;36mLlamaRotaryEmbedding.forward\u001b[0;34m(self, x, position_ids)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mdevice_type, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    209\u001b[0m     freqs \u001b[38;5;241m=\u001b[39m (inv_freq_expanded\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m@\u001b[39m position_ids_expanded\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     cos \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39mcos()\n\u001b[1;32m    212\u001b[0m     sin \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39msin()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask_gen_model.train()\n",
    "for epoch in range(1):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        context_mask = data['context_mask'].to(device)\n",
    "        # get generated texts\n",
    "        gen_outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "        gen_tokens = gen_outputs.sequences\n",
    "        pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "        # get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "        gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "        # (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "        unpaded_token_mask = (gen_tokens != tokenizer.pad_token_id).long()\n",
    "        unpaded_token_mask[:, :-pad_length] = 1\n",
    "        gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "\n",
    "        # get the response mask, which is the mask for the generated tokens (the user inputs are masked with 0)\n",
    "        response_mask = gen_attention_mask.clone()\n",
    "        response_mask[:, :-pad_length] = 0 # TODO: 有问题. 有问题吗？\n",
    "\n",
    "        context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "        loss_dict = mask_gen_model.train_one_batch(model, gen_tokens, gen_attention_mask, context_mask, response_mask, optimizer,\n",
    "                                                   num_steps=5, mini_batch_size=16, ppo_epochs=2)\n",
    "\n",
    "\n",
    "        log = f\"Epoch {epoch+1}, Step {idx+1}: Loss = {loss_dict['loss']:.4f}, \" \\\n",
    "               f\"Actor Loss = {loss_dict['actor_loss']:.4f}, \" \\\n",
    "               f\"Critic Loss = {loss_dict['critic_loss']:.4f}, \" \\\n",
    "               f\"Entropy = {loss_dict['entropy']:.4f}, \" \\\n",
    "               f\"Returns = {loss_dict['returns']:.4f}, \" \\\n",
    "               f\"Value = {loss_dict['value']:.4f}, \" \\\n",
    "                f\"mask_loss = {loss_dict['mask_loss']:.4f}\" \\\n",
    "                f\"std_loss = {loss_dict['std_loss']:.4f}\" \\\n",
    "            #    f\"Cont_loss = {loss_dict['contrast_loss']:.4f}, \"  \\\n",
    "               \n",
    "        pbar.set_description(log)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print()\n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            torch.save(mask_gen_model.state_dict(), f'saved_model/imdb_mask_gen_model_{epoch}_{idx}.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/853698.1.gpu/ipykernel_654701/1973279685.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_gen_model.load_state_dict(torch.load('saved_model/imdb_mask_gen_model_0_100.pth',map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "\n",
    "mask_gen_model.load_state_dict(torch.load('saved_model/imdb_mask_gen_model_0_100.pth',map_location=device))\n",
    "\n",
    "mask_gen_model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "test_inputs = next(iter(test_dataloader)).to(device)\n",
    "# test_inputs = next(iter(train_dataloader)).to(device)\n",
    "\n",
    "# tokens = tokenizer.convert_ids_to_tokens(test_inputs['input_ids'][idx])\n",
    "\n",
    "\n",
    "\n",
    "# data_dict = {\n",
    "#     'sentence': [\"I absolutely love this product! It exceeded all my expectations.\", \n",
    "#              \"The movie was fantastic, and the acting was top-notch.\",\n",
    "#              \"This restaurant offers great service and delicious food. Highly recommend!\",\n",
    "#              \"The product works as advertised, nothing more, nothing less.\",\n",
    "#              \"The event was well-organized, but it didn’t leave a lasting impression.\",\n",
    "#              \"t’s an average phone, nothing special but it does the job.\",\n",
    "#              \"I’m really disappointed with this purchase. It broke within a week.\",\n",
    "#              \"The movie was too long and boring, I wouldn’t recommend it.\",\n",
    "#              \"Terrible customer service, I won’t be coming back to this place.\"],\n",
    "#     'label': [1, 1, 1, 0, 0, 0, -1, -1, -1]\n",
    "# }\n",
    "# manual_test_data = Dataset.from_dict(data_dict)\n",
    "\n",
    "# manual_test_dataloader = DataLoader(manual_test_data, batch_size=9, collate_fn=collate_fn, shuffle=False)\n",
    "# #\n",
    "# test_inputs = next(iter(manual_test_dataloader)).to(device)\n",
    "\n",
    "\n",
    "# generate the answer for the test inputs\n",
    "gen_outputs = model.generate(\n",
    "            input_ids=test_inputs['input_ids'],\n",
    "            attention_mask=test_inputs['attention_mask'],\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "input_ids = test_inputs['input_ids']\n",
    "attention_mask = test_inputs['attention_mask']\n",
    "gen_tokens = gen_outputs.sequences\n",
    "pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "# get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "context_mask = F.pad(test_inputs['context_mask'], (0, pad_length), mode='constant', value=0)\n",
    "# (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "unpaded_token_mask = (gen_tokens != tokenizer.pad_token_id).long()\n",
    "unpaded_token_mask[:, :-pad_length] = 1\n",
    "gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "\n",
    "response_mask = gen_attention_mask.clone()\n",
    "response_mask[:, :-pad_length] = 0 # TODO: 有问题. 有问题吗？\n",
    "\n",
    "# context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # prompt_outputs = model(input_ids=test_inputs['input_ids'], attention_mask=test_inputs['attention_mask'], output_hidden_states=True, return_dict=True)\n",
    "#     prompt_outputs = model(input_ids=gen_tokens, attention_mask=gen_attention_mask, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "#     last_hidden_state = prompt_outputs.hidden_states[-1].float()\n",
    "#     mask_logits = mask_gen_model(last_hidden_state)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    state = gen_tokens, gen_attention_mask, context_mask, response_mask\n",
    "    dist, value = mask_gen_model.get_dist_critic(model, state)\n",
    "\n",
    "mask_logits = dist.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, 8)\n",
    "# idx = 0\n",
    "test_ids = gen_tokens[idx]\n",
    "test_mask = gen_attention_mask[idx]\n",
    "test_mask_prob = torch.sigmoid(mask_logits[idx])\n",
    "# inverse TODO\n",
    "# test_mask_prob = 1 - test_mask_prob\n",
    "test_context_mask = context_mask[idx]\n",
    "\n",
    "test_tokens = tokenizer.convert_ids_to_tokens(test_ids)\n",
    "scores = test_mask_prob * test_context_mask\n",
    "\n",
    "def normalize_except_zeros(array):\n",
    "    # Create a mask to identify non-zero elements\n",
    "    mask = (array > 0)\n",
    "    \n",
    "    # Extract non-zero elements\n",
    "    non_zero_elements = array[mask]\n",
    "    \n",
    "    # Normalize non-zero elements\n",
    "    min_val = np.min(non_zero_elements)\n",
    "    max_val = np.max(non_zero_elements)\n",
    "\n",
    "    normalized_non_zero_elements = (non_zero_elements - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Create a copy of the original array to preserve zero values\n",
    "    normalized_array = np.copy(array)\n",
    "    \n",
    "    # Assign normalized values back to the corresponding positions\n",
    "    normalized_array[mask] = normalized_non_zero_elements\n",
    "    \n",
    "    return normalized_array\n",
    "scores = normalize_except_zeros(scores.detach().cpu().numpy())\n",
    "\n",
    "# # remove special tokens\n",
    "# filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) if token not in tokenizer.all_special_tokens]\n",
    "filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|begin_of_text|>, Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: system, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: You, Score: 0.0\n",
      "Token: Ġare, Score: 0.0\n",
      "Token: Ġa, Score: 0.0\n",
      "Token: Ġchat, Score: 0.0\n",
      "Token: bot, Score: 0.0\n",
      "Token: Ġfor, Score: 0.0\n",
      "Token: Ġanswering, Score: 0.0\n",
      "Token: Ġquestions, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: ĠYour, Score: 0.0\n",
      "Token: Ġreply, Score: 0.0\n",
      "Token: Ġwith, Score: 0.0\n",
      "Token: Ġa, Score: 0.0\n",
      "Token: Ġshort, Score: 0.0\n",
      "Token: Ġanswer, Score: 0.0\n",
      "Token: Ġto, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġquestion, Score: 0.0\n",
      "Token: Ġprovided, Score: 0.0\n",
      "Token: Ġin, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġcontext, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: user, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: Question, Score: 0.05894096940755844\n",
      "Token: :, Score: 0.5631991624832153\n",
      "Token: ĠWhat, Score: 0.15373413264751434\n",
      "Token: Ġis, Score: 0.010523246601223946\n",
      "Token: Ġin, Score: 0.8960342407226562\n",
      "Token: Ġfront, Score: 0.3879421055316925\n",
      "Token: Ġof, Score: 0.2851405441761017\n",
      "Token: Ġthe, Score: 1.0\n",
      "Token: ĠNotre, Score: 0.008520049042999744\n",
      "Token: ĠDame, Score: 0.0799761638045311\n",
      "Token: ĠMain, Score: 0.04295910522341728\n",
      "Token: ĠBuilding, Score: 0.917119026184082\n",
      "Token: ?Ċ, Score: 0.9246863722801208\n",
      "Token: Context, Score: 0.006228600163012743\n",
      "Token: :, Score: 0.013302086852490902\n",
      "Token: ĠArchitect, Score: 0.0007514022290706635\n",
      "Token: urally, Score: 0.009651090018451214\n",
      "Token: ,, Score: 0.0046075149439275265\n",
      "Token: Ġthe, Score: 0.006200680509209633\n",
      "Token: Ġschool, Score: 0.021841784939169884\n",
      "Token: Ġhas, Score: 0.000860821339301765\n",
      "Token: Ġa, Score: 0.0025532208383083344\n",
      "Token: ĠCatholic, Score: 0.006397278048098087\n",
      "Token: Ġcharacter, Score: 0.00037173135206103325\n",
      "Token: ., Score: 0.06319165229797363\n",
      "Token: ĠAt, Score: 0.0023679700680077076\n",
      "Token: op, Score: 0.0007927551050670445\n",
      "Token: Ġthe, Score: 0.004025631118565798\n",
      "Token: ĠMain, Score: 0.0012131381081417203\n",
      "Token: ĠBuilding, Score: 0.007334501016885042\n",
      "Token: 's, Score: 0.003258242504671216\n",
      "Token: Ġgold, Score: 0.011928785592317581\n",
      "Token: Ġdome, Score: 0.007846898399293423\n",
      "Token: Ġis, Score: 0.0009753353660926223\n",
      "Token: Ġa, Score: 0.002493576379492879\n",
      "Token: Ġgolden, Score: 0.005015358794480562\n",
      "Token: Ġstatue, Score: 0.0013011796399950981\n",
      "Token: Ġof, Score: 0.004701549187302589\n",
      "Token: Ġthe, Score: 0.006839731242507696\n",
      "Token: ĠVirgin, Score: 0.0005172018427401781\n",
      "Token: ĠMary, Score: 0.001077314605936408\n",
      "Token: ., Score: 0.06934995949268341\n",
      "Token: ĠImmediately, Score: 0.0019285179441794753\n",
      "Token: Ġin, Score: 0.0003791946801356971\n",
      "Token: Ġfront, Score: 0.0028757585678249598\n",
      "Token: Ġof, Score: 0.00019796572451014072\n",
      "Token: Ġthe, Score: 0.0009166696108877659\n",
      "Token: ĠMain, Score: 0.0068810912780463696\n",
      "Token: ĠBuilding, Score: 0.0022256015799939632\n",
      "Token: Ġand, Score: 0.0017646910855546594\n",
      "Token: Ġfacing, Score: 0.012657699175179005\n",
      "Token: Ġit, Score: 0.0016509919660165906\n",
      "Token: ,, Score: 0.005789360497146845\n",
      "Token: Ġis, Score: 0.0011905129067599773\n",
      "Token: Ġa, Score: 0.0006216264446265996\n",
      "Token: Ġcopper, Score: 0.004586599767208099\n",
      "Token: Ġstatue, Score: 0.0007959336508065462\n",
      "Token: Ġof, Score: 0.004524243529886007\n",
      "Token: ĠChrist, Score: 0.0023739158641546965\n",
      "Token: Ġwith, Score: 0.0009405132732354105\n",
      "Token: Ġarms, Score: 0.0005422582617029548\n",
      "Token: Ġup, Score: 0.0010304833995178342\n",
      "Token: raised, Score: 0.0003584226651582867\n",
      "Token: Ġwith, Score: 0.00031587318517267704\n",
      "Token: Ġthe, Score: 0.0010081009240821004\n",
      "Token: Ġlegend, Score: 0.00216840673238039\n",
      "Token: Ġ\", Score: 0.022734934464097023\n",
      "Token: Ven, Score: 0.009507912211120129\n",
      "Token: ite, Score: 0.001114772050641477\n",
      "Token: ĠAd, Score: 0.0016702894354239106\n",
      "Token: ĠMe, Score: 0.002954567549750209\n",
      "Token: ĠOm, Score: 0.006348320282995701\n",
      "Token: nes, Score: 0.001586352358572185\n",
      "Token: \"., Score: 0.17710620164871216\n",
      "Token: ĠNext, Score: 0.008378774859011173\n",
      "Token: Ġto, Score: 0.0005666990182362497\n",
      "Token: Ġthe, Score: 0.0009804262081161141\n",
      "Token: ĠMain, Score: 0.0033628814853727818\n",
      "Token: ĠBuilding, Score: 0.004875034559518099\n",
      "Token: Ġis, Score: 0.002029458060860634\n",
      "Token: Ġthe, Score: 0.00620862003415823\n",
      "Token: ĠBasil, Score: 0.009058485738933086\n",
      "Token: ica, Score: 0.003321815514937043\n",
      "Token: Ġof, Score: 0.0016354889376088977\n",
      "Token: Ġthe, Score: 0.005331141408532858\n",
      "Token: ĠSacred, Score: 0.00039089005440473557\n",
      "Token: ĠHeart, Score: 0.004670852329581976\n",
      "Token: ., Score: 0.18062052130699158\n",
      "Token: ĠImmediately, Score: 0.0036934588570147753\n",
      "Token: Ġbehind, Score: 0.0011526987655088305\n",
      "Token: Ġthe, Score: 0.0004741269221995026\n",
      "Token: Ġbasil, Score: 0.01462473999708891\n",
      "Token: ica, Score: 0.003296996932476759\n",
      "Token: Ġis, Score: 0.0024666753597557545\n",
      "Token: Ġthe, Score: 0.009191752411425114\n",
      "Token: ĠG, Score: 0.09032707661390305\n",
      "Token: rot, Score: 0.01625770330429077\n",
      "Token: to, Score: 0.0015076245181262493\n",
      "Token: ,, Score: 0.0009426700999028981\n",
      "Token: Ġa, Score: 0.000391984183806926\n",
      "Token: ĠMarian, Score: 0.0007714394014328718\n",
      "Token: Ġplace, Score: 0.00016431594849564135\n",
      "Token: Ġof, Score: 0.0\n",
      "Token: Ġprayer, Score: 0.0003183665103279054\n",
      "Token: Ġand, Score: 1.4304159776656888e-05\n",
      "Token: Ġreflection, Score: 0.0007883625803515315\n",
      "Token: ., Score: 0.144569531083107\n",
      "Token: ĠIt, Score: 0.005368868820369244\n",
      "Token: Ġis, Score: 0.00045104947639629245\n",
      "Token: Ġa, Score: 0.0003083578194491565\n",
      "Token: Ġreplica, Score: 0.0016721183201298118\n",
      "Token: Ġof, Score: 0.0004637762322090566\n",
      "Token: Ġthe, Score: 0.0008224121411330998\n",
      "Token: Ġg, Score: 0.0032430374994874\n",
      "Token: rot, Score: 0.007773214485496283\n",
      "Token: to, Score: 0.002784518525004387\n",
      "Token: Ġat, Score: 0.0005163551541045308\n",
      "Token: ĠL, Score: 0.003980415873229504\n",
      "Token: our, Score: 0.004104164894670248\n",
      "Token: des, Score: 0.000315703684464097\n",
      "Token: ,, Score: 0.0004934259923174977\n",
      "Token: ĠFrance, Score: 0.0010394523851573467\n",
      "Token: Ġwhere, Score: 3.58914585376624e-05\n",
      "Token: Ġthe, Score: 0.00010410065442556515\n",
      "Token: ĠVirgin, Score: 3.314147761557251e-05\n",
      "Token: ĠMary, Score: 0.0004904426168650389\n",
      "Token: Ġreputed, Score: 0.00017702991317491978\n",
      "Token: ly, Score: 0.00035172863863408566\n",
      "Token: Ġappeared, Score: 0.0003019814030267298\n",
      "Token: Ġto, Score: 0.0002903951099142432\n",
      "Token: ĠSaint, Score: 0.0007144032279029489\n",
      "Token: ĠBern, Score: 0.0015909860376268625\n",
      "Token: ad, Score: 0.0036243977956473827\n",
      "Token: ette, Score: 0.00015389190230052918\n",
      "Token: ĠS, Score: 0.0005732214776799083\n",
      "Token: oub, Score: 0.004489355254918337\n",
      "Token: ir, Score: 0.002740065101534128\n",
      "Token: ous, Score: 0.0008542206487618387\n",
      "Token: Ġin, Score: 0.00020783561922144145\n",
      "Token: Ġ, Score: 0.00626017153263092\n",
      "Token: 185, Score: 0.018115568906068802\n",
      "Token: 8, Score: 0.0017422543605789542\n",
      "Token: ., Score: 0.11055542528629303\n",
      "Token: ĠAt, Score: 0.0005383678362704813\n",
      "Token: Ġthe, Score: 0.0008435403578914702\n",
      "Token: Ġend, Score: 0.004483499564230442\n",
      "Token: Ġof, Score: 0.0019671721383929253\n",
      "Token: Ġthe, Score: 0.005321003030985594\n",
      "Token: Ġmain, Score: 0.003331938525661826\n",
      "Token: Ġdrive, Score: 0.002246271353214979\n",
      "Token: Ġ(, Score: 0.03389691933989525\n",
      "Token: and, Score: 0.002568560652434826\n",
      "Token: Ġin, Score: 0.0005072283674962819\n",
      "Token: Ġa, Score: 0.0028325377497822046\n",
      "Token: Ġdirect, Score: 0.0016248521860688925\n",
      "Token: Ġline, Score: 0.0023343656212091446\n",
      "Token: Ġthat, Score: 0.007124317344278097\n",
      "Token: Ġconnects, Score: 0.0004874547303188592\n",
      "Token: Ġthrough, Score: 0.00036042011925019324\n",
      "Token: Ġ, Score: 0.012886634096503258\n",
      "Token: 3, Score: 0.013698979280889034\n",
      "Token: Ġstatues, Score: 0.0020432169549167156\n",
      "Token: Ġand, Score: 0.0006032278761267662\n",
      "Token: Ġthe, Score: 0.0018508518114686012\n",
      "Token: ĠGold, Score: 0.009137303568422794\n",
      "Token: ĠDome, Score: 0.004776895511895418\n",
      "Token: ),, Score: 0.002862141467630863\n",
      "Token: Ġis, Score: 0.0027643435169011354\n",
      "Token: Ġa, Score: 0.0008372579468414187\n",
      "Token: Ġsimple, Score: 0.00044903787784278393\n",
      "Token: ,, Score: 0.0005468188901431859\n",
      "Token: Ġmodern, Score: 0.0021898511331528425\n",
      "Token: Ġstone, Score: 0.00035168073372915387\n",
      "Token: Ġstatue, Score: 0.00035530258901417255\n",
      "Token: Ġof, Score: 0.0014416836202144623\n",
      "Token: ĠMary, Score: 0.0022155570331960917\n",
      "Token: ., Score: 0.11419672518968582\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: assistant, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: In, Score: 0.0\n",
      "Token: Ġfront, Score: 0.0\n",
      "Token: Ġof, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: ĠNotre, Score: 0.0\n",
      "Token: ĠDame, Score: 0.0\n",
      "Token: ĠMain, Score: 0.0\n",
      "Token: ĠBuilding, Score: 0.0\n",
      "Token: Ġis, Score: 0.0\n",
      "Token: Ġa, Score: 0.0\n",
      "Token: Ġcopper, Score: 0.0\n",
      "Token: Ġstatue, Score: 0.0\n",
      "Token: Ġof, Score: 0.0\n",
      "Token: ĠChrist, Score: 0.0\n",
      "Token: Ġwith, Score: 0.0\n",
      "Token: Ġarms, Score: 0.0\n",
      "Token: Ġup, Score: 0.0\n",
      "Token: raised, Score: 0.0\n",
      "Token: ,, Score: 0.0\n",
      "Token: Ġbearing, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġlegend, Score: 0.0\n",
      "Token: Ġ\", Score: 0.0\n",
      "Token: Ven, Score: 0.0\n",
      "Token: ite, Score: 0.0\n",
      "Token: ĠAd, Score: 0.0\n",
      "Token: ĠMe, Score: 0.0\n",
      "Token: ĠOm, Score: 0.0\n",
      "Token: nes, Score: 0.0\n",
      "Token: \"., Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "for token, score in filtered_token_scores:\n",
    "    print(f\"Token: {token}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|begin_of_text|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">system</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">You</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">are</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">a</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">chatbot</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">for</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">answering</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">questions.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Your</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">reply</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">with</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">a</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">short</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">answer</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">to</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">question</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">provided</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">in</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">context.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">user</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|end_header_id|></span> <span style=\"background-color: rgb(175, 255, 175); color: black;\">Question:</span> <span style=\"background-color: rgb(215, 255, 215); color: black;\">What</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">is</span> <span style=\"background-color: rgb(26, 255, 26); color: black;\">in</span> <span style=\"background-color: rgb(156, 255, 156); color: black;\">front</span> <span style=\"background-color: rgb(182, 255, 182); color: black;\">of</span> <span style=\"background-color: rgb(0, 255, 0); color: black;\">the</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">Notre</span> <span style=\"background-color: rgb(234, 255, 234); color: black;\">Dame</span> <span style=\"background-color: rgb(244, 255, 244); color: black;\">Main</span> <span style=\"background-color: rgb(136, 255, 136); color: black;\">Building?Context:</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">Architecturally,</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">the</span> <span style=\"background-color: rgb(249, 255, 249); color: black;\">school</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">has</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">Catholic</span> <span style=\"background-color: rgb(246, 255, 246); color: black;\">character.</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Atop</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Main</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">Building's</span> <span style=\"background-color: rgb(251, 255, 251); color: black;\">gold</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">dome</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">is</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">golden</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">statue</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">of</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Virgin</span> <span style=\"background-color: rgb(246, 255, 246); color: black;\">Mary.</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Immediately</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">in</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">front</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">of</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">Main</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Building</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">and</span> <span style=\"background-color: rgb(251, 255, 251); color: black;\">facing</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">it,</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">is</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">copper</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">statue</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">of</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Christ</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">with</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">arms</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">upraised</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">with</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">legend</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">\"Venite</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Ad</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Me</span> <span style=\"background-color: rgb(239, 255, 239); color: black;\">Omnes\".</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">Next</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">to</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Main</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">Building</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">is</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">the</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">Basilica</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">of</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Sacred</span> <span style=\"background-color: rgb(231, 255, 231); color: black;\">Heart.</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Immediately</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">behind</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">basilica</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">is</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">the</span> <span style=\"background-color: rgb(248, 255, 248); color: black;\">Grotto,</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Marian</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">place</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">of</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">prayer</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">and</span> <span style=\"background-color: rgb(236, 255, 236); color: black;\">reflection.</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">It</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">is</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">replica</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">of</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">grotto</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">at</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Lourdes,</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">France</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">where</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Virgin</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Mary</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">reputedly</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">appeared</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">to</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Saint</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Bernadette</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Soubirous</span> <span style=\"background-color: rgb(246, 255, 246); color: black;\">in1858.</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">At</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">end</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">of</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">the</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">main</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">drive</span> <span style=\"background-color: rgb(250, 255, 250); color: black;\">(and</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">in</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">direct</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">line</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">that</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">connects</span> <span style=\"background-color: rgb(253, 255, 253); color: black;\">through3</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">statues</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">and</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">the</span> <span style=\"background-color: rgb(252, 255, 252); color: black;\">Gold</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">Dome),</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">is</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">a</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">simple,</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">modern</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">stone</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">statue</span> <span style=\"background-color: rgb(254, 255, 254); color: black;\">of</span> <span style=\"background-color: rgb(240, 255, 240); color: black;\">Mary.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">assistant</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">In</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">front</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">of</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Notre</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Dame</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Main</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Building</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">is</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">a</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">copper</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">statue</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">of</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Christ</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">with</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">arms</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">upraised,</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">bearing</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">legend</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">\"Venite</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Ad</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Me</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Omnes\".</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_token(token):\n",
    "    # 移除所有普通的特殊字符，比如 'Ġ' 和 'Ċ'\n",
    "    return token.replace(\"Ġ\", \"\").replace(\"Ċ\", \"\")\n",
    "\n",
    "merged_tokens_scores = []\n",
    "current_token = \"\"\n",
    "current_score = 0\n",
    "count = 0\n",
    "\n",
    "def is_special_token(token):\n",
    "    # 判断是否是特殊的独立 token，例如 '<|start_header_id|>' 这样的 token\n",
    "    return token.startswith(\"<|\") and token.endswith(\"|>\")\n",
    "\n",
    "# 用于合并 token 和 score，取平均值\n",
    "for token, score in filtered_token_scores:\n",
    "    # 检查是否是特殊 token\n",
    "    if is_special_token(token):\n",
    "        # 如果当前有累积的 token，先把它们加入结果\n",
    "        if current_token:\n",
    "            # 确保分数归一化在 [0, 1] 之间\n",
    "            average_score = min(current_score / count, 1.0)\n",
    "            merged_tokens_scores.append((current_token, average_score))\n",
    "            current_token = \"\"\n",
    "            current_score = 0\n",
    "            count = 0\n",
    "\n",
    "        # 特殊 token 直接加入，不合并\n",
    "        merged_tokens_scores.append((token, score))\n",
    "        continue\n",
    "\n",
    "    # 清理 token 中的特殊字符\n",
    "    cleaned_token = clean_token(token)\n",
    "\n",
    "    # 忽略清理后的空 token\n",
    "    if not cleaned_token:\n",
    "        continue\n",
    "\n",
    "    # 判断是否是新单词的开始（以 'Ġ' 或 'Ċ' 开头的通常是新词）\n",
    "    if token.startswith(\"Ġ\") or token.startswith(\"Ċ\"):\n",
    "        if current_token:\n",
    "            # 确保分数归一化在 [0, 1] 之间\n",
    "            average_score = min(current_score / count, 1.0)\n",
    "            merged_tokens_scores.append((current_token, average_score))\n",
    "        \n",
    "        # 初始化新的 token 和 score\n",
    "        current_token = cleaned_token\n",
    "        current_score = score\n",
    "        count = 1\n",
    "    else:\n",
    "        # 如果是子词，则继续合并\n",
    "        current_token += cleaned_token\n",
    "        current_score += score\n",
    "        count += 1\n",
    "\n",
    "# 处理最后一个 token\n",
    "if current_token:\n",
    "    # 确保分数归一化在 [0, 1] 之间\n",
    "    average_score = min(current_score / count, 1.0)\n",
    "    merged_tokens_scores.append((current_token, average_score))\n",
    "\n",
    "# # 输出结果\n",
    "# for token, score in merged_tokens_scores:\n",
    "#     print(f\"Token: {token}, Score: {score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 根据分数高亮文本（示例中使用HTML标签）\n",
    "highlighted_text = \"\"\n",
    "for token, score in merged_tokens_scores:\n",
    "    # 动态设置背景颜色：score为0时为白色，score为1时为绿色\n",
    "    red = int((1 - score) * 255)\n",
    "    green = 255\n",
    "    blue = int((1 - score) * 255)\n",
    "    color = f'rgb({red}, {green}, {blue})'\n",
    "    highlighted_text += f'<span style=\"background-color: {color}; color: black;\">{token}</span> '\n",
    "\n",
    "# 打印高亮后的文本\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(highlighted_text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8213, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_mask_prob * test_context_mask).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs.keys()\n",
    "\n",
    "collate_fn()\n",
    "\n",
    "tokenizer(\"this is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = ds['train'].select(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data_dict = {\n",
    "    'text': [\"This is the first example.\", \"This is the second example.\"],\n",
    "    'label': [0, 1]\n",
    "}\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
