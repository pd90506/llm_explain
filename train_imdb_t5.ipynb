{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring environment parameters\n",
    "import os\n",
    "import json \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='log/app.log',            # Specify the log file name\n",
    "    level=logging.DEBUG,           # Set the log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Set the log format\n",
    ")\n",
    "\n",
    "# Load the environment configuration JSON data\n",
    "json_path = 'env_config.json'\n",
    "with open(json_path, 'r') as file:\n",
    "    env_config = json.load(file)\n",
    "\n",
    "hf_home = env_config['HF_HOME']\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ['HF_HOME'] = hf_home\n",
    "# Set the access token to huggingface hub\n",
    "access_token = env_config['access_token']\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary packages\n",
    "import transformers \n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, LlamaForTokenClassification #, LlamaRotaryEmbedding\n",
    "# from transformers import LlamaTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from llmexp.helper import DataHelper\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# TODO 注意load正确的模型\n",
    "from llmexp.imdb_model import MaskGeneratingModelForIMDB\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"google-t5/t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ds = load_dataset(\"imdb\")\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "# ds = load_dataset(\"stanfordnlp/sst2\")\n",
    "train_ds = ds['train']\n",
    "# test_ds = ds['test']\n",
    "test_ds = ds['validation']\n",
    "\n",
    "llm_exp_helper = DataHelper(tokenizer)\n",
    "# collate_fn = llm_exp_helper.get_collate_fun('imdb')\n",
    "# collate_fn = llm_exp_helper.get_collate_fun('sst2')\n",
    "collate_fn = llm_exp_helper.get_collate_fun('squad')\n",
    "\n",
    "# Define batch size here!\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd70e9acb9b74864853039881c6664ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure and load model\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B\"  # non-instruct version\n",
    "\n",
    "# how to use the quant version?\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=torch.float32,\n",
    "    # device_map=\"auto\",\n",
    "    device_map=device,\n",
    "    token=access_token,\n",
    "    # load_in_4bit=True,\n",
    ")\n",
    "\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure mask model and  Training parameters\n",
    "mask_gen_model = MaskGeneratingModelForIMDB()\n",
    "mask_gen_model.to(device)\n",
    "\n",
    "# Set pad_token_id if it is not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(mask_gen_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        ...,\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271],\n",
       "        [128009, 128009, 128009,  ...,  78191, 128007,    271]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]]), 'context_mask': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5475 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: tensor(0.3830, device='cuda:0') factor: tensor(0.4684, device='cuda:0')\n",
      "reward: tensor(0.3300, device='cuda:0') factor: tensor(0.4986, device='cuda:0')\n",
      "reward: tensor(0.4267, device='cuda:0') factor: tensor(0.4882, device='cuda:0')\n",
      "ratio tensor(1.0000, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1: Loss = 0.4115, Actor Loss = 0.0657, Critic Loss = 0.6928, Entropy = 0.6050, Returns = 1.2230, Value = 1.1058, mask_loss = 0.7042std_loss = 0.0208:   0%|          | 1/5475 [01:23<127:12:04, 83.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio tensor(6.7789e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "reward: tensor(0.4398, device='cuda:0') factor: tensor(0.7843, device='cuda:0')\n",
      "reward: tensor(0.4329, device='cuda:0') factor: tensor(0.7613, device='cuda:0')\n",
      "reward: tensor(0.4620, device='cuda:0') factor: tensor(0.7709, device='cuda:0')\n",
      "ratio tensor(1.0000, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask_gen_model.train()\n",
    "for epoch in range(1):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        context_mask = data['context_mask'].to(device)\n",
    "        # get generated texts\n",
    "        gen_outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "        gen_tokens = gen_outputs.sequences\n",
    "        pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "        # get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "        gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "        # (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "        unpaded_token_mask = (gen_tokens != tokenizer.pad_token_id).long()\n",
    "        unpaded_token_mask[:, :-pad_length] = 1\n",
    "        gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "\n",
    "        # get the response mask, which is the mask for the generated tokens (the user inputs are masked with 0)\n",
    "        response_mask = gen_attention_mask.clone()\n",
    "        response_mask[:, :-pad_length] = 0 # TODO: 有问题. 有问题吗？\n",
    "\n",
    "        context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "        loss_dict = mask_gen_model.train_one_batch(model, gen_tokens, gen_attention_mask, context_mask, response_mask, optimizer,\n",
    "                                                   num_steps=3, mini_batch_size=32, ppo_epochs=2)\n",
    "\n",
    "\n",
    "        log = f\"Epoch {epoch+1}, Step {idx+1}: Loss = {loss_dict['loss']:.4f}, \" \\\n",
    "               f\"Actor Loss = {loss_dict['actor_loss']:.4f}, \" \\\n",
    "               f\"Critic Loss = {loss_dict['critic_loss']:.4f}, \" \\\n",
    "               f\"Entropy = {loss_dict['entropy']:.4f}, \" \\\n",
    "               f\"Returns = {loss_dict['returns']:.4f}, \" \\\n",
    "               f\"Value = {loss_dict['value']:.4f}, \" \\\n",
    "                f\"mask_loss = {loss_dict['mask_loss']:.4f}\" \\\n",
    "                f\"std_loss = {loss_dict['std_loss']:.4f}\" \\\n",
    "            #    f\"Cont_loss = {loss_dict['contrast_loss']:.4f}, \"  \\\n",
    "               \n",
    "        pbar.set_description(log)\n",
    "\n",
    "        # if idx % 1 == 0:\n",
    "        #     print()\n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            torch.save(mask_gen_model.state_dict(), f'saved_model/imdb_mask_gen_model_{epoch}_{idx}.pth') \n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "\n",
    "# mask_gen_model.load_state_dict(torch.load('saved_model/imdb_mask_gen_model_0_40.pth',map_location=device))\n",
    "\n",
    "mask_gen_model.eval()\n",
    "\n",
    "test_inputs = next(iter(test_dataloader)).to(device)\n",
    "# test_inputs = next(iter(train_dataloader)).to(device)\n",
    "\n",
    "# tokens = tokenizer.convert_ids_to_tokens(test_inputs['input_ids'][idx])\n",
    "\n",
    "\n",
    "\n",
    "# data_dict = {\n",
    "#     'sentence': [\"I absolutely love this product! It exceeded all my expectations.\", \n",
    "#              \"The movie was fantastic, and the acting was top-notch.\",\n",
    "#              \"This restaurant offers great service and delicious food. Highly recommend!\",\n",
    "#              \"The product works as advertised, nothing more, nothing less.\",\n",
    "#              \"The event was well-organized, but it didn’t leave a lasting impression.\",\n",
    "#              \"t’s an average phone, nothing special but it does the job.\",\n",
    "#              \"I’m really disappointed with this purchase. It broke within a week.\",\n",
    "#              \"The movie was too long and boring, I wouldn’t recommend it.\",\n",
    "#              \"Terrible customer service, I won’t be coming back to this place.\"],\n",
    "#     'label': [1, 1, 1, 0, 0, 0, -1, -1, -1]\n",
    "# }\n",
    "# manual_test_data = Dataset.from_dict(data_dict)\n",
    "\n",
    "# manual_test_dataloader = DataLoader(manual_test_data, batch_size=9, collate_fn=collate_fn, shuffle=False)\n",
    "# #\n",
    "# test_inputs = next(iter(manual_test_dataloader)).to(device)\n",
    "\n",
    "\n",
    "# generate the answer for the test inputs\n",
    "gen_outputs = model.generate(\n",
    "            input_ids=test_inputs['input_ids'],\n",
    "            attention_mask=test_inputs['attention_mask'],\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "input_ids = test_inputs['input_ids']\n",
    "attention_mask = test_inputs['attention_mask']\n",
    "gen_tokens = gen_outputs.sequences\n",
    "pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "# get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "context_mask = F.pad(test_inputs['context_mask'], (0, pad_length), mode='constant', value=0)\n",
    "# (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "unpaded_token_mask = (gen_tokens != tokenizer.pad_token_id).long()\n",
    "unpaded_token_mask[:, :-pad_length] = 1\n",
    "gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "\n",
    "response_mask = gen_attention_mask.clone()\n",
    "response_mask[:, :-pad_length] = 0 # TODO: 有问题. 有问题吗？\n",
    "\n",
    "# context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # prompt_outputs = model(input_ids=test_inputs['input_ids'], attention_mask=test_inputs['attention_mask'], output_hidden_states=True, return_dict=True)\n",
    "#     prompt_outputs = model(input_ids=gen_tokens, attention_mask=gen_attention_mask, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "#     last_hidden_state = prompt_outputs.hidden_states[-1].float()\n",
    "#     mask_logits = mask_gen_model(last_hidden_state)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    state = gen_tokens, gen_attention_mask, context_mask, response_mask\n",
    "    dist, value = mask_gen_model.get_dist_critic(model, state)\n",
    "\n",
    "mask_logits = dist.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|begin_of_text|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">system</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">You</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">are</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">a</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">chatbot</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">for</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">answering</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">questions.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Your</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">reply</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">with</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">answer</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">to</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">question</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">in</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">context.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">user</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|end_header_id|></span> <span style=\"background-color: rgb(216, 255, 216); color: black;\">Question:</span> <span style=\"background-color: rgb(239, 255, 239); color: black;\">What</span> <span style=\"background-color: rgb(200, 255, 200); color: black;\">sits</span> <span style=\"background-color: rgb(67, 255, 67); color: black;\">on</span> <span style=\"background-color: rgb(152, 255, 152); color: black;\">top</span> <span style=\"background-color: rgb(0, 255, 0); color: black;\">of</span> <span style=\"background-color: rgb(66, 255, 66); color: black;\">the</span> <span style=\"background-color: rgb(141, 255, 141); color: black;\">Main</span> <span style=\"background-color: rgb(193, 255, 193); color: black;\">Building</span> <span style=\"background-color: rgb(70, 255, 70); color: black;\">at</span> <span style=\"background-color: rgb(190, 255, 190); color: black;\">Notre</span> <span style=\"background-color: rgb(192, 255, 192); color: black;\">Dame?Context:</span> <span style=\"background-color: rgb(194, 255, 194); color: black;\">Architecturally,</span> <span style=\"background-color: rgb(213, 255, 213); color: black;\">the</span> <span style=\"background-color: rgb(163, 255, 163); color: black;\">school</span> <span style=\"background-color: rgb(184, 255, 184); color: black;\">has</span> <span style=\"background-color: rgb(173, 255, 173); color: black;\">a</span> <span style=\"background-color: rgb(130, 255, 130); color: black;\">Catholic</span> <span style=\"background-color: rgb(219, 255, 219); color: black;\">character.</span> <span style=\"background-color: rgb(174, 255, 174); color: black;\">Atop</span> <span style=\"background-color: rgb(179, 255, 179); color: black;\">the</span> <span style=\"background-color: rgb(150, 255, 150); color: black;\">Main</span> <span style=\"background-color: rgb(182, 255, 182); color: black;\">Building's</span> <span style=\"background-color: rgb(141, 255, 141); color: black;\">gold</span> <span style=\"background-color: rgb(194, 255, 194); color: black;\">dome</span> <span style=\"background-color: rgb(200, 255, 200); color: black;\">is</span> <span style=\"background-color: rgb(201, 255, 201); color: black;\">a</span> <span style=\"background-color: rgb(137, 255, 137); color: black;\">golden</span> <span style=\"background-color: rgb(208, 255, 208); color: black;\">statue</span> <span style=\"background-color: rgb(122, 255, 122); color: black;\">of</span> <span style=\"background-color: rgb(129, 255, 129); color: black;\">the</span> <span style=\"background-color: rgb(141, 255, 141); color: black;\">Virgin</span> <span style=\"background-color: rgb(206, 255, 206); color: black;\">Mary.</span> <span style=\"background-color: rgb(244, 255, 244); color: black;\">Immediately</span> <span style=\"background-color: rgb(157, 255, 157); color: black;\">in</span> <span style=\"background-color: rgb(169, 255, 169); color: black;\">front</span> <span style=\"background-color: rgb(106, 255, 106); color: black;\">of</span> <span style=\"background-color: rgb(114, 255, 114); color: black;\">the</span> <span style=\"background-color: rgb(125, 255, 125); color: black;\">Main</span> <span style=\"background-color: rgb(180, 255, 180); color: black;\">Building</span> <span style=\"background-color: rgb(192, 255, 192); color: black;\">and</span> <span style=\"background-color: rgb(113, 255, 113); color: black;\">facing</span> <span style=\"background-color: rgb(170, 255, 170); color: black;\">it,</span> <span style=\"background-color: rgb(144, 255, 144); color: black;\">is</span> <span style=\"background-color: rgb(173, 255, 173); color: black;\">a</span> <span style=\"background-color: rgb(134, 255, 134); color: black;\">copper</span> <span style=\"background-color: rgb(200, 255, 200); color: black;\">statue</span> <span style=\"background-color: rgb(69, 255, 69); color: black;\">of</span> <span style=\"background-color: rgb(196, 255, 196); color: black;\">Christ</span> <span style=\"background-color: rgb(106, 255, 106); color: black;\">with</span> <span style=\"background-color: rgb(158, 255, 158); color: black;\">arms</span> <span style=\"background-color: rgb(179, 255, 179); color: black;\">upraised</span> <span style=\"background-color: rgb(143, 255, 143); color: black;\">with</span> <span style=\"background-color: rgb(186, 255, 186); color: black;\">the</span> <span style=\"background-color: rgb(250, 255, 250); color: black;\">legend</span> <span style=\"background-color: rgb(172, 255, 172); color: black;\">\"Venite</span> <span style=\"background-color: rgb(182, 255, 182); color: black;\">Ad</span> <span style=\"background-color: rgb(165, 255, 165); color: black;\">Me</span> <span style=\"background-color: rgb(193, 255, 193); color: black;\">Omnes\".</span> <span style=\"background-color: rgb(195, 255, 195); color: black;\">Next</span> <span style=\"background-color: rgb(164, 255, 164); color: black;\">to</span> <span style=\"background-color: rgb(129, 255, 129); color: black;\">the</span> <span style=\"background-color: rgb(174, 255, 174); color: black;\">Main</span> <span style=\"background-color: rgb(189, 255, 189); color: black;\">Building</span> <span style=\"background-color: rgb(153, 255, 153); color: black;\">is</span> <span style=\"background-color: rgb(118, 255, 118); color: black;\">the</span> <span style=\"background-color: rgb(121, 255, 121); color: black;\">Basilica</span> <span style=\"background-color: rgb(122, 255, 122); color: black;\">of</span> <span style=\"background-color: rgb(127, 255, 127); color: black;\">the</span> <span style=\"background-color: rgb(192, 255, 192); color: black;\">Sacred</span> <span style=\"background-color: rgb(202, 255, 202); color: black;\">Heart.</span> <span style=\"background-color: rgb(221, 255, 221); color: black;\">Immediately</span> <span style=\"background-color: rgb(157, 255, 157); color: black;\">behind</span> <span style=\"background-color: rgb(158, 255, 158); color: black;\">the</span> <span style=\"background-color: rgb(144, 255, 144); color: black;\">basilica</span> <span style=\"background-color: rgb(151, 255, 151); color: black;\">is</span> <span style=\"background-color: rgb(89, 255, 89); color: black;\">the</span> <span style=\"background-color: rgb(154, 255, 154); color: black;\">Grotto,</span> <span style=\"background-color: rgb(178, 255, 178); color: black;\">a</span> <span style=\"background-color: rgb(132, 255, 132); color: black;\">Marian</span> <span style=\"background-color: rgb(179, 255, 179); color: black;\">place</span> <span style=\"background-color: rgb(152, 255, 152); color: black;\">of</span> <span style=\"background-color: rgb(216, 255, 216); color: black;\">prayer</span> <span style=\"background-color: rgb(133, 255, 133); color: black;\">and</span> <span style=\"background-color: rgb(239, 255, 239); color: black;\">reflection.</span> <span style=\"background-color: rgb(197, 255, 197); color: black;\">It</span> <span style=\"background-color: rgb(237, 255, 237); color: black;\">is</span> <span style=\"background-color: rgb(195, 255, 195); color: black;\">a</span> <span style=\"background-color: rgb(168, 255, 168); color: black;\">replica</span> <span style=\"background-color: rgb(158, 255, 158); color: black;\">of</span> <span style=\"background-color: rgb(165, 255, 165); color: black;\">the</span> <span style=\"background-color: rgb(184, 255, 184); color: black;\">grotto</span> <span style=\"background-color: rgb(193, 255, 193); color: black;\">at</span> <span style=\"background-color: rgb(210, 255, 210); color: black;\">Lourdes,</span> <span style=\"background-color: rgb(223, 255, 223); color: black;\">France</span> <span style=\"background-color: rgb(114, 255, 114); color: black;\">where</span> <span style=\"background-color: rgb(167, 255, 167); color: black;\">the</span> <span style=\"background-color: rgb(132, 255, 132); color: black;\">Virgin</span> <span style=\"background-color: rgb(150, 255, 150); color: black;\">Mary</span> <span style=\"background-color: rgb(172, 255, 172); color: black;\">reputedly</span> <span style=\"background-color: rgb(179, 255, 179); color: black;\">appeared</span> <span style=\"background-color: rgb(133, 255, 133); color: black;\">to</span> <span style=\"background-color: rgb(153, 255, 153); color: black;\">Saint</span> <span style=\"background-color: rgb(164, 255, 164); color: black;\">Bernadette</span> <span style=\"background-color: rgb(208, 255, 208); color: black;\">Soubirous</span> <span style=\"background-color: rgb(210, 255, 210); color: black;\">in1858.</span> <span style=\"background-color: rgb(179, 255, 179); color: black;\">At</span> <span style=\"background-color: rgb(129, 255, 129); color: black;\">the</span> <span style=\"background-color: rgb(214, 255, 214); color: black;\">end</span> <span style=\"background-color: rgb(225, 255, 225); color: black;\">of</span> <span style=\"background-color: rgb(211, 255, 211); color: black;\">the</span> <span style=\"background-color: rgb(206, 255, 206); color: black;\">main</span> <span style=\"background-color: rgb(207, 255, 207); color: black;\">drive</span> <span style=\"background-color: rgb(179, 255, 179); color: black;\">(and</span> <span style=\"background-color: rgb(161, 255, 161); color: black;\">in</span> <span style=\"background-color: rgb(182, 255, 182); color: black;\">a</span> <span style=\"background-color: rgb(104, 255, 104); color: black;\">direct</span> <span style=\"background-color: rgb(178, 255, 178); color: black;\">line</span> <span style=\"background-color: rgb(151, 255, 151); color: black;\">that</span> <span style=\"background-color: rgb(163, 255, 163); color: black;\">connects</span> <span style=\"background-color: rgb(167, 255, 167); color: black;\">through3</span> <span style=\"background-color: rgb(143, 255, 143); color: black;\">statues</span> <span style=\"background-color: rgb(134, 255, 134); color: black;\">and</span> <span style=\"background-color: rgb(124, 255, 124); color: black;\">the</span> <span style=\"background-color: rgb(99, 255, 99); color: black;\">Gold</span> <span style=\"background-color: rgb(160, 255, 160); color: black;\">Dome),</span> <span style=\"background-color: rgb(147, 255, 147); color: black;\">is</span> <span style=\"background-color: rgb(137, 255, 137); color: black;\">a</span> <span style=\"background-color: rgb(158, 255, 158); color: black;\">simple,</span> <span style=\"background-color: rgb(170, 255, 170); color: black;\">modern</span> <span style=\"background-color: rgb(166, 255, 166); color: black;\">stone</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">statue</span> <span style=\"background-color: rgb(98, 255, 98); color: black;\">of</span> <span style=\"background-color: rgb(169, 255, 169); color: black;\">Mary.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">assistant</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">According</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">to</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">context,</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">golden</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">statue</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">of</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Virgin</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Mary</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">sits</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">on</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">top</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">of</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Main</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Building</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">at</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Notre</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Dame.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><|eot_id|></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, 8)\n",
    "test_ids = gen_tokens[idx]\n",
    "test_mask = gen_attention_mask[idx]\n",
    "test_mask_prob = torch.sigmoid(mask_logits[idx])\n",
    "# inverse TODO\n",
    "# test_mask_prob = 1 - test_mask_prob\n",
    "test_context_mask = context_mask[idx]\n",
    "\n",
    "test_tokens = tokenizer.convert_ids_to_tokens(test_ids)\n",
    "scores = test_mask_prob * test_context_mask\n",
    "\n",
    "def normalize_except_zeros(array):\n",
    "    # Create a mask to identify non-zero elements\n",
    "    mask = (array > 0)\n",
    "    \n",
    "    # Extract non-zero elements\n",
    "    non_zero_elements = array[mask]\n",
    "    \n",
    "    # Normalize non-zero elements\n",
    "    min_val = np.min(non_zero_elements)\n",
    "    max_val = np.max(non_zero_elements)\n",
    "\n",
    "    normalized_non_zero_elements = (non_zero_elements - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Create a copy of the original array to preserve zero values\n",
    "    normalized_array = np.copy(array)\n",
    "    \n",
    "    # Assign normalized values back to the corresponding positions\n",
    "    normalized_array[mask] = normalized_non_zero_elements\n",
    "    \n",
    "    return normalized_array\n",
    "scores = normalize_except_zeros(scores.detach().cpu().numpy())\n",
    "\n",
    "# # remove special tokens\n",
    "# filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) if token not in tokenizer.all_special_tokens]\n",
    "filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_token(token):\n",
    "    # 移除所有普通的特殊字符，比如 'Ġ' 和 'Ċ'\n",
    "    return token.replace(\"Ġ\", \"\").replace(\"Ċ\", \"\")\n",
    "\n",
    "merged_tokens_scores = []\n",
    "current_token = \"\"\n",
    "current_score = 0\n",
    "count = 0\n",
    "\n",
    "def is_special_token(token):\n",
    "    # 判断是否是特殊的独立 token，例如 '<|start_header_id|>' 这样的 token\n",
    "    return token.startswith(\"<|\") and token.endswith(\"|>\")\n",
    "\n",
    "# 用于合并 token 和 score，取平均值\n",
    "for token, score in filtered_token_scores:\n",
    "    # 检查是否是特殊 token\n",
    "    if is_special_token(token):\n",
    "        # 如果当前有累积的 token，先把它们加入结果\n",
    "        if current_token:\n",
    "            # 确保分数归一化在 [0, 1] 之间\n",
    "            average_score = min(current_score / count, 1.0)\n",
    "            merged_tokens_scores.append((current_token, average_score))\n",
    "            current_token = \"\"\n",
    "            current_score = 0\n",
    "            count = 0\n",
    "\n",
    "        # 特殊 token 直接加入，不合并\n",
    "        merged_tokens_scores.append((token, score))\n",
    "        continue\n",
    "\n",
    "    # 清理 token 中的特殊字符\n",
    "    cleaned_token = clean_token(token)\n",
    "\n",
    "    # 忽略清理后的空 token\n",
    "    if not cleaned_token:\n",
    "        continue\n",
    "\n",
    "    # 判断是否是新单词的开始（以 'Ġ' 或 'Ċ' 开头的通常是新词）\n",
    "    if token.startswith(\"Ġ\") or token.startswith(\"Ċ\"):\n",
    "        if current_token:\n",
    "            # 确保分数归一化在 [0, 1] 之间\n",
    "            average_score = min(current_score / count, 1.0)\n",
    "            merged_tokens_scores.append((current_token, average_score))\n",
    "        \n",
    "        # 初始化新的 token 和 score\n",
    "        current_token = cleaned_token\n",
    "        current_score = score\n",
    "        count = 1\n",
    "    else:\n",
    "        # 如果是子词，则继续合并\n",
    "        current_token += cleaned_token\n",
    "        current_score += score\n",
    "        count += 1\n",
    "\n",
    "# 处理最后一个 token\n",
    "if current_token:\n",
    "    # 确保分数归一化在 [0, 1] 之间\n",
    "    average_score = min(current_score / count, 1.0)\n",
    "    merged_tokens_scores.append((current_token, average_score))\n",
    "\n",
    "# # 输出结果\n",
    "# for token, score in merged_tokens_scores:\n",
    "#     print(f\"Token: {token}, Score: {score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 根据分数高亮文本（示例中使用HTML标签）\n",
    "highlighted_text = \"\"\n",
    "for token, score in merged_tokens_scores:\n",
    "    # 动态设置背景颜色：score为0时为白色，score为1时为绿色\n",
    "    red = int((1 - score) * 255)\n",
    "    green = 255\n",
    "    blue = int((1 - score) * 255)\n",
    "    color = f'rgb({red}, {green}, {blue})'\n",
    "    highlighted_text += f'<span style=\"background-color: {color}; color: black;\">{token}</span> '\n",
    "\n",
    "# 打印高亮后的文本\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(highlighted_text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|begin_of_text|>, Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: system, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: You, Score: 0.0\n",
      "Token: Ġare, Score: 0.0\n",
      "Token: Ġa, Score: 0.0\n",
      "Token: Ġchat, Score: 0.0\n",
      "Token: bot, Score: 0.0\n",
      "Token: Ġfor, Score: 0.0\n",
      "Token: Ġanswering, Score: 0.0\n",
      "Token: Ġquestions, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: ĠYour, Score: 0.0\n",
      "Token: Ġreply, Score: 0.0\n",
      "Token: Ġwith, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġanswer, Score: 0.0\n",
      "Token: Ġto, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġquestion, Score: 0.0\n",
      "Token: Ġin, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġcontext, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: user, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: Question, Score: 0.7133389115333557\n",
      "Token: :, Score: 0.7092896699905396\n",
      "Token: ĠHow, Score: 0.3258957862854004\n",
      "Token: Ġmany, Score: 0.1920238435268402\n",
      "Token: Ġstudent, Score: 0.7921452522277832\n",
      "Token: Ġnews, Score: 0.6680269241333008\n",
      "Token: Ġpapers, Score: 0.6519895792007446\n",
      "Token: Ġare, Score: 0.7358902096748352\n",
      "Token: Ġfound, Score: 0.8161467909812927\n",
      "Token: Ġat, Score: 0.22713488340377808\n",
      "Token: ĠNotre, Score: 0.4331718385219574\n",
      "Token: ĠDame, Score: 0.8070284724235535\n",
      "Token: ?Ċ, Score: 0.7487039566040039\n",
      "Token: Context, Score: 0.36952582001686096\n",
      "Token: :, Score: 0.5008003115653992\n",
      "Token: ĠAs, Score: 0.504429817199707\n",
      "Token: Ġat, Score: 0.23810704052448273\n",
      "Token: Ġmost, Score: 0.41389402747154236\n",
      "Token: Ġother, Score: 0.5311117172241211\n",
      "Token: Ġuniversities, Score: 0.8440494537353516\n",
      "Token: ,, Score: 0.3687707483768463\n",
      "Token: ĠNotre, Score: 0.5459681153297424\n",
      "Token: ĠDame, Score: 0.6424822211265564\n",
      "Token: 's, Score: 0.5339277982711792\n",
      "Token: Ġstudents, Score: 0.7836216688156128\n",
      "Token: Ġrun, Score: 0.4652549624443054\n",
      "Token: Ġa, Score: 0.4372740089893341\n",
      "Token: Ġnumber, Score: 0.7661125659942627\n",
      "Token: Ġof, Score: 0.6806610822677612\n",
      "Token: Ġnews, Score: 0.7757472395896912\n",
      "Token: Ġmedia, Score: 0.816373884677887\n",
      "Token: Ġoutlets, Score: 0.9442552328109741\n",
      "Token: ., Score: 0.8066878318786621\n",
      "Token: ĠThe, Score: 0.6460795402526855\n",
      "Token: Ġnine, Score: 0.8644997477531433\n",
      "Token: Ġstudent, Score: 0.7854640483856201\n",
      "Token: -run, Score: 0.7454727292060852\n",
      "Token: Ġoutlets, Score: 0.8308504819869995\n",
      "Token: Ġinclude, Score: 0.8251990675926208\n",
      "Token: Ġthree, Score: 0.7883829474449158\n",
      "Token: Ġnewspapers, Score: 0.9656087160110474\n",
      "Token: ,, Score: 0.787926435470581\n",
      "Token: Ġboth, Score: 0.8169425129890442\n",
      "Token: Ġa, Score: 0.6863846778869629\n",
      "Token: Ġradio, Score: 0.7673417925834656\n",
      "Token: Ġand, Score: 0.734693169593811\n",
      "Token: Ġtelevision, Score: 0.7121940851211548\n",
      "Token: Ġstation, Score: 0.9811449646949768\n",
      "Token: ,, Score: 0.8295890092849731\n",
      "Token: Ġand, Score: 0.6217188835144043\n",
      "Token: Ġseveral, Score: 0.7427685856819153\n",
      "Token: Ġmagazines, Score: 0.9867626428604126\n",
      "Token: Ġand, Score: 0.6220703125\n",
      "Token: Ġjournals, Score: 0.9836158156394958\n",
      "Token: ., Score: 0.815376341342926\n",
      "Token: ĠBeg, Score: 0.8381279110908508\n",
      "Token: un, Score: 0.8933025002479553\n",
      "Token: Ġas, Score: 0.7028563618659973\n",
      "Token: Ġa, Score: 0.6370502710342407\n",
      "Token: Ġone, Score: 0.7710503339767456\n",
      "Token: -page, Score: 0.4478057324886322\n",
      "Token: Ġjournal, Score: 0.9351155161857605\n",
      "Token: Ġin, Score: 0.6660817265510559\n",
      "Token: ĠSeptember, Score: 0.8297600746154785\n",
      "Token: Ġ, Score: 0.30277207493782043\n",
      "Token: 187, Score: 0.04130806401371956\n",
      "Token: 6, Score: 0.9824410080909729\n",
      "Token: ,, Score: 0.8392037153244019\n",
      "Token: Ġthe, Score: 0.5859525203704834\n",
      "Token: ĠSch, Score: 0.3614733815193176\n",
      "Token: ol, Score: 0.35361048579216003\n",
      "Token: astic, Score: 0.822892427444458\n",
      "Token: Ġmagazine, Score: 0.9854098558425903\n",
      "Token: Ġis, Score: 0.8984928131103516\n",
      "Token: Ġissued, Score: 0.5803102850914001\n",
      "Token: Ġtwice, Score: 0.7342619299888611\n",
      "Token: Ġmonthly, Score: 0.9108960628509521\n",
      "Token: Ġand, Score: 0.6937833428382874\n",
      "Token: Ġclaims, Score: 0.7652638554573059\n",
      "Token: Ġto, Score: 0.7065955996513367\n",
      "Token: Ġbe, Score: 0.8090159296989441\n",
      "Token: Ġthe, Score: 0.7082353830337524\n",
      "Token: Ġoldest, Score: 0.7098844051361084\n",
      "Token: Ġcontinuous, Score: 0.6599606275558472\n",
      "Token: Ġcollegiate, Score: 0.6441090106964111\n",
      "Token: Ġpublication, Score: 0.9936403036117554\n",
      "Token: Ġin, Score: 0.5926966667175293\n",
      "Token: Ġthe, Score: 0.5529193878173828\n",
      "Token: ĠUnited, Score: 0.4812324643135071\n",
      "Token: ĠStates, Score: 1.0\n",
      "Token: ., Score: 0.8086414337158203\n",
      "Token: ĠThe, Score: 0.48425039649009705\n",
      "Token: Ġother, Score: 0.651616632938385\n",
      "Token: Ġmagazine, Score: 0.7907425165176392\n",
      "Token: ,, Score: 0.5033501982688904\n",
      "Token: ĠThe, Score: 0.022504465654492378\n",
      "Token: ĠJ, Score: 0.0\n",
      "Token: ugg, Score: 0.21534781157970428\n",
      "Token: ler, Score: 0.6310120820999146\n",
      "Token: ,, Score: 0.6432710886001587\n",
      "Token: Ġis, Score: 0.7010692358016968\n",
      "Token: Ġreleased, Score: 0.3829956650733948\n",
      "Token: Ġtwice, Score: 0.584166944026947\n",
      "Token: Ġa, Score: 0.3445259630680084\n",
      "Token: Ġyear, Score: 0.9668272733688354\n",
      "Token: Ġand, Score: 0.618474543094635\n",
      "Token: Ġfocuses, Score: 0.751868486404419\n",
      "Token: Ġon, Score: 0.5398547053337097\n",
      "Token: Ġstudent, Score: 0.7776280045509338\n",
      "Token: Ġliterature, Score: 0.9981814026832581\n",
      "Token: Ġand, Score: 0.6610096096992493\n",
      "Token: Ġartwork, Score: 0.9807029962539673\n",
      "Token: ., Score: 0.8096382021903992\n",
      "Token: ĠThe, Score: 0.5729453563690186\n",
      "Token: ĠDome, Score: 0.42160269618034363\n",
      "Token: Ġyear, Score: 0.5797041058540344\n",
      "Token: book, Score: 0.8305489420890808\n",
      "Token: Ġis, Score: 0.8048155307769775\n",
      "Token: Ġpublished, Score: 0.588589072227478\n",
      "Token: Ġannually, Score: 0.9370752573013306\n",
      "Token: ., Score: 0.7911008596420288\n",
      "Token: ĠThe, Score: 0.4661688804626465\n",
      "Token: Ġnewspapers, Score: 0.7078862190246582\n",
      "Token: Ġhave, Score: 0.7107353806495667\n",
      "Token: Ġvarying, Score: 0.5865824818611145\n",
      "Token: Ġpublication, Score: 0.534619927406311\n",
      "Token: Ġinterests, Score: 0.9110686779022217\n",
      "Token: ,, Score: 0.6772403120994568\n",
      "Token: Ġwith, Score: 0.512978732585907\n",
      "Token: ĠThe, Score: 0.05611153319478035\n",
      "Token: ĠObserver, Score: 0.7441628575325012\n",
      "Token: Ġpublished, Score: 0.5129334926605225\n",
      "Token: Ġdaily, Score: 0.8225616812705994\n",
      "Token: Ġand, Score: 0.5294565558433533\n",
      "Token: Ġmainly, Score: 0.6146439909934998\n",
      "Token: Ġreporting, Score: 0.43653661012649536\n",
      "Token: Ġuniversity, Score: 0.6716732978820801\n",
      "Token: Ġand, Score: 0.1640244722366333\n",
      "Token: Ġother, Score: 0.3986424207687378\n",
      "Token: Ġnews, Score: 0.7698571681976318\n",
      "Token: ,, Score: 0.6778396368026733\n",
      "Token: Ġand, Score: 0.46988123655319214\n",
      "Token: Ġstaff, Score: 0.6077755689620972\n",
      "Token: ed, Score: 0.6377232074737549\n",
      "Token: Ġby, Score: 0.5614859461784363\n",
      "Token: Ġstudents, Score: 0.7906143665313721\n",
      "Token: Ġfrom, Score: 0.3926694691181183\n",
      "Token: Ġboth, Score: 0.34711265563964844\n",
      "Token: ĠNotre, Score: 0.4716476500034332\n",
      "Token: ĠDame, Score: 0.6054229140281677\n",
      "Token: Ġand, Score: 0.3923049867153168\n",
      "Token: ĠSaint, Score: 0.6210574507713318\n",
      "Token: ĠMary, Score: 0.6901170015335083\n",
      "Token: 's, Score: 0.6557786464691162\n",
      "Token: ĠCollege, Score: 0.819862961769104\n",
      "Token: ., Score: 0.803735077381134\n",
      "Token: ĠUnlike, Score: 0.5244604349136353\n",
      "Token: ĠSch, Score: 0.5185925960540771\n",
      "Token: ol, Score: 0.5405115485191345\n",
      "Token: astic, Score: 0.6141176223754883\n",
      "Token: Ġand, Score: 0.3094671070575714\n",
      "Token: ĠThe, Score: 0.14632123708724976\n",
      "Token: ĠDome, Score: 0.6156668663024902\n",
      "Token: ,, Score: 0.49928638339042664\n",
      "Token: ĠThe, Score: 0.26988402009010315\n",
      "Token: ĠObserver, Score: 0.7467948198318481\n",
      "Token: Ġis, Score: 0.7400821447372437\n",
      "Token: Ġan, Score: 0.5994292497634888\n",
      "Token: Ġindependent, Score: 0.6591066122055054\n",
      "Token: Ġpublication, Score: 0.8945663571357727\n",
      "Token: Ġand, Score: 0.4875323176383972\n",
      "Token: Ġdoes, Score: 0.7538642883300781\n",
      "Token: Ġnot, Score: 0.6379258036613464\n",
      "Token: Ġhave, Score: 0.5678418278694153\n",
      "Token: Ġa, Score: 0.544988214969635\n",
      "Token: Ġfaculty, Score: 0.7338812947273254\n",
      "Token: Ġadvisor, Score: 0.9853208661079407\n",
      "Token: Ġor, Score: 0.5037599802017212\n",
      "Token: Ġany, Score: 0.48025256395339966\n",
      "Token: Ġeditorial, Score: 0.5598338842391968\n",
      "Token: Ġoversight, Score: 0.9758588075637817\n",
      "Token: Ġfrom, Score: 0.5358285307884216\n",
      "Token: Ġthe, Score: 0.5498723387718201\n",
      "Token: ĠUniversity, Score: 0.8998578786849976\n",
      "Token: ., Score: 0.8329622149467468\n",
      "Token: ĠIn, Score: 0.1950363963842392\n",
      "Token: Ġ, Score: 0.1831257939338684\n",
      "Token: 198, Score: 0.16101573407649994\n",
      "Token: 7, Score: 0.7065663933753967\n",
      "Token: ,, Score: 0.4855395257472992\n",
      "Token: Ġwhen, Score: 0.500141978263855\n",
      "Token: Ġsome, Score: 0.5089609622955322\n",
      "Token: Ġstudents, Score: 0.6292356848716736\n",
      "Token: Ġbelieved, Score: 0.5323701500892639\n",
      "Token: Ġthat, Score: 0.4133944809436798\n",
      "Token: ĠThe, Score: 0.34984132647514343\n",
      "Token: ĠObserver, Score: 0.7989001274108887\n",
      "Token: Ġbegan, Score: 0.2701287865638733\n",
      "Token: Ġto, Score: 0.089219830930233\n",
      "Token: Ġshow, Score: 0.20223402976989746\n",
      "Token: Ġa, Score: 0.11302263289690018\n",
      "Token: Ġconservative, Score: 0.5545384883880615\n",
      "Token: Ġbias, Score: 0.86100834608078\n",
      "Token: ,, Score: 0.5387520790100098\n",
      "Token: Ġa, Score: 0.4723651111125946\n",
      "Token: Ġliberal, Score: 0.7255533933639526\n",
      "Token: Ġnewspaper, Score: 0.8330159187316895\n",
      "Token: ,, Score: 0.42815959453582764\n",
      "Token: ĠCommon, Score: 0.07329528033733368\n",
      "Token: ĠSense, Score: 0.6042964458465576\n",
      "Token: Ġwas, Score: 0.777947187423706\n",
      "Token: Ġpublished, Score: 0.8013978004455566\n",
      "Token: ., Score: 0.7908691763877869\n",
      "Token: ĠLikewise, Score: 0.7945078611373901\n",
      "Token: ,, Score: 0.5780773162841797\n",
      "Token: Ġin, Score: 0.2616274654865265\n",
      "Token: Ġ, Score: 0.039948344230651855\n",
      "Token: 200, Score: 0.12528084218502045\n",
      "Token: 3, Score: 0.6222874522209167\n",
      "Token: ,, Score: 0.45228928327560425\n",
      "Token: Ġwhen, Score: 0.47258687019348145\n",
      "Token: Ġother, Score: 0.6567977070808411\n",
      "Token: Ġstudents, Score: 0.6990756392478943\n",
      "Token: Ġbelieved, Score: 0.4100911021232605\n",
      "Token: Ġthat, Score: 0.2589709460735321\n",
      "Token: Ġthe, Score: 0.3891105651855469\n",
      "Token: Ġpaper, Score: 0.8052529096603394\n",
      "Token: Ġshowed, Score: 0.2781904339790344\n",
      "Token: Ġa, Score: 0.08605609834194183\n",
      "Token: Ġliberal, Score: 0.5660194158554077\n",
      "Token: Ġbias, Score: 0.7244246602058411\n",
      "Token: ,, Score: 0.4865017831325531\n",
      "Token: Ġthe, Score: 0.3817940056324005\n",
      "Token: Ġconservative, Score: 0.6163153052330017\n",
      "Token: Ġpaper, Score: 0.5505629181861877\n",
      "Token: ĠIrish, Score: 0.015030601061880589\n",
      "Token: ĠRover, Score: 0.8123645782470703\n",
      "Token: Ġwent, Score: 0.6762389540672302\n",
      "Token: Ġinto, Score: 0.39241164922714233\n",
      "Token: Ġproduction, Score: 0.9326078295707703\n",
      "Token: ., Score: 0.7789201736450195\n",
      "Token: ĠNeither, Score: 0.4981752634048462\n",
      "Token: Ġpaper, Score: 0.7920562028884888\n",
      "Token: Ġis, Score: 0.773112952709198\n",
      "Token: Ġpublished, Score: 0.4604092240333557\n",
      "Token: Ġas, Score: 0.3819873631000519\n",
      "Token: Ġoften, Score: 0.6550389528274536\n",
      "Token: Ġas, Score: 0.529907763004303\n",
      "Token: ĠThe, Score: 0.6451119184494019\n",
      "Token: ĠObserver, Score: 0.86810702085495\n",
      "Token: ;, Score: 0.5168123841285706\n",
      "Token: Ġhowever, Score: 0.7112640738487244\n",
      "Token: ,, Score: 0.47089719772338867\n",
      "Token: Ġall, Score: 0.5242079496383667\n",
      "Token: Ġthree, Score: 0.48944219946861267\n",
      "Token: Ġare, Score: 0.8333059549331665\n",
      "Token: Ġdistributed, Score: 0.5499359965324402\n",
      "Token: Ġto, Score: 0.38713082671165466\n",
      "Token: Ġall, Score: 0.5053368210792542\n",
      "Token: Ġstudents, Score: 0.8382138609886169\n",
      "Token: ., Score: 0.7951562404632568\n",
      "Token: ĠFinally, Score: 0.7152434587478638\n",
      "Token: ,, Score: 0.5004880428314209\n",
      "Token: Ġin, Score: 0.30157965421676636\n",
      "Token: ĠSpring, Score: 0.3941420018672943\n",
      "Token: Ġ, Score: 0.107573002576828\n",
      "Token: 200, Score: 0.07233458012342453\n",
      "Token: 8, Score: 0.5811697244644165\n",
      "Token: Ġan, Score: 0.623075544834137\n",
      "Token: Ġundergraduate, Score: 0.8162933588027954\n",
      "Token: Ġjournal, Score: 0.8100656270980835\n",
      "Token: Ġfor, Score: 0.5758321285247803\n",
      "Token: Ġpolitical, Score: 0.5101740956306458\n",
      "Token: Ġscience, Score: 0.8178579211235046\n",
      "Token: Ġresearch, Score: 0.880852460861206\n",
      "Token: ,, Score: 0.44856998324394226\n",
      "Token: ĠBeyond, Score: 0.2890843152999878\n",
      "Token: ĠPolitics, Score: 0.7167336344718933\n",
      "Token: ,, Score: 0.8406010270118713\n",
      "Token: Ġmade, Score: 0.6559221744537354\n",
      "Token: Ġits, Score: 0.5127570033073425\n",
      "Token: Ġdebut, Score: 0.9474197626113892\n",
      "Token: ., Score: 0.8003119826316833\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: assistant, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: According, Score: 0.0\n",
      "Token: Ġto, Score: 0.0\n",
      "Token: Ġthe, Score: 0.0\n",
      "Token: Ġcontext, Score: 0.0\n",
      "Token: ,, Score: 0.0\n",
      "Token: Ġthere, Score: 0.0\n",
      "Token: Ġare, Score: 0.0\n",
      "Token: Ġthree, Score: 0.0\n",
      "Token: Ġstudent, Score: 0.0\n",
      "Token: -run, Score: 0.0\n",
      "Token: Ġnewspapers, Score: 0.0\n",
      "Token: Ġfound, Score: 0.0\n",
      "Token: Ġat, Score: 0.0\n",
      "Token: ĠNotre, Score: 0.0\n",
      "Token: ĠDame, Score: 0.0\n",
      "Token: :, Score: 0.0\n",
      "Token: ĠThe, Score: 0.0\n",
      "Token: ĠObserver, Score: 0.0\n",
      "Token: ,, Score: 0.0\n",
      "Token: ĠCommon, Score: 0.0\n",
      "Token: ĠSense, Score: 0.0\n",
      "Token: ,, Score: 0.0\n",
      "Token: Ġand, Score: 0.0\n",
      "Token: ĠIrish, Score: 0.0\n",
      "Token: ĠRover, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n",
      "Token: <|eot_id|>, Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "for token, score in filtered_token_scores:\n",
    "    print(f\"Token: {token}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_mask_prob * test_context_mask).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs.keys()\n",
    "\n",
    "collate_fn()\n",
    "\n",
    "tokenizer(\"this is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = ds['train'].select(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data_dict = {\n",
    "    'text': [\"This is the first example.\", \"This is the second example.\"],\n",
    "    'label': [0, 1]\n",
    "}\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
