{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='log/app.log',            # Specify the log file name\n",
    "    level=logging.DEBUG,           # Set the log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Set the log format\n",
    ")\n",
    "\n",
    "# Load the environment configuration JSON data\n",
    "json_path = 'env_config.json'\n",
    "with open(json_path, 'r') as file:\n",
    "    env_config = json.load(file)\n",
    "\n",
    "hf_home = env_config['HF_HOME']\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ['HF_HOME'] = hf_home\n",
    "# Set the access token to huggingface hub\n",
    "access_token = env_config['access_token']\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/crc/c/conda/23.5.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.55s/it]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'LlamaTokenizerFast'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "print(transformers.__version__)\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from transformers import LlamaTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B\"  # non-instruct version\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    token=access_token,\n",
    ")\n",
    "\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(model_id, token=access_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmexp.helper import LlmExpHelper\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# imdb = load_dataset(\"imdb\")\n",
    "ds = load_dataset(\"rajpurkar/squad\")\n",
    "train_ds = ds['train']\n",
    "test_ds = ds['validation']\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"stanfordnlp/sst2\")\n",
    "# train_ds = ds['train']\n",
    "llm_exp_helper = LlmExpHelper(tokenizer, 'squad')\n",
    "collate_fn = llm_exp_helper.get_collate_fun()\n",
    "\n",
    "# Define batch size here!\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(train_dataloader))\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmexp.squad_model import MaskGeneratingModel\n",
    "\n",
    "mask_gen_model = MaskGeneratingModel(hidden_size=4096, mlp_hidden_dim=1024, mlp_bottleneck_dim=768, mlp_num_blocks=2)\n",
    "mask_gen_model.to(device)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set pad_token_id if it is not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(mask_gen_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1: Loss = 0.2883, Reward Loss = 0.2800, Mean Reward = 0.4903,Mask_loss = 0.1661 mask_mean = 0.5699:   0%|          | 1/5475 [00:10<15:13:49, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 11: Loss = 0.1777, Reward Loss = 0.1748, Mean Reward = 0.3219,Mask_loss = 0.0578 mask_mean = 0.2001:   0%|          | 11/5475 [01:50<17:12:01, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 21: Loss = 0.2929, Reward Loss = 0.2784, Mean Reward = 0.4837,Mask_loss = 0.2917 mask_mean = 0.7479:   0%|          | 21/5475 [03:41<17:32:33, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 31: Loss = 0.2095, Reward Loss = 0.2071, Mean Reward = 0.3650,Mask_loss = 0.0488 mask_mean = 0.3160:   1%|          | 31/5475 [05:38<17:09:34, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 41: Loss = 0.2735, Reward Loss = 0.2679, Mean Reward = 0.4563,Mask_loss = 0.1118 mask_mean = 0.5527:   1%|          | 41/5475 [07:24<15:30:27, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 51: Loss = 0.2697, Reward Loss = 0.2588, Mean Reward = 0.4674,Mask_loss = 0.2172 mask_mean = 0.6638:   1%|          | 51/5475 [08:59<15:12:35, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 61: Loss = 0.2454, Reward Loss = 0.2439, Mean Reward = 0.4322,Mask_loss = 0.0296 mask_mean = 0.3583:   1%|          | 61/5475 [10:29<13:58:37,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 71: Loss = 0.2525, Reward Loss = 0.2491, Mean Reward = 0.4436,Mask_loss = 0.0687 mask_mean = 0.4041:   1%|▏         | 71/5475 [12:09<13:49:02,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 81: Loss = 0.2504, Reward Loss = 0.2464, Mean Reward = 0.4339,Mask_loss = 0.0805 mask_mean = 0.4991:   1%|▏         | 81/5475 [13:54<15:15:24, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 91: Loss = 0.2671, Reward Loss = 0.2615, Mean Reward = 0.4539,Mask_loss = 0.1102 mask_mean = 0.5355:   2%|▏         | 91/5475 [15:37<15:53:30, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 101: Loss = 0.2407, Reward Loss = 0.2385, Mean Reward = 0.4119,Mask_loss = 0.0432 mask_mean = 0.3322:   2%|▏         | 101/5475 [17:20<15:45:11, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 111: Loss = 0.2347, Reward Loss = 0.2336, Mean Reward = 0.4180,Mask_loss = 0.0222 mask_mean = 0.2967:   2%|▏         | 111/5475 [18:50<12:27:09,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 121: Loss = 0.2859, Reward Loss = 0.2798, Mean Reward = 0.4841,Mask_loss = 0.1229 mask_mean = 0.5403:   2%|▏         | 121/5475 [20:27<12:56:56,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 131: Loss = 0.2250, Reward Loss = 0.2235, Mean Reward = 0.3937,Mask_loss = 0.0311 mask_mean = 0.3632:   2%|▏         | 131/5475 [22:07<15:36:22, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 141: Loss = 0.2622, Reward Loss = 0.2589, Mean Reward = 0.4391,Mask_loss = 0.0642 mask_mean = 0.4520:   3%|▎         | 141/5475 [23:46<15:14:26, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 151: Loss = 0.2553, Reward Loss = 0.2512, Mean Reward = 0.4221,Mask_loss = 0.0811 mask_mean = 0.4980:   3%|▎         | 151/5475 [25:25<15:09:00, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 161: Loss = 0.2042, Reward Loss = 0.2023, Mean Reward = 0.3587,Mask_loss = 0.0379 mask_mean = 0.3316:   3%|▎         | 161/5475 [27:09<14:29:12,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 171: Loss = 0.2568, Reward Loss = 0.2552, Mean Reward = 0.4437,Mask_loss = 0.0327 mask_mean = 0.3692:   3%|▎         | 171/5475 [28:49<15:44:08, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 181: Loss = 0.2159, Reward Loss = 0.2147, Mean Reward = 0.3819,Mask_loss = 0.0240 mask_mean = 0.3148:   3%|▎         | 181/5475 [30:37<14:52:23, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 191: Loss = 0.2739, Reward Loss = 0.2689, Mean Reward = 0.4550,Mask_loss = 0.0999 mask_mean = 0.5226:   3%|▎         | 191/5475 [32:07<13:22:40,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 201: Loss = 0.2892, Reward Loss = 0.2803, Mean Reward = 0.4839,Mask_loss = 0.1778 mask_mean = 0.5968:   4%|▎         | 200/5475 [33:34<13:01:57,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 201: Loss = 0.2892, Reward Loss = 0.2803, Mean Reward = 0.4839,Mask_loss = 0.1778 mask_mean = 0.5968:   4%|▎         | 201/5475 [33:39<13:25:53,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 211: Loss = 0.2911, Reward Loss = 0.2849, Mean Reward = 0.4871,Mask_loss = 0.1256 mask_mean = 0.5468:   4%|▍         | 211/5475 [35:16<14:22:07,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 221: Loss = 0.1883, Reward Loss = 0.1859, Mean Reward = 0.3385,Mask_loss = 0.0487 mask_mean = 0.2511:   4%|▍         | 221/5475 [37:04<14:20:49,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 231: Loss = 0.2768, Reward Loss = 0.2687, Mean Reward = 0.4592,Mask_loss = 0.1624 mask_mean = 0.6096:   4%|▍         | 231/5475 [38:38<13:21:22,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 241: Loss = 0.2917, Reward Loss = 0.2854, Mean Reward = 0.4800,Mask_loss = 0.1254 mask_mean = 0.5477:   4%|▍         | 241/5475 [40:11<13:10:36,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 251: Loss = 0.2725, Reward Loss = 0.2684, Mean Reward = 0.4482,Mask_loss = 0.0820 mask_mean = 0.4777:   5%|▍         | 251/5475 [41:49<13:15:22,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 261: Loss = 0.2981, Reward Loss = 0.2942, Mean Reward = 0.4824,Mask_loss = 0.0784 mask_mean = 0.4707:   5%|▍         | 261/5475 [43:19<12:32:11,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 271: Loss = 0.1955, Reward Loss = 0.1931, Mean Reward = 0.3507,Mask_loss = 0.0484 mask_mean = 0.2532:   5%|▍         | 271/5475 [45:05<15:52:23, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 281: Loss = 0.1724, Reward Loss = 0.1692, Mean Reward = 0.3204,Mask_loss = 0.0646 mask_mean = 0.1879:   5%|▌         | 281/5475 [47:00<18:41:14, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 291: Loss = 0.2825, Reward Loss = 0.2794, Mean Reward = 0.4695,Mask_loss = 0.0624 mask_mean = 0.4439:   5%|▌         | 291/5475 [48:45<14:49:46, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 301: Loss = 0.2989, Reward Loss = 0.2934, Mean Reward = 0.4777,Mask_loss = 0.1099 mask_mean = 0.5376:   5%|▌         | 301/5475 [50:27<14:45:14, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 311: Loss = 0.2770, Reward Loss = 0.2719, Mean Reward = 0.4607,Mask_loss = 0.1022 mask_mean = 0.4977:   6%|▌         | 311/5475 [52:05<13:15:32,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 321: Loss = 0.2706, Reward Loss = 0.2678, Mean Reward = 0.4586,Mask_loss = 0.0555 mask_mean = 0.4089:   6%|▌         | 321/5475 [53:33<12:43:36,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 331: Loss = 0.2927, Reward Loss = 0.2860, Mean Reward = 0.4774,Mask_loss = 0.1331 mask_mean = 0.5776:   6%|▌         | 331/5475 [55:08<13:38:20,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 341: Loss = 0.2547, Reward Loss = 0.2527, Mean Reward = 0.4298,Mask_loss = 0.0403 mask_mean = 0.3758:   6%|▌         | 341/5475 [56:53<13:36:23,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 351: Loss = 0.2687, Reward Loss = 0.2645, Mean Reward = 0.4469,Mask_loss = 0.0837 mask_mean = 0.4535:   6%|▋         | 351/5475 [58:41<15:51:57, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 361: Loss = 0.1802, Reward Loss = 0.1774, Mean Reward = 0.3308,Mask_loss = 0.0558 mask_mean = 0.2073:   7%|▋         | 361/5475 [1:00:16<14:08:59,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 371: Loss = 0.2876, Reward Loss = 0.2827, Mean Reward = 0.4660,Mask_loss = 0.0967 mask_mean = 0.5118:   7%|▋         | 371/5475 [1:02:02<14:25:35, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 381: Loss = 0.2628, Reward Loss = 0.2615, Mean Reward = 0.4416,Mask_loss = 0.0260 mask_mean = 0.3641:   7%|▋         | 381/5475 [1:03:45<14:23:11, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 391: Loss = 0.2540, Reward Loss = 0.2509, Mean Reward = 0.4192,Mask_loss = 0.0617 mask_mean = 0.4413:   7%|▋         | 391/5475 [1:05:19<12:37:14,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 401: Loss = 0.1996, Reward Loss = 0.1987, Mean Reward = 0.3627,Mask_loss = 0.0186 mask_mean = 0.2622:   7%|▋         | 400/5475 [1:06:52<13:31:33,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 401: Loss = 0.1996, Reward Loss = 0.1987, Mean Reward = 0.3627,Mask_loss = 0.0186 mask_mean = 0.2622:   7%|▋         | 401/5475 [1:06:58<13:45:33,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 411: Loss = 0.1612, Reward Loss = 0.1578, Mean Reward = 0.2874,Mask_loss = 0.0682 mask_mean = 0.2394:   8%|▊         | 411/5475 [1:08:32<13:43:23,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 421: Loss = 0.2595, Reward Loss = 0.2576, Mean Reward = 0.4419,Mask_loss = 0.0378 mask_mean = 0.3643:   8%|▊         | 421/5475 [1:10:10<13:11:05,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 431: Loss = 0.2625, Reward Loss = 0.2615, Mean Reward = 0.4564,Mask_loss = 0.0194 mask_mean = 0.3302:   8%|▊         | 431/5475 [1:11:49<13:01:35,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 441: Loss = 0.2824, Reward Loss = 0.2726, Mean Reward = 0.4676,Mask_loss = 0.1976 mask_mean = 0.6672:   8%|▊         | 441/5475 [1:13:31<13:31:18,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 451: Loss = 0.2859, Reward Loss = 0.2790, Mean Reward = 0.4634,Mask_loss = 0.1374 mask_mean = 0.5813:   8%|▊         | 451/5475 [1:15:07<13:22:27,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 461: Loss = 0.2121, Reward Loss = 0.2103, Mean Reward = 0.3634,Mask_loss = 0.0370 mask_mean = 0.3581:   8%|▊         | 461/5475 [1:17:07<14:56:17, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 471: Loss = 0.2682, Reward Loss = 0.2660, Mean Reward = 0.4453,Mask_loss = 0.0447 mask_mean = 0.3793:   9%|▊         | 471/5475 [1:18:37<12:58:05,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 481: Loss = 0.3021, Reward Loss = 0.2930, Mean Reward = 0.5000,Mask_loss = 0.1808 mask_mean = 0.6181:   9%|▉         | 481/5475 [1:20:10<13:09:27,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 491: Loss = 0.2109, Reward Loss = 0.2095, Mean Reward = 0.3742,Mask_loss = 0.0290 mask_mean = 0.2714:   9%|▉         | 491/5475 [1:21:50<13:13:08,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 501: Loss = 0.2062, Reward Loss = 0.2048, Mean Reward = 0.3733,Mask_loss = 0.0278 mask_mean = 0.2863:   9%|▉         | 501/5475 [1:23:32<13:33:21,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 511: Loss = 0.2242, Reward Loss = 0.2229, Mean Reward = 0.4058,Mask_loss = 0.0259 mask_mean = 0.2827:   9%|▉         | 511/5475 [1:25:05<12:51:55,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 521: Loss = 0.2072, Reward Loss = 0.2056, Mean Reward = 0.3744,Mask_loss = 0.0308 mask_mean = 0.2625:  10%|▉         | 521/5475 [1:26:46<13:24:02,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 531: Loss = 0.2814, Reward Loss = 0.2711, Mean Reward = 0.4773,Mask_loss = 0.2052 mask_mean = 0.6522:  10%|▉         | 531/5475 [1:28:29<15:32:20, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 541: Loss = 0.2739, Reward Loss = 0.2611, Mean Reward = 0.4750,Mask_loss = 0.2566 mask_mean = 0.7214:  10%|▉         | 541/5475 [1:30:19<15:15:20, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 551: Loss = 0.2893, Reward Loss = 0.2756, Mean Reward = 0.4971,Mask_loss = 0.2728 mask_mean = 0.7211:  10%|█         | 551/5475 [1:32:05<14:09:36, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 561: Loss = 0.2077, Reward Loss = 0.2061, Mean Reward = 0.3573,Mask_loss = 0.0324 mask_mean = 0.2907:  10%|█         | 561/5475 [1:33:45<13:40:38, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 571: Loss = 0.2898, Reward Loss = 0.2833, Mean Reward = 0.4670,Mask_loss = 0.1295 mask_mean = 0.5747:  10%|█         | 571/5475 [1:35:24<13:55:17, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 581: Loss = 0.2951, Reward Loss = 0.2914, Mean Reward = 0.4714,Mask_loss = 0.0737 mask_mean = 0.4858:  11%|█         | 581/5475 [1:37:08<14:04:21, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 591: Loss = 0.2818, Reward Loss = 0.2786, Mean Reward = 0.4573,Mask_loss = 0.0635 mask_mean = 0.4653:  11%|█         | 591/5475 [1:38:54<15:39:08, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 601: Loss = 0.2490, Reward Loss = 0.2475, Mean Reward = 0.4188,Mask_loss = 0.0290 mask_mean = 0.3620:  11%|█         | 600/5475 [1:40:26<13:58:05, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 601: Loss = 0.2490, Reward Loss = 0.2475, Mean Reward = 0.4188,Mask_loss = 0.0290 mask_mean = 0.3620:  11%|█         | 601/5475 [1:40:31<14:00:57, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 611: Loss = 0.2717, Reward Loss = 0.2698, Mean Reward = 0.4442,Mask_loss = 0.0370 mask_mean = 0.4192:  11%|█         | 611/5475 [1:42:15<14:27:50, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 621: Loss = 0.2805, Reward Loss = 0.2762, Mean Reward = 0.4489,Mask_loss = 0.0843 mask_mean = 0.5066:  11%|█▏        | 621/5475 [1:43:50<11:41:18,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 631: Loss = 0.2895, Reward Loss = 0.2869, Mean Reward = 0.4692,Mask_loss = 0.0522 mask_mean = 0.4325:  12%|█▏        | 631/5475 [1:45:28<13:41:53, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 641: Loss = 0.2958, Reward Loss = 0.2901, Mean Reward = 0.4772,Mask_loss = 0.1140 mask_mean = 0.5411:  12%|█▏        | 641/5475 [1:47:03<12:13:32,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 651: Loss = 0.2944, Reward Loss = 0.2901, Mean Reward = 0.4750,Mask_loss = 0.0858 mask_mean = 0.4974:  12%|█▏        | 651/5475 [1:48:39<12:45:13,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 661: Loss = 0.1549, Reward Loss = 0.1517, Mean Reward = 0.2870,Mask_loss = 0.0629 mask_mean = 0.2053:  12%|█▏        | 661/5475 [1:50:20<14:44:52, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 671: Loss = 0.2442, Reward Loss = 0.2430, Mean Reward = 0.4198,Mask_loss = 0.0234 mask_mean = 0.3410:  12%|█▏        | 671/5475 [1:52:02<13:23:22, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 681: Loss = 0.2881, Reward Loss = 0.2843, Mean Reward = 0.4671,Mask_loss = 0.0772 mask_mean = 0.4841:  12%|█▏        | 681/5475 [1:53:43<13:35:36, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 691: Loss = 0.2873, Reward Loss = 0.2820, Mean Reward = 0.4700,Mask_loss = 0.1055 mask_mean = 0.5338:  13%|█▎        | 691/5475 [1:55:20<14:37:36, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 701: Loss = 0.2630, Reward Loss = 0.2614, Mean Reward = 0.4376,Mask_loss = 0.0309 mask_mean = 0.3934:  13%|█▎        | 701/5475 [1:57:03<13:57:26, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 711: Loss = 0.2847, Reward Loss = 0.2807, Mean Reward = 0.4566,Mask_loss = 0.0800 mask_mean = 0.4756:  13%|█▎        | 711/5475 [1:58:40<13:49:32, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 721: Loss = 0.2932, Reward Loss = 0.2901, Mean Reward = 0.4712,Mask_loss = 0.0626 mask_mean = 0.4536:  13%|█▎        | 721/5475 [2:00:18<13:13:26, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 731: Loss = 0.2708, Reward Loss = 0.2660, Mean Reward = 0.4307,Mask_loss = 0.0973 mask_mean = 0.5383:  13%|█▎        | 731/5475 [2:02:08<14:54:15, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 741: Loss = 0.2499, Reward Loss = 0.2482, Mean Reward = 0.4127,Mask_loss = 0.0346 mask_mean = 0.4095:  14%|█▎        | 741/5475 [2:03:51<14:12:13, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 751: Loss = 0.2897, Reward Loss = 0.2862, Mean Reward = 0.4665,Mask_loss = 0.0685 mask_mean = 0.4668:  14%|█▎        | 751/5475 [2:05:25<11:44:27,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 761: Loss = 0.2887, Reward Loss = 0.2840, Mean Reward = 0.4723,Mask_loss = 0.0924 mask_mean = 0.5063:  14%|█▍        | 761/5475 [2:07:14<15:21:57, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 771: Loss = 0.2983, Reward Loss = 0.2857, Mean Reward = 0.4992,Mask_loss = 0.2524 mask_mean = 0.6950:  14%|█▍        | 771/5475 [2:08:53<12:21:17,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 781: Loss = 0.2780, Reward Loss = 0.2757, Mean Reward = 0.4522,Mask_loss = 0.0472 mask_mean = 0.4478:  14%|█▍        | 781/5475 [2:10:29<12:03:18,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 791: Loss = 0.2669, Reward Loss = 0.2641, Mean Reward = 0.4328,Mask_loss = 0.0559 mask_mean = 0.4523:  14%|█▍        | 791/5475 [2:12:16<15:13:13, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 801: Loss = 0.2889, Reward Loss = 0.2814, Mean Reward = 0.4701,Mask_loss = 0.1491 mask_mean = 0.6033:  15%|█▍        | 800/5475 [2:13:57<13:15:39, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 801: Loss = 0.2889, Reward Loss = 0.2814, Mean Reward = 0.4701,Mask_loss = 0.1491 mask_mean = 0.6033:  15%|█▍        | 801/5475 [2:14:02<12:59:56, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 811: Loss = 0.2830, Reward Loss = 0.2778, Mean Reward = 0.4509,Mask_loss = 0.1044 mask_mean = 0.5321:  15%|█▍        | 811/5475 [2:15:37<12:08:23,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 821: Loss = 0.2430, Reward Loss = 0.2417, Mean Reward = 0.4080,Mask_loss = 0.0261 mask_mean = 0.3838:  15%|█▍        | 821/5475 [2:17:20<13:06:09, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 831: Loss = 0.2657, Reward Loss = 0.2647, Mean Reward = 0.4466,Mask_loss = 0.0203 mask_mean = 0.3593:  15%|█▌        | 831/5475 [2:18:53<11:50:18,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 841: Loss = 0.2264, Reward Loss = 0.2252, Mean Reward = 0.3864,Mask_loss = 0.0248 mask_mean = 0.3596:  15%|█▌        | 841/5475 [2:20:32<14:05:12, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 851: Loss = 0.2546, Reward Loss = 0.2524, Mean Reward = 0.4148,Mask_loss = 0.0427 mask_mean = 0.4146:  16%|█▌        | 851/5475 [2:22:02<12:19:35,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 861: Loss = 0.1522, Reward Loss = 0.1484, Mean Reward = 0.2901,Mask_loss = 0.0760 mask_mean = 0.1649:  16%|█▌        | 861/5475 [2:23:44<12:54:13, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 871: Loss = 0.2672, Reward Loss = 0.2642, Mean Reward = 0.4349,Mask_loss = 0.0607 mask_mean = 0.4369:  16%|█▌        | 871/5475 [2:25:26<14:07:06, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 881: Loss = 0.2163, Reward Loss = 0.2147, Mean Reward = 0.3670,Mask_loss = 0.0310 mask_mean = 0.3506:  16%|█▌        | 881/5475 [2:26:59<11:54:56,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 891: Loss = 0.2796, Reward Loss = 0.2735, Mean Reward = 0.4575,Mask_loss = 0.1203 mask_mean = 0.5678:  16%|█▋        | 891/5475 [2:28:28<11:53:23,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 901: Loss = 0.2879, Reward Loss = 0.2819, Mean Reward = 0.4697,Mask_loss = 0.1209 mask_mean = 0.5496:  16%|█▋        | 901/5475 [2:30:06<12:20:12,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 911: Loss = 0.2822, Reward Loss = 0.2789, Mean Reward = 0.4594,Mask_loss = 0.0663 mask_mean = 0.4563:  17%|█▋        | 911/5475 [2:31:46<13:15:06, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 921: Loss = 0.2308, Reward Loss = 0.2298, Mean Reward = 0.4005,Mask_loss = 0.0205 mask_mean = 0.2964:  17%|█▋        | 921/5475 [2:33:29<13:22:41, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 931: Loss = 0.1613, Reward Loss = 0.1580, Mean Reward = 0.3141,Mask_loss = 0.0653 mask_mean = 0.1614:  17%|█▋        | 931/5475 [2:35:06<12:30:27,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 941: Loss = 0.2152, Reward Loss = 0.2136, Mean Reward = 0.3946,Mask_loss = 0.0332 mask_mean = 0.2495:  17%|█▋        | 941/5475 [2:36:55<13:30:51, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 951: Loss = 0.2725, Reward Loss = 0.2702, Mean Reward = 0.4504,Mask_loss = 0.0447 mask_mean = 0.3986:  17%|█▋        | 951/5475 [2:38:38<12:52:46, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 961: Loss = 0.2609, Reward Loss = 0.2579, Mean Reward = 0.4193,Mask_loss = 0.0583 mask_mean = 0.4573:  18%|█▊        | 961/5475 [2:40:24<13:16:19, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 971: Loss = 0.2642, Reward Loss = 0.2619, Mean Reward = 0.4381,Mask_loss = 0.0460 mask_mean = 0.4062:  18%|█▊        | 971/5475 [2:41:58<11:16:02,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 981: Loss = 0.2118, Reward Loss = 0.2098, Mean Reward = 0.3529,Mask_loss = 0.0405 mask_mean = 0.3485:  18%|█▊        | 981/5475 [2:43:34<12:27:25,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 991: Loss = 0.2825, Reward Loss = 0.2783, Mean Reward = 0.4533,Mask_loss = 0.0844 mask_mean = 0.5003:  18%|█▊        | 991/5475 [2:45:16<13:46:50, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1001: Loss = 0.2781, Reward Loss = 0.2639, Mean Reward = 0.4871,Mask_loss = 0.2827 mask_mean = 0.7376:  18%|█▊        | 1000/5475 [2:46:47<11:45:03,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1001: Loss = 0.2781, Reward Loss = 0.2639, Mean Reward = 0.4871,Mask_loss = 0.2827 mask_mean = 0.7376:  18%|█▊        | 1001/5475 [2:46:53<12:22:35,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1011: Loss = 0.3062, Reward Loss = 0.3021, Mean Reward = 0.4905,Mask_loss = 0.0817 mask_mean = 0.4752:  18%|█▊        | 1011/5475 [2:48:26<12:27:16, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1021: Loss = 0.2022, Reward Loss = 0.2002, Mean Reward = 0.3487,Mask_loss = 0.0403 mask_mean = 0.2906:  19%|█▊        | 1021/5475 [2:50:01<11:44:19,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1031: Loss = 0.2213, Reward Loss = 0.2203, Mean Reward = 0.3852,Mask_loss = 0.0189 mask_mean = 0.3009:  19%|█▉        | 1031/5475 [2:51:39<13:23:35, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1041: Loss = 0.2282, Reward Loss = 0.2267, Mean Reward = 0.3982,Mask_loss = 0.0285 mask_mean = 0.3302:  19%|█▉        | 1041/5475 [2:53:18<12:17:52,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1051: Loss = 0.2932, Reward Loss = 0.2898, Mean Reward = 0.4680,Mask_loss = 0.0675 mask_mean = 0.4740:  19%|█▉        | 1051/5475 [2:55:00<12:47:15, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1061: Loss = 0.2640, Reward Loss = 0.2622, Mean Reward = 0.4445,Mask_loss = 0.0366 mask_mean = 0.3510:  19%|█▉        | 1061/5475 [2:56:33<10:57:12,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1071: Loss = 0.2353, Reward Loss = 0.2345, Mean Reward = 0.4024,Mask_loss = 0.0156 mask_mean = 0.3229:  20%|█▉        | 1071/5475 [2:58:14<11:27:39,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1081: Loss = 0.2251, Reward Loss = 0.2239, Mean Reward = 0.3899,Mask_loss = 0.0252 mask_mean = 0.2975:  20%|█▉        | 1081/5475 [2:59:47<10:56:56,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1091: Loss = 0.2944, Reward Loss = 0.2873, Mean Reward = 0.4668,Mask_loss = 0.1428 mask_mean = 0.6027:  20%|█▉        | 1091/5475 [3:01:24<12:02:16,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1101: Loss = 0.2971, Reward Loss = 0.2876, Mean Reward = 0.4870,Mask_loss = 0.1898 mask_mean = 0.6291:  20%|██        | 1101/5475 [3:03:01<11:19:49,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1111: Loss = 0.3040, Reward Loss = 0.2965, Mean Reward = 0.4901,Mask_loss = 0.1512 mask_mean = 0.5789:  20%|██        | 1111/5475 [3:04:44<12:54:31, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1121: Loss = 0.2683, Reward Loss = 0.2659, Mean Reward = 0.4405,Mask_loss = 0.0471 mask_mean = 0.4081:  20%|██        | 1121/5475 [3:06:14<10:52:25,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1131: Loss = 0.2733, Reward Loss = 0.2715, Mean Reward = 0.4474,Mask_loss = 0.0354 mask_mean = 0.4138:  21%|██        | 1131/5475 [3:07:45<10:33:14,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1141: Loss = 0.2747, Reward Loss = 0.2730, Mean Reward = 0.4542,Mask_loss = 0.0323 mask_mean = 0.3842:  21%|██        | 1141/5475 [3:09:21<11:18:29,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1151: Loss = 0.3059, Reward Loss = 0.3029, Mean Reward = 0.4867,Mask_loss = 0.0599 mask_mean = 0.4452:  21%|██        | 1151/5475 [3:10:58<10:53:01,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1161: Loss = 0.3077, Reward Loss = 0.3034, Mean Reward = 0.4908,Mask_loss = 0.0872 mask_mean = 0.4820:  21%|██        | 1161/5475 [3:12:33<10:49:03,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1171: Loss = 0.2699, Reward Loss = 0.2683, Mean Reward = 0.4486,Mask_loss = 0.0321 mask_mean = 0.3614:  21%|██▏       | 1171/5475 [3:14:12<11:09:31,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1181: Loss = 0.2433, Reward Loss = 0.2422, Mean Reward = 0.4218,Mask_loss = 0.0201 mask_mean = 0.3126:  22%|██▏       | 1181/5475 [3:15:56<12:43:10, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1191: Loss = 0.1832, Reward Loss = 0.1809, Mean Reward = 0.3388,Mask_loss = 0.0464 mask_mean = 0.2051:  22%|██▏       | 1191/5475 [3:17:41<12:56:52, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1201: Loss = 0.1983, Reward Loss = 0.1965, Mean Reward = 0.3618,Mask_loss = 0.0352 mask_mean = 0.2464:  22%|██▏       | 1200/5475 [3:19:15<11:12:37,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1201: Loss = 0.1983, Reward Loss = 0.1965, Mean Reward = 0.3618,Mask_loss = 0.0352 mask_mean = 0.2464:  22%|██▏       | 1201/5475 [3:19:24<13:44:06, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1211: Loss = 0.1968, Reward Loss = 0.1957, Mean Reward = 0.3603,Mask_loss = 0.0217 mask_mean = 0.2347:  22%|██▏       | 1211/5475 [3:20:55<11:25:49,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1221: Loss = 0.3012, Reward Loss = 0.2980, Mean Reward = 0.4690,Mask_loss = 0.0645 mask_mean = 0.4652:  22%|██▏       | 1221/5475 [3:22:25<9:53:44,  8.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1231: Loss = 0.2932, Reward Loss = 0.2896, Mean Reward = 0.4554,Mask_loss = 0.0729 mask_mean = 0.4795:  22%|██▏       | 1231/5475 [3:24:03<11:59:20, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1241: Loss = 0.2541, Reward Loss = 0.2526, Mean Reward = 0.4283,Mask_loss = 0.0285 mask_mean = 0.3376:  23%|██▎       | 1241/5475 [3:25:43<12:49:34, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1251: Loss = 0.2341, Reward Loss = 0.2328, Mean Reward = 0.3923,Mask_loss = 0.0263 mask_mean = 0.3457:  23%|██▎       | 1251/5475 [3:27:20<12:18:04, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1261: Loss = 0.1752, Reward Loss = 0.1731, Mean Reward = 0.3308,Mask_loss = 0.0419 mask_mean = 0.2113:  23%|██▎       | 1261/5475 [3:29:05<12:31:50, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1271: Loss = 0.2109, Reward Loss = 0.2100, Mean Reward = 0.3892,Mask_loss = 0.0183 mask_mean = 0.2263:  23%|██▎       | 1271/5475 [3:30:45<11:14:44,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1281: Loss = 0.1901, Reward Loss = 0.1878, Mean Reward = 0.3449,Mask_loss = 0.0458 mask_mean = 0.2269:  23%|██▎       | 1281/5475 [3:32:20<10:51:01,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1291: Loss = 0.3065, Reward Loss = 0.3033, Mean Reward = 0.4978,Mask_loss = 0.0635 mask_mean = 0.4311:  24%|██▎       | 1291/5475 [3:33:59<10:47:22,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1301: Loss = 0.3010, Reward Loss = 0.2956, Mean Reward = 0.4805,Mask_loss = 0.1083 mask_mean = 0.5400:  24%|██▍       | 1301/5475 [3:35:49<12:15:52, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1311: Loss = 0.3020, Reward Loss = 0.2929, Mean Reward = 0.4937,Mask_loss = 0.1812 mask_mean = 0.6158:  24%|██▍       | 1311/5475 [3:37:32<11:37:19, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1321: Loss = 0.2549, Reward Loss = 0.2534, Mean Reward = 0.4172,Mask_loss = 0.0303 mask_mean = 0.3943:  24%|██▍       | 1321/5475 [3:39:17<12:01:10, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1331: Loss = 0.2913, Reward Loss = 0.2891, Mean Reward = 0.4666,Mask_loss = 0.0445 mask_mean = 0.4132:  24%|██▍       | 1331/5475 [3:40:57<10:39:44,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1341: Loss = 0.1461, Reward Loss = 0.1418, Mean Reward = 0.2725,Mask_loss = 0.0855 mask_mean = 0.1739:  24%|██▍       | 1341/5475 [3:42:44<12:57:56, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1351: Loss = 0.2178, Reward Loss = 0.2163, Mean Reward = 0.3843,Mask_loss = 0.0287 mask_mean = 0.2807:  25%|██▍       | 1351/5475 [3:44:25<11:04:34,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1361: Loss = 0.2235, Reward Loss = 0.2217, Mean Reward = 0.3857,Mask_loss = 0.0363 mask_mean = 0.3035:  25%|██▍       | 1361/5475 [3:46:03<10:48:26,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1371: Loss = 0.1817, Reward Loss = 0.1791, Mean Reward = 0.3341,Mask_loss = 0.0517 mask_mean = 0.2154:  25%|██▌       | 1371/5475 [3:47:27<9:38:27,  8.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1381: Loss = 0.2809, Reward Loss = 0.2782, Mean Reward = 0.4468,Mask_loss = 0.0527 mask_mean = 0.4313:  25%|██▌       | 1381/5475 [3:49:03<10:23:45,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1391: Loss = 0.2610, Reward Loss = 0.2602, Mean Reward = 0.4497,Mask_loss = 0.0163 mask_mean = 0.3233:  25%|██▌       | 1391/5475 [3:50:38<10:40:51,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1401: Loss = 0.2815, Reward Loss = 0.2784, Mean Reward = 0.4639,Mask_loss = 0.0627 mask_mean = 0.4425:  26%|██▌       | 1400/5475 [3:52:14<11:24:58, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1401: Loss = 0.2815, Reward Loss = 0.2784, Mean Reward = 0.4639,Mask_loss = 0.0627 mask_mean = 0.4425:  26%|██▌       | 1401/5475 [3:52:20<11:41:19, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1411: Loss = 0.3017, Reward Loss = 0.2978, Mean Reward = 0.4849,Mask_loss = 0.0773 mask_mean = 0.4790:  26%|██▌       | 1411/5475 [3:54:06<11:42:09, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1421: Loss = 0.2893, Reward Loss = 0.2854, Mean Reward = 0.4591,Mask_loss = 0.0784 mask_mean = 0.4938:  26%|██▌       | 1421/5475 [3:55:36<11:24:32, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1431: Loss = 0.2213, Reward Loss = 0.2201, Mean Reward = 0.3930,Mask_loss = 0.0230 mask_mean = 0.2574:  26%|██▌       | 1431/5475 [3:57:09<10:55:54,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1441: Loss = 0.1781, Reward Loss = 0.1760, Mean Reward = 0.3184,Mask_loss = 0.0416 mask_mean = 0.2754:  26%|██▋       | 1441/5475 [3:58:56<13:16:46, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1451: Loss = 0.2528, Reward Loss = 0.2521, Mean Reward = 0.4247,Mask_loss = 0.0148 mask_mean = 0.3355:  27%|██▋       | 1451/5475 [4:00:42<11:31:36, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1461: Loss = 0.2763, Reward Loss = 0.2747, Mean Reward = 0.4536,Mask_loss = 0.0317 mask_mean = 0.3988:  27%|██▋       | 1461/5475 [4:02:15<11:03:02,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1471: Loss = 0.2375, Reward Loss = 0.2371, Mean Reward = 0.4198,Mask_loss = 0.0089 mask_mean = 0.2868:  27%|██▋       | 1471/5475 [4:03:52<10:47:26,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1481: Loss = 0.2674, Reward Loss = 0.2662, Mean Reward = 0.4592,Mask_loss = 0.0239 mask_mean = 0.3357:  27%|██▋       | 1481/5475 [4:05:20<9:42:27,  8.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1491: Loss = 0.2461, Reward Loss = 0.2450, Mean Reward = 0.4291,Mask_loss = 0.0217 mask_mean = 0.2914:  27%|██▋       | 1491/5475 [4:07:00<10:58:43,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1501: Loss = 0.2438, Reward Loss = 0.2425, Mean Reward = 0.4182,Mask_loss = 0.0250 mask_mean = 0.3198:  27%|██▋       | 1501/5475 [4:08:35<10:44:00,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1511: Loss = 0.2907, Reward Loss = 0.2889, Mean Reward = 0.4736,Mask_loss = 0.0353 mask_mean = 0.3903:  28%|██▊       | 1511/5475 [4:10:14<11:21:01, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1521: Loss = 0.2705, Reward Loss = 0.2688, Mean Reward = 0.4381,Mask_loss = 0.0348 mask_mean = 0.3878:  28%|██▊       | 1521/5475 [4:12:01<12:20:22, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1531: Loss = 0.1975, Reward Loss = 0.1967, Mean Reward = 0.3528,Mask_loss = 0.0169 mask_mean = 0.2703:  28%|██▊       | 1531/5475 [4:13:46<11:27:41, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1541: Loss = 0.2879, Reward Loss = 0.2853, Mean Reward = 0.4533,Mask_loss = 0.0522 mask_mean = 0.4344:  28%|██▊       | 1541/5475 [4:15:40<11:54:39, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1551: Loss = 0.2459, Reward Loss = 0.2436, Mean Reward = 0.4118,Mask_loss = 0.0452 mask_mean = 0.3599:  28%|██▊       | 1551/5475 [4:17:20<11:11:51, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1561: Loss = 0.2146, Reward Loss = 0.2137, Mean Reward = 0.3890,Mask_loss = 0.0184 mask_mean = 0.2633:  29%|██▊       | 1561/5475 [4:18:57<11:20:08, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1571: Loss = 0.2100, Reward Loss = 0.2090, Mean Reward = 0.3821,Mask_loss = 0.0184 mask_mean = 0.2576:  29%|██▊       | 1571/5475 [4:20:40<12:13:39, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1581: Loss = 0.2715, Reward Loss = 0.2694, Mean Reward = 0.4362,Mask_loss = 0.0426 mask_mean = 0.3859:  29%|██▉       | 1581/5475 [4:22:23<10:40:09,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1591: Loss = 0.2762, Reward Loss = 0.2728, Mean Reward = 0.4357,Mask_loss = 0.0673 mask_mean = 0.4631:  29%|██▉       | 1591/5475 [4:24:06<10:26:06,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1601: Loss = 0.1893, Reward Loss = 0.1869, Mean Reward = 0.3488,Mask_loss = 0.0484 mask_mean = 0.2132:  29%|██▉       | 1600/5475 [4:25:44<11:06:34, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1601: Loss = 0.1893, Reward Loss = 0.1869, Mean Reward = 0.3488,Mask_loss = 0.0484 mask_mean = 0.2132:  29%|██▉       | 1601/5475 [4:25:48<10:34:50,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1611: Loss = 0.1797, Reward Loss = 0.1773, Mean Reward = 0.3369,Mask_loss = 0.0483 mask_mean = 0.2149:  29%|██▉       | 1611/5475 [4:27:31<9:57:57,  9.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1621: Loss = 0.2550, Reward Loss = 0.2536, Mean Reward = 0.4249,Mask_loss = 0.0285 mask_mean = 0.3486:  30%|██▉       | 1621/5475 [4:29:10<10:21:33,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1631: Loss = 0.3097, Reward Loss = 0.3058, Mean Reward = 0.4809,Mask_loss = 0.0766 mask_mean = 0.4826:  30%|██▉       | 1631/5475 [4:30:46<10:07:50,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1641: Loss = 0.2368, Reward Loss = 0.2346, Mean Reward = 0.3908,Mask_loss = 0.0435 mask_mean = 0.3748:  30%|██▉       | 1641/5475 [4:32:22<10:18:01,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1651: Loss = 0.2895, Reward Loss = 0.2807, Mean Reward = 0.4731,Mask_loss = 0.1760 mask_mean = 0.6319:  30%|███       | 1651/5475 [4:34:03<10:20:30,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1661: Loss = 0.3050, Reward Loss = 0.2965, Mean Reward = 0.4853,Mask_loss = 0.1698 mask_mean = 0.6173:  30%|███       | 1661/5475 [4:35:52<11:08:28, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1671: Loss = 0.3055, Reward Loss = 0.2984, Mean Reward = 0.4754,Mask_loss = 0.1430 mask_mean = 0.5931:  31%|███       | 1671/5475 [4:37:23<9:31:22,  9.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1681: Loss = 0.2848, Reward Loss = 0.2833, Mean Reward = 0.4630,Mask_loss = 0.0300 mask_mean = 0.3835:  31%|███       | 1681/5475 [4:38:53<9:06:40,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1691: Loss = 0.2799, Reward Loss = 0.2777, Mean Reward = 0.4626,Mask_loss = 0.0439 mask_mean = 0.4152:  31%|███       | 1691/5475 [4:40:33<10:45:23, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1701: Loss = 0.3079, Reward Loss = 0.3015, Mean Reward = 0.4925,Mask_loss = 0.1291 mask_mean = 0.5503:  31%|███       | 1701/5475 [4:42:05<10:58:54, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1711: Loss = 0.2880, Reward Loss = 0.2832, Mean Reward = 0.4413,Mask_loss = 0.0978 mask_mean = 0.5299:  31%|███▏      | 1711/5475 [4:43:42<10:51:33, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1721: Loss = 0.2753, Reward Loss = 0.2742, Mean Reward = 0.4606,Mask_loss = 0.0219 mask_mean = 0.3578:  31%|███▏      | 1721/5475 [4:45:24<10:04:34,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1731: Loss = 0.1340, Reward Loss = 0.1275, Mean Reward = 0.2498,Mask_loss = 0.1301 mask_mean = 0.1389:  32%|███▏      | 1731/5475 [4:47:12<12:26:34, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1741: Loss = 0.1887, Reward Loss = 0.1866, Mean Reward = 0.3472,Mask_loss = 0.0427 mask_mean = 0.2235:  32%|███▏      | 1741/5475 [4:48:41<8:53:18,  8.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1751: Loss = 0.1980, Reward Loss = 0.1953, Mean Reward = 0.3501,Mask_loss = 0.0525 mask_mean = 0.2263:  32%|███▏      | 1751/5475 [4:50:26<10:46:03, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1761: Loss = 0.2471, Reward Loss = 0.2458, Mean Reward = 0.4206,Mask_loss = 0.0257 mask_mean = 0.3242:  32%|███▏      | 1761/5475 [4:52:02<9:23:03,  9.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1771: Loss = 0.2523, Reward Loss = 0.2497, Mean Reward = 0.4198,Mask_loss = 0.0525 mask_mean = 0.3490:  32%|███▏      | 1771/5475 [4:53:41<9:40:25,  9.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1781: Loss = 0.1941, Reward Loss = 0.1927, Mean Reward = 0.3772,Mask_loss = 0.0285 mask_mean = 0.1899:  33%|███▎      | 1781/5475 [4:55:23<10:21:35, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1791: Loss = 0.2874, Reward Loss = 0.2835, Mean Reward = 0.4513,Mask_loss = 0.0791 mask_mean = 0.4749:  33%|███▎      | 1791/5475 [4:57:08<10:43:59, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1801: Loss = 0.2839, Reward Loss = 0.2789, Mean Reward = 0.4491,Mask_loss = 0.0996 mask_mean = 0.5103:  33%|███▎      | 1800/5475 [4:58:43<10:22:11, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1801: Loss = 0.2839, Reward Loss = 0.2789, Mean Reward = 0.4491,Mask_loss = 0.0996 mask_mean = 0.5103:  33%|███▎      | 1801/5475 [4:58:50<11:48:17, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1811: Loss = 0.2947, Reward Loss = 0.2912, Mean Reward = 0.4708,Mask_loss = 0.0693 mask_mean = 0.4691:  33%|███▎      | 1811/5475 [5:00:32<9:59:13,  9.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1821: Loss = 0.3148, Reward Loss = 0.3073, Mean Reward = 0.4986,Mask_loss = 0.1501 mask_mean = 0.5832:  33%|███▎      | 1821/5475 [5:02:16<10:25:57, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1831: Loss = 0.2875, Reward Loss = 0.2780, Mean Reward = 0.4650,Mask_loss = 0.1906 mask_mean = 0.6555:  33%|███▎      | 1831/5475 [5:03:56<9:54:02,  9.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1841: Loss = 0.2919, Reward Loss = 0.2880, Mean Reward = 0.4552,Mask_loss = 0.0770 mask_mean = 0.4838:  34%|███▎      | 1841/5475 [5:05:39<10:33:17, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1851: Loss = 0.2680, Reward Loss = 0.2650, Mean Reward = 0.4300,Mask_loss = 0.0599 mask_mean = 0.4239:  34%|███▍      | 1851/5475 [5:07:24<10:29:37, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1861: Loss = 0.2093, Reward Loss = 0.2071, Mean Reward = 0.3624,Mask_loss = 0.0442 mask_mean = 0.2872:  34%|███▍      | 1861/5475 [5:09:00<10:36:23, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1871: Loss = 0.2276, Reward Loss = 0.2262, Mean Reward = 0.3977,Mask_loss = 0.0280 mask_mean = 0.2979:  34%|███▍      | 1871/5475 [5:10:31<9:13:15,  9.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1881: Loss = 0.2277, Reward Loss = 0.2269, Mean Reward = 0.4075,Mask_loss = 0.0164 mask_mean = 0.2458:  34%|███▍      | 1881/5475 [5:12:04<9:34:16,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1891: Loss = 0.1743, Reward Loss = 0.1714, Mean Reward = 0.3210,Mask_loss = 0.0575 mask_mean = 0.2102:  35%|███▍      | 1891/5475 [5:13:41<9:58:55, 10.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1901: Loss = 0.1562, Reward Loss = 0.1525, Mean Reward = 0.2928,Mask_loss = 0.0730 mask_mean = 0.1880:  35%|███▍      | 1901/5475 [5:15:18<9:30:11,  9.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1911: Loss = 0.2642, Reward Loss = 0.2631, Mean Reward = 0.4395,Mask_loss = 0.0219 mask_mean = 0.3380:  35%|███▍      | 1911/5475 [5:16:48<9:35:46,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1921: Loss = 0.1879, Reward Loss = 0.1863, Mean Reward = 0.3313,Mask_loss = 0.0317 mask_mean = 0.2646:  35%|███▌      | 1921/5475 [5:18:29<9:10:56,  9.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1931: Loss = 0.2531, Reward Loss = 0.2525, Mean Reward = 0.4352,Mask_loss = 0.0120 mask_mean = 0.3070:  35%|███▌      | 1931/5475 [5:20:07<10:08:42, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1941: Loss = 0.2535, Reward Loss = 0.2523, Mean Reward = 0.4057,Mask_loss = 0.0246 mask_mean = 0.3802:  35%|███▌      | 1941/5475 [5:21:39<9:09:38,  9.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1951: Loss = 0.2709, Reward Loss = 0.2656, Mean Reward = 0.4262,Mask_loss = 0.1068 mask_mean = 0.5491:  36%|███▌      | 1951/5475 [5:23:15<9:13:51,  9.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1961: Loss = 0.2926, Reward Loss = 0.2908, Mean Reward = 0.4658,Mask_loss = 0.0366 mask_mean = 0.4032:  36%|███▌      | 1961/5475 [5:25:04<11:23:58, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1971: Loss = 0.2225, Reward Loss = 0.2205, Mean Reward = 0.3862,Mask_loss = 0.0398 mask_mean = 0.2971:  36%|███▌      | 1971/5475 [5:26:42<9:37:46,  9.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1981: Loss = 0.2920, Reward Loss = 0.2868, Mean Reward = 0.4573,Mask_loss = 0.1045 mask_mean = 0.5247:  36%|███▌      | 1981/5475 [5:28:19<10:32:18, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1991: Loss = 0.2016, Reward Loss = 0.2003, Mean Reward = 0.3650,Mask_loss = 0.0258 mask_mean = 0.2545:  36%|███▋      | 1991/5475 [5:29:59<9:30:03,  9.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2001: Loss = 0.2535, Reward Loss = 0.2519, Mean Reward = 0.4251,Mask_loss = 0.0321 mask_mean = 0.3447:  37%|███▋      | 2000/5475 [5:31:39<10:03:30, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2001: Loss = 0.2535, Reward Loss = 0.2519, Mean Reward = 0.4251,Mask_loss = 0.0321 mask_mean = 0.3447:  37%|███▋      | 2001/5475 [5:31:44<10:01:32, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2011: Loss = 0.2595, Reward Loss = 0.2583, Mean Reward = 0.4243,Mask_loss = 0.0249 mask_mean = 0.3931:  37%|███▋      | 2011/5475 [5:33:23<10:27:16, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2021: Loss = 0.3043, Reward Loss = 0.2991, Mean Reward = 0.4919,Mask_loss = 0.1052 mask_mean = 0.5140:  37%|███▋      | 2021/5475 [5:34:53<8:49:11,  9.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2031: Loss = 0.2894, Reward Loss = 0.2860, Mean Reward = 0.4611,Mask_loss = 0.0685 mask_mean = 0.4771:  37%|███▋      | 2031/5475 [5:36:42<9:49:36, 10.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2041: Loss = 0.2620, Reward Loss = 0.2599, Mean Reward = 0.4245,Mask_loss = 0.0431 mask_mean = 0.4242:  37%|███▋      | 2041/5475 [5:38:22<9:03:46,  9.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2051: Loss = 0.2441, Reward Loss = 0.2431, Mean Reward = 0.4248,Mask_loss = 0.0198 mask_mean = 0.3018:  37%|███▋      | 2051/5475 [5:40:08<10:52:27, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2061: Loss = 0.2619, Reward Loss = 0.2600, Mean Reward = 0.4201,Mask_loss = 0.0381 mask_mean = 0.4045:  38%|███▊      | 2061/5475 [5:41:42<8:50:02,  9.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2071: Loss = 0.2389, Reward Loss = 0.2379, Mean Reward = 0.3962,Mask_loss = 0.0201 mask_mean = 0.3468:  38%|███▊      | 2071/5475 [5:43:23<9:33:26, 10.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2081: Loss = 0.2526, Reward Loss = 0.2501, Mean Reward = 0.4108,Mask_loss = 0.0482 mask_mean = 0.4074:  38%|███▊      | 2081/5475 [5:44:59<9:43:39, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2091: Loss = 0.2911, Reward Loss = 0.2886, Mean Reward = 0.4607,Mask_loss = 0.0512 mask_mean = 0.4283:  38%|███▊      | 2091/5475 [5:46:46<9:15:08,  9.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2101: Loss = 0.2586, Reward Loss = 0.2574, Mean Reward = 0.4189,Mask_loss = 0.0243 mask_mean = 0.3898:  38%|███▊      | 2101/5475 [5:48:29<9:05:20,  9.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2111: Loss = 0.2284, Reward Loss = 0.2277, Mean Reward = 0.3959,Mask_loss = 0.0142 mask_mean = 0.2985:  39%|███▊      | 2111/5475 [5:50:13<9:49:16, 10.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2121: Loss = 0.2480, Reward Loss = 0.2470, Mean Reward = 0.4254,Mask_loss = 0.0193 mask_mean = 0.3160:  39%|███▊      | 2121/5475 [5:52:01<10:55:59, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2131: Loss = 0.2355, Reward Loss = 0.2344, Mean Reward = 0.3942,Mask_loss = 0.0230 mask_mean = 0.3394:  39%|███▉      | 2131/5475 [5:53:49<10:43:01, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2141: Loss = 0.1845, Reward Loss = 0.1830, Mean Reward = 0.3501,Mask_loss = 0.0301 mask_mean = 0.2287:  39%|███▉      | 2141/5475 [5:55:22<8:58:47,  9.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2151: Loss = 0.2764, Reward Loss = 0.2737, Mean Reward = 0.4416,Mask_loss = 0.0555 mask_mean = 0.4413:  39%|███▉      | 2151/5475 [5:56:55<9:02:27,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2161: Loss = 0.2922, Reward Loss = 0.2899, Mean Reward = 0.4605,Mask_loss = 0.0459 mask_mean = 0.4247:  39%|███▉      | 2161/5475 [5:58:44<9:01:17,  9.80s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2171: Loss = 0.2719, Reward Loss = 0.2703, Mean Reward = 0.4468,Mask_loss = 0.0312 mask_mean = 0.3987:  40%|███▉      | 2171/5475 [6:00:28<9:03:24,  9.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2181: Loss = 0.1822, Reward Loss = 0.1798, Mean Reward = 0.3540,Mask_loss = 0.0479 mask_mean = 0.1856:  40%|███▉      | 2181/5475 [6:02:07<8:31:14,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2191: Loss = 0.1496, Reward Loss = 0.1455, Mean Reward = 0.2885,Mask_loss = 0.0805 mask_mean = 0.1574:  40%|████      | 2191/5475 [6:03:38<8:28:59,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2201: Loss = 0.2476, Reward Loss = 0.2461, Mean Reward = 0.4048,Mask_loss = 0.0307 mask_mean = 0.3749:  40%|████      | 2200/5475 [6:05:17<8:54:18,  9.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2201: Loss = 0.2476, Reward Loss = 0.2461, Mean Reward = 0.4048,Mask_loss = 0.0307 mask_mean = 0.3749:  40%|████      | 2201/5475 [6:05:23<9:04:20,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2211: Loss = 0.2323, Reward Loss = 0.2307, Mean Reward = 0.3856,Mask_loss = 0.0312 mask_mean = 0.3305:  40%|████      | 2211/5475 [6:07:06<9:21:09, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2221: Loss = 0.2380, Reward Loss = 0.2369, Mean Reward = 0.4109,Mask_loss = 0.0213 mask_mean = 0.3181:  41%|████      | 2221/5475 [6:08:42<9:23:34, 10.39s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2231: Loss = 0.2583, Reward Loss = 0.2575, Mean Reward = 0.4513,Mask_loss = 0.0157 mask_mean = 0.2987:  41%|████      | 2231/5475 [6:10:22<8:28:43,  9.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2241: Loss = 0.2468, Reward Loss = 0.2460, Mean Reward = 0.4327,Mask_loss = 0.0156 mask_mean = 0.2997:  41%|████      | 2241/5475 [6:12:01<8:49:22,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2251: Loss = 0.2795, Reward Loss = 0.2781, Mean Reward = 0.4735,Mask_loss = 0.0275 mask_mean = 0.3633:  41%|████      | 2251/5475 [6:13:45<8:42:38,  9.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2261: Loss = 0.2409, Reward Loss = 0.2406, Mean Reward = 0.4402,Mask_loss = 0.0064 mask_mean = 0.2660:  41%|████▏     | 2261/5475 [6:15:35<8:50:43,  9.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2271: Loss = 0.2901, Reward Loss = 0.2884, Mean Reward = 0.4629,Mask_loss = 0.0344 mask_mean = 0.3902:  41%|████▏     | 2271/5475 [6:17:22<8:51:15,  9.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2281: Loss = 0.2598, Reward Loss = 0.2585, Mean Reward = 0.4310,Mask_loss = 0.0250 mask_mean = 0.3787:  42%|████▏     | 2281/5475 [6:18:58<8:09:58,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2291: Loss = 0.2909, Reward Loss = 0.2890, Mean Reward = 0.4844,Mask_loss = 0.0379 mask_mean = 0.3856:  42%|████▏     | 2291/5475 [6:20:44<9:35:23, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2301: Loss = 0.2867, Reward Loss = 0.2848, Mean Reward = 0.4713,Mask_loss = 0.0362 mask_mean = 0.3833:  42%|████▏     | 2301/5475 [6:22:26<8:43:14,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2311: Loss = 0.2091, Reward Loss = 0.2069, Mean Reward = 0.3668,Mask_loss = 0.0439 mask_mean = 0.2975:  42%|████▏     | 2311/5475 [6:24:05<8:12:06,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2321: Loss = 0.2887, Reward Loss = 0.2875, Mean Reward = 0.4661,Mask_loss = 0.0245 mask_mean = 0.3677:  42%|████▏     | 2321/5475 [6:25:36<8:04:44,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2331: Loss = 0.3058, Reward Loss = 0.3028, Mean Reward = 0.4946,Mask_loss = 0.0589 mask_mean = 0.4316:  43%|████▎     | 2331/5475 [6:27:21<9:41:09, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2341: Loss = 0.3008, Reward Loss = 0.2968, Mean Reward = 0.4664,Mask_loss = 0.0794 mask_mean = 0.4874:  43%|████▎     | 2341/5475 [6:28:52<8:00:17,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2351: Loss = 0.2445, Reward Loss = 0.2435, Mean Reward = 0.4140,Mask_loss = 0.0190 mask_mean = 0.3142:  43%|████▎     | 2351/5475 [6:30:35<8:27:09,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2361: Loss = 0.2786, Reward Loss = 0.2772, Mean Reward = 0.4541,Mask_loss = 0.0276 mask_mean = 0.3657:  43%|████▎     | 2361/5475 [6:32:14<8:08:51,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2371: Loss = 0.2806, Reward Loss = 0.2790, Mean Reward = 0.4534,Mask_loss = 0.0307 mask_mean = 0.3854:  43%|████▎     | 2371/5475 [6:34:00<7:57:02,  9.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2381: Loss = 0.2322, Reward Loss = 0.2316, Mean Reward = 0.4091,Mask_loss = 0.0133 mask_mean = 0.2788:  43%|████▎     | 2381/5475 [6:35:43<9:10:02, 10.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2391: Loss = 0.2970, Reward Loss = 0.2947, Mean Reward = 0.4649,Mask_loss = 0.0450 mask_mean = 0.4391:  44%|████▎     | 2391/5475 [6:37:31<8:28:39,  9.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2401: Loss = 0.2618, Reward Loss = 0.2605, Mean Reward = 0.4414,Mask_loss = 0.0257 mask_mean = 0.3140:  44%|████▍     | 2400/5475 [6:38:59<7:50:29,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2401: Loss = 0.2618, Reward Loss = 0.2605, Mean Reward = 0.4414,Mask_loss = 0.0257 mask_mean = 0.3140:  44%|████▍     | 2401/5475 [6:39:04<8:08:57,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2411: Loss = 0.2578, Reward Loss = 0.2567, Mean Reward = 0.4120,Mask_loss = 0.0218 mask_mean = 0.3991:  44%|████▍     | 2411/5475 [6:40:34<7:29:24,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2421: Loss = 0.2639, Reward Loss = 0.2628, Mean Reward = 0.4388,Mask_loss = 0.0218 mask_mean = 0.3327:  44%|████▍     | 2421/5475 [6:42:06<7:50:26,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2431: Loss = 0.2988, Reward Loss = 0.2929, Mean Reward = 0.4683,Mask_loss = 0.1187 mask_mean = 0.5495:  44%|████▍     | 2431/5475 [6:43:47<7:34:57,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2441: Loss = 0.1625, Reward Loss = 0.1600, Mean Reward = 0.3078,Mask_loss = 0.0494 mask_mean = 0.2114:  45%|████▍     | 2441/5475 [6:45:23<7:41:45,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2451: Loss = 0.2240, Reward Loss = 0.2230, Mean Reward = 0.3977,Mask_loss = 0.0200 mask_mean = 0.2794:  45%|████▍     | 2451/5475 [6:47:10<8:58:24, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2461: Loss = 0.2421, Reward Loss = 0.2413, Mean Reward = 0.4201,Mask_loss = 0.0167 mask_mean = 0.2976:  45%|████▍     | 2461/5475 [6:48:55<9:34:49, 11.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2471: Loss = 0.2154, Reward Loss = 0.2144, Mean Reward = 0.3883,Mask_loss = 0.0218 mask_mean = 0.2671:  45%|████▌     | 2471/5475 [6:50:31<8:30:24, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2481: Loss = 0.2233, Reward Loss = 0.2224, Mean Reward = 0.3849,Mask_loss = 0.0187 mask_mean = 0.3154:  45%|████▌     | 2481/5475 [6:52:14<8:42:52, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2491: Loss = 0.2383, Reward Loss = 0.2374, Mean Reward = 0.4053,Mask_loss = 0.0178 mask_mean = 0.3181:  45%|████▌     | 2491/5475 [6:54:06<8:31:22, 10.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2501: Loss = 0.2429, Reward Loss = 0.2419, Mean Reward = 0.4027,Mask_loss = 0.0203 mask_mean = 0.3431:  46%|████▌     | 2501/5475 [6:55:41<7:51:22,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2511: Loss = 0.2290, Reward Loss = 0.2281, Mean Reward = 0.4109,Mask_loss = 0.0181 mask_mean = 0.2542:  46%|████▌     | 2511/5475 [6:57:40<9:26:59, 11.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2521: Loss = 0.2342, Reward Loss = 0.2336, Mean Reward = 0.4020,Mask_loss = 0.0120 mask_mean = 0.3372:  46%|████▌     | 2521/5475 [6:59:20<7:53:12,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2530: Loss = 0.1483, Reward Loss = 0.1442, Mean Reward = 0.2899,Mask_loss = 0.0816 mask_mean = 0.1463:  46%|████▌     | 2530/5475 [7:00:56<8:09:59,  9.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m     last_hidden_state \u001b[38;5;241m=\u001b[39m last_hidden_state\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     41\u001b[0m mask_logits \u001b[38;5;241m=\u001b[39m mask_gen_model(last_hidden_state)\n\u001b[0;32m---> 43\u001b[0m mask_gen_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmask_gen_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                                                   \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m loss, reward_loss, mask_loss, mask_mean, mean_reward \u001b[38;5;241m=\u001b[39m mask_gen_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], mask_gen_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], mask_gen_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], mask_gen_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_mean\u001b[39m\u001b[38;5;124m'\u001b[39m], mask_gen_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_reward\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m log \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m     47\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Reward = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_reward\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_mean = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_mean\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m~/wd/llm_explain/llmexp/squad_model.py:205\u001b[0m, in \u001b[0;36mMaskGeneratingModel.loss_func\u001b[0;34m(self, model, gen_tokens, gen_attention_mask, context_mask, mask_logits, response_mask, num_samples)\u001b[0m\n\u001b[1;32m    202\u001b[0m sim_gt, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_sim(model, gen_tokens, gen_attention_mask, response_mask, labels\u001b[38;5;241m=\u001b[39mgen_tokens)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m perturbed_input_ids, perturbed_attention_mask, user_input_mask \u001b[38;5;129;01min\u001b[39;00m perturbed_samples:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# obtain the similarity of the perturbed samples\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     sim, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbed_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbed_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_reward(sim, sim_gt) \n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# reward = torch.exp(sim)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/wd/llm_explain/llmexp/squad_model.py:163\u001b[0m, in \u001b[0;36mMaskGeneratingModel.calculate_sim\u001b[0;34m(self, model, input_ids, attention_mask, response_mask, labels)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_sim\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, input_ids, attention_mask, response_mask, labels):\n\u001b[0;32m--> 163\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# shift labels and response_mask to the left by one to match the next token prediction format\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1164\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:968\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    957\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    958\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    959\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    965\u001b[0m         cache_position,\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:710\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    708\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 710\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    713\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    714\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    715\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    720\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    721\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:87\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     85\u001b[0m input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     86\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 87\u001b[0m variance \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask_gen_model.train()\n",
    "for epoch in range(1):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        context_mask = data['context_mask'].to(device)\n",
    "        # get generated texts\n",
    "        gen_outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "        gen_tokens = gen_outputs.sequences\n",
    "        pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "        # get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "        gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "        # (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "        unpaded_token_mask = (gen_tokens != pad_token_id).long()\n",
    "        unpaded_token_mask[:, :-pad_length] = 1\n",
    "        gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "        # get the response mask, which is the mask for the generated tokens (the user inputs are masked with 0)\n",
    "        response_mask = gen_attention_mask.clone()\n",
    "        response_mask[:, :-pad_length] = 0 # TODO: 有问题. 有问题吗？\n",
    "\n",
    "        context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "        # Get the last hidden state for the prompt + response sequence\n",
    "        with torch.no_grad():\n",
    "            full_outputs = model(input_ids=gen_tokens, attention_mask=gen_attention_mask, output_hidden_states=True, return_dict=True)\n",
    "            last_hidden_state = full_outputs.hidden_states[-1]\n",
    "            last_hidden_state = last_hidden_state.float()\n",
    "        \n",
    "        mask_logits = mask_gen_model(last_hidden_state)\n",
    "\n",
    "        mask_gen_outputs = mask_gen_model.loss_func(model, gen_tokens, gen_attention_mask, context_mask, mask_logits, response_mask, \n",
    "                                                                           num_samples=5)\n",
    "        loss, reward_loss, mask_loss, mask_mean, mean_reward = mask_gen_outputs['loss'], mask_gen_outputs['reward_loss'], mask_gen_outputs['mask_loss'], mask_gen_outputs['mask_mean'], mask_gen_outputs['mean_reward']\n",
    "        log = (f\"Epoch {epoch+1}, Step {idx+1}: Loss = {loss.item():.4f}, \" \n",
    "                             f\"Reward Loss = {reward_loss.item():.4f}, \"\n",
    "                             f\"Mean Reward = {mean_reward.mean().item():.4f},\"\n",
    "                             f\"Mask_loss = {mask_loss.item():.4f} \"\n",
    "                             f\"mask_mean = {mask_mean.item():.4f}\"\n",
    "        )\n",
    "        pbar.set_description(log)\n",
    "        logging.debug(log)\n",
    "    \n",
    "        # the parameters before updating\n",
    "        params_before = mask_gen_model.state_dict()\n",
    "\n",
    "        # Train the model (inner loop)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # the mask_prob after the updates\n",
    "        with torch.no_grad():\n",
    "            mask_logits_after = mask_gen_model(last_hidden_state)\n",
    "\n",
    "            mask_gen_outputs_after = mask_gen_model.loss_func(model, gen_tokens, gen_attention_mask, context_mask, mask_logits_after, response_mask, \n",
    "                                                                            num_samples=5)\n",
    "            loss_after, reward_loss_after, mask_loss_after, mask_mean_after, mean_reward_after = mask_gen_outputs_after['loss'], mask_gen_outputs_after['reward_loss'], mask_gen_outputs_after['mask_loss'], mask_gen_outputs_after['mask_mean'], mask_gen_outputs_after['mean_reward']\n",
    "            mask_prob_after = (torch.sigmoid(mask_logits_after) * context_mask).clone().detach()\n",
    "            mean_reward_after = mean_reward_after.clone().detach()\n",
    "\n",
    "        # load the parameters before the updates\n",
    "        mask_gen_model.load_state_dict(params_before)\n",
    "        mask_logits_before = mask_gen_model(last_hidden_state)\n",
    "\n",
    "        mask_gen_outputs_before = mask_gen_model.loss_func(model, gen_tokens, gen_attention_mask, context_mask, mask_logits_before, response_mask, \n",
    "                                                                           num_samples=5)\n",
    "        loss_before, reward_loss_before, mask_loss_before, mask_mean_before, mean_reward_before = mask_gen_outputs_before['loss'], mask_gen_outputs_before['reward_loss'], mask_gen_outputs_before['mask_loss'], mask_gen_outputs_before['mask_mean'], mask_gen_outputs_before['mean_reward']\n",
    "        mask_prob_before = (torch.sigmoid(mask_logits_before) * context_mask)\n",
    "\n",
    "        # calculate the ratio of the mask probabilities before and after the updates\n",
    "        ratio = mask_prob_after / (mask_prob_before + 1e-6)\n",
    "\n",
    "        # 定义PPO的损失函数，假设clip_param是你定义的剪切参数\n",
    "        clip_param = 0.2\n",
    "        advantage = (mean_reward_after - mean_reward_before).unsqueeze(-1)  # 计算优势函数（advantage），这是根据任务定义的\n",
    "        surr1 = ratio * advantage\n",
    "        surr2 = torch.clamp(ratio, 1 - clip_param, 1 + clip_param) * advantage\n",
    "        ppo_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "        # 更新模型参数\n",
    "        optimizer.zero_grad()\n",
    "        ppo_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print()\n",
    "        if idx % 200 == 0 and idx != 0:\n",
    "            torch.save(mask_gen_model.state_dict(), f'saved_model/mask_gen_model_{epoch}_{idx}.pth') \n",
    "            print()\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 417])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx = 0\n",
    "from captum.attr import visualization as viz\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mask_gen_model.eval()\n",
    "\n",
    "# tokens = tokenizer.convert_ids_to_tokens(gen_tokens[idx])\n",
    "# texts = \"This movie was the best movie I have ever seen! some scenes were ridiculous, but acting was great.\"\n",
    "# texts = \"I did not like this movie. Some of the actors were good, but overall the movie was boring.\"\n",
    "# texts = \"I hate that I love you.\"\n",
    "# texts = \"I don't like this movie.\"\n",
    "# texts = \"I really love this film.\"\n",
    "# texts = \"I really love this film. The acting was great, and the story was amazing. I would recommend this movie to everyone.\"\n",
    "# # texts = \"I don't like this movie. The acting was terrible, and the story was boring. I would not recommend this movie to anyone.\"\n",
    "# messages_lambda = lambda texts: [\n",
    "#             {\"role\": \"system\", \"content\": \"Answer the question based on the context.\"},\n",
    "#             # {\"role\": \"system\", \"content\": \"You are a chatbot for sentimate analysis.\"},\n",
    "#             {\"role\": \"user\", \"content\": texts},\n",
    "#         ]\n",
    "# messages = messages_lambda(texts)\n",
    "# messages_with_template_applied = tokenizer.apply_chat_template(\n",
    "#             messages,\n",
    "#             tokenize=False,\n",
    "#             add_generation_prompt=True,\n",
    "#         )\n",
    "\n",
    "# # test_text = [{\"text\": texts, \"label\": None}]\n",
    "# test_text = [{\"sentence\": texts, \"label\": None}]\n",
    "# test_inputs = collate_fn(test_text).to(device)\n",
    "\n",
    "test_inputs = next(iter(test_dataloader)).to(device)\n",
    "tokens = tokenizer.convert_ids_to_tokens(test_inputs['input_ids'][idx])\n",
    "\n",
    "# generate the answer for the test inputs\n",
    "gen_outputs = model.generate(\n",
    "            input_ids=test_inputs['input_ids'],\n",
    "            attention_mask=test_inputs['attention_mask'],\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "input_ids = test_inputs['input_ids']\n",
    "attention_mask = test_inputs['attention_mask']\n",
    "gen_tokens = gen_outputs.sequences\n",
    "pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "# get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "context_mask = F.pad(test_inputs['context_mask'], (0, pad_length), mode='constant', value=0)\n",
    "# (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "unpaded_token_mask = (gen_tokens != pad_token_id).long()\n",
    "unpaded_token_mask[:, :-pad_length] = 1\n",
    "gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "\n",
    "with torch.no_grad():\n",
    "    # prompt_outputs = model(input_ids=test_inputs['input_ids'], attention_mask=test_inputs['attention_mask'], output_hidden_states=True, return_dict=True)\n",
    "    prompt_outputs = model(input_ids=gen_tokens, attention_mask=gen_attention_mask, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "    last_hidden_state = prompt_outputs.hidden_states[-1].float()\n",
    "    mask_logits = mask_gen_model(last_hidden_state)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "test_ids = gen_tokens[idx]\n",
    "test_mask = gen_attention_mask[idx]\n",
    "test_mask_prob = torch.sigmoid(mask_logits[idx])\n",
    "test_context_mask = context_mask[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: rgb(255, 255, 255); color: black;\"><|start_header_id|>system<|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><br><br></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">You</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">are</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">a</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">chatbot</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">for</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">answering</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">questions.</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">You</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">can</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">help</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">users</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">with</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">their</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">questions</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">via</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">concise</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">responses.<|start_header_id|>user<|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><br><br></span> <span style=\"background-color: rgb(190, 255, 190); color: black;\">Context:</span> <span style=\"background-color: rgb(246, 255, 246); color: black;\">Super</span> <span style=\"background-color: rgb(236, 255, 236); color: black;\">Bowl</span> <span style=\"background-color: rgb(229, 255, 229); color: black;\">50</span> <span style=\"background-color: rgb(242, 255, 242); color: black;\">was</span> <span style=\"background-color: rgb(202, 255, 202); color: black;\">an</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">American</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">football</span> <span style=\"background-color: rgb(226, 255, 226); color: black;\">game</span> <span style=\"background-color: rgb(208, 255, 208); color: black;\">to</span> <span style=\"background-color: rgb(204, 255, 204); color: black;\">determine</span> <span style=\"background-color: rgb(200, 255, 200); color: black;\">the</span> <span style=\"background-color: rgb(230, 255, 230); color: black;\">champion</span> <span style=\"background-color: rgb(193, 255, 193); color: black;\">of</span> <span style=\"background-color: rgb(218, 255, 218); color: black;\">the</span> <span style=\"background-color: rgb(230, 255, 230); color: black;\">National</span> <span style=\"background-color: rgb(243, 255, 243); color: black;\">Football</span> <span style=\"background-color: rgb(217, 255, 217); color: black;\">League</span> <span style=\"background-color: rgb(217, 255, 217); color: black;\">(NFL)</span> <span style=\"background-color: rgb(190, 255, 190); color: black;\">for</span> <span style=\"background-color: rgb(198, 255, 198); color: black;\">the</span> <span style=\"background-color: rgb(228, 255, 228); color: black;\">2015</span> <span style=\"background-color: rgb(229, 255, 229); color: black;\">season.</span> <span style=\"background-color: rgb(220, 255, 220); color: black;\">The</span> <span style=\"background-color: rgb(240, 255, 240); color: black;\">American</span> <span style=\"background-color: rgb(239, 255, 239); color: black;\">Football</span> <span style=\"background-color: rgb(241, 255, 241); color: black;\">Conference</span> <span style=\"background-color: rgb(226, 255, 226); color: black;\">(AFC)</span> <span style=\"background-color: rgb(248, 255, 248); color: black;\">champion</span> <span style=\"background-color: rgb(237, 255, 237); color: black;\">Denver</span> <span style=\"background-color: rgb(216, 255, 216); color: black;\">Broncos</span> <span style=\"background-color: rgb(224, 255, 224); color: black;\">defeated</span> <span style=\"background-color: rgb(238, 255, 238); color: black;\">the</span> <span style=\"background-color: rgb(233, 255, 233); color: black;\">National</span> <span style=\"background-color: rgb(204, 255, 204); color: black;\">Football</span> <span style=\"background-color: rgb(238, 255, 238); color: black;\">Conference</span> <span style=\"background-color: rgb(205, 255, 205); color: black;\">(NFC)</span> <span style=\"background-color: rgb(244, 255, 244); color: black;\">champion</span> <span style=\"background-color: rgb(225, 255, 225); color: black;\">Carolina</span> <span style=\"background-color: rgb(242, 255, 242); color: black;\">Panthers</span> <span style=\"background-color: rgb(230, 255, 230); color: black;\">24âĢĵ10</span> <span style=\"background-color: rgb(236, 255, 236); color: black;\">to</span> <span style=\"background-color: rgb(228, 255, 228); color: black;\">earn</span> <span style=\"background-color: rgb(243, 255, 243); color: black;\">their</span> <span style=\"background-color: rgb(230, 255, 230); color: black;\">third</span> <span style=\"background-color: rgb(238, 255, 238); color: black;\">Super</span> <span style=\"background-color: rgb(235, 255, 235); color: black;\">Bowl</span> <span style=\"background-color: rgb(237, 255, 237); color: black;\">title.</span> <span style=\"background-color: rgb(233, 255, 233); color: black;\">The</span> <span style=\"background-color: rgb(237, 255, 237); color: black;\">game</span> <span style=\"background-color: rgb(226, 255, 226); color: black;\">was</span> <span style=\"background-color: rgb(206, 255, 206); color: black;\">played</span> <span style=\"background-color: rgb(202, 255, 202); color: black;\">on</span> <span style=\"background-color: rgb(212, 255, 212); color: black;\">February</span> <span style=\"background-color: rgb(205, 255, 205); color: black;\">7,</span> <span style=\"background-color: rgb(231, 255, 231); color: black;\">2016,</span> <span style=\"background-color: rgb(204, 255, 204); color: black;\">at</span> <span style=\"background-color: rgb(180, 255, 180); color: black;\">Levi's</span> <span style=\"background-color: rgb(222, 255, 222); color: black;\">Stadium</span> <span style=\"background-color: rgb(218, 255, 218); color: black;\">in</span> <span style=\"background-color: rgb(195, 255, 195); color: black;\">the</span> <span style=\"background-color: rgb(225, 255, 225); color: black;\">San</span> <span style=\"background-color: rgb(196, 255, 196); color: black;\">Francisco</span> <span style=\"background-color: rgb(226, 255, 226); color: black;\">Bay</span> <span style=\"background-color: rgb(236, 255, 236); color: black;\">Area</span> <span style=\"background-color: rgb(152, 255, 152); color: black;\">at</span> <span style=\"background-color: rgb(236, 255, 236); color: black;\">Santa</span> <span style=\"background-color: rgb(222, 255, 222); color: black;\">Clara,</span> <span style=\"background-color: rgb(226, 255, 226); color: black;\">California.</span> <span style=\"background-color: rgb(222, 255, 222); color: black;\">As</span> <span style=\"background-color: rgb(241, 255, 241); color: black;\">this</span> <span style=\"background-color: rgb(241, 255, 241); color: black;\">was</span> <span style=\"background-color: rgb(221, 255, 221); color: black;\">the</span> <span style=\"background-color: rgb(214, 255, 214); color: black;\">50th</span> <span style=\"background-color: rgb(224, 255, 224); color: black;\">Super</span> <span style=\"background-color: rgb(219, 255, 219); color: black;\">Bowl,</span> <span style=\"background-color: rgb(192, 255, 192); color: black;\">the</span> <span style=\"background-color: rgb(211, 255, 211); color: black;\">league</span> <span style=\"background-color: rgb(207, 255, 207); color: black;\">emphasized</span> <span style=\"background-color: rgb(216, 255, 216); color: black;\">the</span> <span style=\"background-color: rgb(185, 255, 185); color: black;\">\"golden</span> <span style=\"background-color: rgb(219, 255, 219); color: black;\">anniversary\"</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">with</span> <span style=\"background-color: rgb(232, 255, 232); color: black;\">various</span> <span style=\"background-color: rgb(205, 255, 205); color: black;\">gold-themed</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">initiatives,</span> <span style=\"background-color: rgb(216, 255, 216); color: black;\">as</span> <span style=\"background-color: rgb(224, 255, 224); color: black;\">well</span> <span style=\"background-color: rgb(206, 255, 206); color: black;\">as</span> <span style=\"background-color: rgb(215, 255, 215); color: black;\">temporarily</span> <span style=\"background-color: rgb(215, 255, 215); color: black;\">suspending</span> <span style=\"background-color: rgb(232, 255, 232); color: black;\">the</span> <span style=\"background-color: rgb(236, 255, 236); color: black;\">tradition</span> <span style=\"background-color: rgb(239, 255, 239); color: black;\">of</span> <span style=\"background-color: rgb(202, 255, 202); color: black;\">naming</span> <span style=\"background-color: rgb(221, 255, 221); color: black;\">each</span> <span style=\"background-color: rgb(242, 255, 242); color: black;\">Super</span> <span style=\"background-color: rgb(182, 255, 182); color: black;\">Bowl</span> <span style=\"background-color: rgb(207, 255, 207); color: black;\">game</span> <span style=\"background-color: rgb(220, 255, 220); color: black;\">with</span> <span style=\"background-color: rgb(228, 255, 228); color: black;\">Roman</span> <span style=\"background-color: rgb(230, 255, 230); color: black;\">numerals</span> <span style=\"background-color: rgb(225, 255, 225); color: black;\">(under</span> <span style=\"background-color: rgb(234, 255, 234); color: black;\">which</span> <span style=\"background-color: rgb(235, 255, 235); color: black;\">the</span> <span style=\"background-color: rgb(245, 255, 245); color: black;\">game</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">would</span> <span style=\"background-color: rgb(243, 255, 243); color: black;\">have</span> <span style=\"background-color: rgb(232, 255, 232); color: black;\">been</span> <span style=\"background-color: rgb(231, 255, 231); color: black;\">known</span> <span style=\"background-color: rgb(237, 255, 237); color: black;\">as</span> <span style=\"background-color: rgb(223, 255, 223); color: black;\">\"Super</span> <span style=\"background-color: rgb(215, 255, 215); color: black;\">Bowl</span> <span style=\"background-color: rgb(217, 255, 217); color: black;\">L\"),</span> <span style=\"background-color: rgb(227, 255, 227); color: black;\">so</span> <span style=\"background-color: rgb(235, 255, 235); color: black;\">that</span> <span style=\"background-color: rgb(222, 255, 222); color: black;\">the</span> <span style=\"background-color: rgb(245, 255, 245); color: black;\">logo</span> <span style=\"background-color: rgb(229, 255, 229); color: black;\">could</span> <span style=\"background-color: rgb(196, 255, 196); color: black;\">prominently</span> <span style=\"background-color: rgb(224, 255, 224); color: black;\">feature</span> <span style=\"background-color: rgb(211, 255, 211); color: black;\">the</span> <span style=\"background-color: rgb(232, 255, 232); color: black;\">Arabic</span> <span style=\"background-color: rgb(237, 255, 237); color: black;\">numerals</span> <span style=\"background-color: rgb(231, 255, 231); color: black;\">50</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><br><br></span> <span style=\"background-color: rgb(193, 255, 193); color: black;\">Question:</span> <span style=\"background-color: rgb(211, 255, 211); color: black;\">Which</span> <span style=\"background-color: rgb(195, 255, 195); color: black;\">NFL</span> <span style=\"background-color: rgb(198, 255, 198); color: black;\">team</span> <span style=\"background-color: rgb(177, 255, 177); color: black;\">represented</span> <span style=\"background-color: rgb(210, 255, 210); color: black;\">the</span> <span style=\"background-color: rgb(199, 255, 199); color: black;\">AFC</span> <span style=\"background-color: rgb(224, 255, 224); color: black;\">at</span> <span style=\"background-color: rgb(223, 255, 223); color: black;\">Super</span> <span style=\"background-color: rgb(224, 255, 224); color: black;\">Bowl</span> <span style=\"background-color: rgb(231, 255, 231); color: black;\">50?<|start_header_id|>assistant<|end_header_id|></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\"><br><br></span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">The</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Denver</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Broncos</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">represented</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">the</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">American</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Football</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Conference</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">(AFC)</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">at</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Super</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">Bowl</span> <span style=\"background-color: rgb(255, 255, 255); color: black;\">50.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tokens = tokenizer.convert_ids_to_tokens(test_ids)\n",
    "scores = test_mask_prob * test_context_mask\n",
    "\n",
    "# remove special tokens\n",
    "filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) if token not in tokenizer.all_special_tokens]\n",
    "\n",
    "# combine subwords\n",
    "merged_tokens_scores = []\n",
    "current_token = \"\"\n",
    "current_score = 0\n",
    "count = 0\n",
    "\n",
    "for token, score in filtered_token_scores:\n",
    "    if token.startswith(\"Ġ\"):\n",
    "        if current_token:\n",
    "            merged_tokens_scores.append((current_token, current_score / count))\n",
    "            # merged_tokens_scores.append((\" \", 0))  # 添加空格\n",
    "        current_token = token[1:] # remove the speical character\n",
    "        current_score = score.detach().cpu().numpy()\n",
    "        count = 1\n",
    "    elif token.endswith(\"Ċ\"):\n",
    "        if current_token:\n",
    "            merged_tokens_scores.append((current_token, current_score / count))\n",
    "        merged_tokens_scores.append((\"<br><br>\", 0))  # 添加换行符\n",
    "        current_token = \"\"\n",
    "        current_score = 0\n",
    "        count = 0\n",
    "    else:\n",
    "        current_token += token\n",
    "        current_score += score.detach().cpu().numpy()\n",
    "        count += 1\n",
    "\n",
    "if current_token:\n",
    "    merged_tokens_scores.append((current_token, current_score / count))\n",
    "\n",
    "\n",
    "# 根据分数高亮文本（示例中使用HTML标签）\n",
    "highlighted_text = \"\"\n",
    "for token, score in merged_tokens_scores:\n",
    "    # 动态设置背景颜色：score为0时为白色，score为1时为绿色\n",
    "    red = int((1 - score) * 255)\n",
    "    green = 255\n",
    "    blue = int((1 - score) * 255)\n",
    "    color = f'rgb({red}, {green}, {blue})'\n",
    "    highlighted_text += f'<span style=\"background-color: {color}; color: black;\">{token}</span> '\n",
    "\n",
    "# 打印高亮后的文本\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(highlighted_text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|start_header_id|>system<|end_header_id|>', 0.0),\n",
       " ('<br><br>', 0),\n",
       " ('You', 0.0),\n",
       " ('are', 0.0),\n",
       " ('a', 0.0),\n",
       " ('chatbot', 0.0),\n",
       " ('for', 0.0),\n",
       " ('answering', 0.0),\n",
       " ('questions.', 0.0),\n",
       " ('You', 0.0),\n",
       " ('can', 0.0),\n",
       " ('help', 0.0),\n",
       " ('users', 0.0),\n",
       " ('with', 0.0),\n",
       " ('their', 0.0),\n",
       " ('questions', 0.0),\n",
       " ('via', 0.0),\n",
       " ('concise', 0.0),\n",
       " ('responses.<|start_header_id|>user<|end_header_id|>', 0.0),\n",
       " ('<br><br>', 0),\n",
       " ('Context:', 0.2531610056757927),\n",
       " ('Super', 0.032565828412771225),\n",
       " ('Bowl', 0.07368159294128418),\n",
       " ('50', 0.09878716617822647),\n",
       " ('was', 0.04960312694311142),\n",
       " ('an', 0.20547136664390564),\n",
       " ('American', 0.10978242754936218),\n",
       " ('football', 0.10689886659383774),\n",
       " ('game', 0.11067824810743332),\n",
       " ('to', 0.18042917549610138),\n",
       " ('determine', 0.19631139934062958),\n",
       " ('the', 0.21517875790596008),\n",
       " ('champion', 0.09768622368574142),\n",
       " ('of', 0.24110572040081024),\n",
       " ('the', 0.14212559163570404),\n",
       " ('National', 0.09662216156721115),\n",
       " ('Football', 0.04373268038034439),\n",
       " ('League', 0.148639976978302),\n",
       " ('(NFL)', 0.1486871838569641),\n",
       " ('for', 0.2519562840461731),\n",
       " ('the', 0.2220645695924759),\n",
       " ('2015', 0.10393094023068745),\n",
       " ('season.', 0.09903401136398315),\n",
       " ('The', 0.13509105145931244),\n",
       " ('American', 0.05805166810750961),\n",
       " ('Football', 0.06118558347225189),\n",
       " ('Conference', 0.05126728489995003),\n",
       " ('(AFC)', 0.11027300357818604),\n",
       " ('champion', 0.025766711682081223),\n",
       " ('Denver', 0.06710606068372726),\n",
       " ('Broncos', 0.15097258985042572),\n",
       " ('defeated', 0.11841968446969986),\n",
       " ('the', 0.06498204916715622),\n",
       " ('National', 0.0834752544760704),\n",
       " ('Football', 0.1984666883945465),\n",
       " ('Conference', 0.06375610083341599),\n",
       " ('(NFC)', 0.19222432374954224),\n",
       " ('champion', 0.04209190234541893),\n",
       " ('Carolina', 0.11560268700122833),\n",
       " ('Panthers', 0.050945889204740524),\n",
       " ('24âĢĵ10', 0.094388447701931),\n",
       " ('to', 0.07251233607530594),\n",
       " ('earn', 0.10432492941617966),\n",
       " ('their', 0.04421350732445717),\n",
       " ('third', 0.0957883968949318),\n",
       " ('Super', 0.06528045237064362),\n",
       " ('Bowl', 0.07780145108699799),\n",
       " ('title.', 0.07041171193122864),\n",
       " ('The', 0.08441720902919769),\n",
       " ('game', 0.0691041350364685),\n",
       " ('was', 0.11018164455890656),\n",
       " ('played', 0.1908121407032013),\n",
       " ('on', 0.20772592723369598),\n",
       " ('February', 0.16789239645004272),\n",
       " ('7,', 0.1958644986152649),\n",
       " ('2016,', 0.09352520108222961),\n",
       " ('at', 0.1974194496870041),\n",
       " (\"Levi's\", 0.2930822968482971),\n",
       " ('Stadium', 0.1271902173757553),\n",
       " ('in', 0.1448991298675537),\n",
       " ('the', 0.23306624591350555),\n",
       " ('San', 0.11722037941217422),\n",
       " ('Francisco', 0.23053109645843506),\n",
       " ('Bay', 0.1102646216750145),\n",
       " ('Area', 0.0726504847407341),\n",
       " ('at', 0.40266093611717224),\n",
       " ('Santa', 0.07294287532567978),\n",
       " ('Clara,', 0.1277475357055664),\n",
       " ('California.', 0.11062599718570709),\n",
       " ('As', 0.12818318605422974),\n",
       " ('this', 0.05161221697926521),\n",
       " ('was', 0.05330527201294899),\n",
       " ('the', 0.13280032575130463),\n",
       " ('50th', 0.15827077627182007),\n",
       " ('Super', 0.1191573366522789),\n",
       " ('Bowl,', 0.1376972794532776),\n",
       " ('the', 0.24398964643478394),\n",
       " ('league', 0.1694183200597763),\n",
       " ('emphasized', 0.18586717545986176),\n",
       " ('the', 0.15016454458236694),\n",
       " ('\"golden', 0.2720382809638977),\n",
       " ('anniversary\"', 0.13951528072357178),\n",
       " ('with', 0.10825029760599136),\n",
       " ('various', 0.08747987449169159),\n",
       " ('gold-themed', 0.19324685633182526),\n",
       " ('initiatives,', 0.10662347078323364),\n",
       " ('as', 0.14954417943954468),\n",
       " ('well', 0.1206539124250412),\n",
       " ('as', 0.19099031388759613),\n",
       " ('temporarily', 0.15626147389411926),\n",
       " ('suspending', 0.15392105281352997),\n",
       " ('the', 0.08908480405807495),\n",
       " ('tradition', 0.0741424635052681),\n",
       " ('of', 0.058947861194610596),\n",
       " ('naming', 0.2066492885351181),\n",
       " ('each', 0.13112716376781464),\n",
       " ('Super', 0.05008784309029579),\n",
       " ('Bowl', 0.28331199288368225),\n",
       " ('game', 0.18460099399089813),\n",
       " ('with', 0.13456879556179047),\n",
       " ('Roman', 0.10336141288280487),\n",
       " ('numerals', 0.09509439766407013),\n",
       " ('(under', 0.11752616614103317),\n",
       " ('which', 0.07914171367883682),\n",
       " ('the', 0.07797446846961975),\n",
       " ('game', 0.035420455038547516),\n",
       " ('would', 0.1072394996881485),\n",
       " ('have', 0.04404059797525406),\n",
       " ('been', 0.08793488889932632),\n",
       " ('known', 0.09340020269155502),\n",
       " ('as', 0.06998839229345322),\n",
       " ('\"Super', 0.12478382140398026),\n",
       " ('Bowl', 0.15618300437927246),\n",
       " ('L\"),', 0.14677868783473969),\n",
       " ('so', 0.10894900560379028),\n",
       " ('that', 0.07495832443237305),\n",
       " ('the', 0.12809085845947266),\n",
       " ('logo', 0.03862886503338814),\n",
       " ('could', 0.09874685108661652),\n",
       " ('prominently', 0.22789880633354187),\n",
       " ('feature', 0.120698481798172),\n",
       " ('the', 0.171427920460701),\n",
       " ('Arabic', 0.08971590548753738),\n",
       " ('numerals', 0.06825578212738037),\n",
       " ('50', 0.09231868386268616),\n",
       " ('<br><br>', 0),\n",
       " ('Question:', 0.2407005950808525),\n",
       " ('Which', 0.17170439660549164),\n",
       " ('NFL', 0.23391522467136383),\n",
       " ('team', 0.21967656910419464),\n",
       " ('represented', 0.3049141764640808),\n",
       " ('the', 0.17501309514045715),\n",
       " ('AFC', 0.21933606266975403),\n",
       " ('at', 0.1198345199227333),\n",
       " ('Super', 0.1239071935415268),\n",
       " ('Bowl', 0.1203296035528183),\n",
       " ('50?<|start_header_id|>assistant<|end_header_id|>', 0.09247827529907227),\n",
       " ('<br><br>', 0),\n",
       " ('The', 0.0),\n",
       " ('Denver', 0.0),\n",
       " ('Broncos', 0.0),\n",
       " ('represented', 0.0),\n",
       " ('the', 0.0),\n",
       " ('American', 0.0),\n",
       " ('Football', 0.0),\n",
       " ('Conference', 0.0),\n",
       " ('(AFC)', 0.0),\n",
       " ('at', 0.0),\n",
       " ('Super', 0.0),\n",
       " ('Bowl', 0.0),\n",
       " ('50.', 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_tokens_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 2.4742e-02 6.0288e-01 4.3501e-01 3.8011e-01 7.7301e-02\n",
      " 4.1161e-04 9.5759e-05 8.4586e-01 4.7034e-01 7.6526e-01 9.9955e-03\n",
      " 4.9102e-01 5.7602e-01 6.6518e-01 8.1205e-01 6.8847e-01 1.8136e-03\n",
      " 1.8811e-04 9.5622e-01 9.5475e-01 2.4792e-01 1.1541e-01 1.3485e-01\n",
      " 5.3585e-03 1.0000e+00 0.0000e+00 5.5876e-05 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Set print options for precision\n",
    "torch.set_printoptions(precision=4)\n",
    "np.set_printoptions(precision=4)\n",
    "print(expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.63934755, 0.11451219, 0.1225187 , 0.43457144, 0.21965683,\n",
       "       0.28944358, 0.08941142, 0.10701324, 0.09935488, 0.05571543,\n",
       "       0.03000107, 0.07527877, 0.15953447, 0.22993316, 0.15300442,\n",
       "       0.3738694 , 0.22266376, 0.29959634, 0.4525226 , 0.11873144,\n",
       "       0.2386478 , 0.20134698, 0.11468548, 0.33462942, 0.12546155,\n",
       "       0.29114434, 0.3496375 , 0.27918556, 0.8707584 , 0.42532292,\n",
       "       0.18798777, 0.88152486, 0.7778979 , 0.38002315, 0.0177369 ,\n",
       "       0.34096608, 0.19461636, 0.55110186, 0.40781736, 0.6573673 ,\n",
       "       0.56073976, 0.7197896 , 0.5075476 , 0.49354845, 0.57938504,\n",
       "       0.2639287 , 0.53644824, 0.74284345, 0.43071514, 0.17025682,\n",
       "       0.2519394 , 0.24771284, 0.76228124, 0.03937887, 0.31321433,\n",
       "       0.3951155 , 0.12060348, 0.8391926 , 0.19060197, 0.14503507,\n",
       "       0.38200086, 0.09805975, 0.53167886, 0.45860618, 0.34170774,\n",
       "       0.38000423, 0.49717534, 0.12770228, 0.54148155, 0.88480836,\n",
       "       0.5025979 , 0.2180987 , 0.44277272, 0.7061062 , 0.6001298 ,\n",
       "       0.4190885 , 0.15418284, 0.01286074, 0.03205981, 0.7166164 ,\n",
       "       0.42272195, 0.1009967 , 0.5880632 , 0.06157847, 0.03148317,\n",
       "       0.01150252, 0.14847231, 0.40222263, 0.45739612, 0.29020867,\n",
       "       0.20442684, 0.01632834, 0.00439288, 0.22261323, 0.10954274,\n",
       "       0.735632  , 0.250885  , 0.23412147, 0.52762663, 0.6082385 ,\n",
       "       0.70563006, 0.18747613, 0.03181224, 0.1954265 , 0.46577016,\n",
       "       0.08638231, 0.587938  , 0.17073946, 0.19899334, 0.44022155,\n",
       "       0.28126696, 0.18912274, 0.606753  , 0.2354937 , 0.30333954,\n",
       "       0.9088377 , 0.760515  , 0.00247158, 0.65670216, 0.37467483,\n",
       "       0.8893074 , 0.49679863, 0.8678529 , 0.64698756, 0.921829  ,\n",
       "       0.32185513, 0.11627685, 0.19978185, 0.5822873 , 0.46432415,\n",
       "       0.27071175, 0.26083463, 0.35565257, 0.11644382, 0.12587062,\n",
       "       0.02788724, 0.04585992, 0.23267932, 0.52556354, 0.12978171,\n",
       "       0.05500807, 0.86675435, 0.59887177, 0.13369308, 0.37950924,\n",
       "       0.836148  , 0.1870308 , 0.6357755 , 0.18462983, 0.05141451,\n",
       "       0.2866516 , 0.3967239 , 0.9536885 , 0.36054942, 0.44063833,\n",
       "       0.2609197 , 0.61237025, 0.15894488, 0.21989977, 0.69814706,\n",
       "       0.37813613, 0.8174311 , 0.8459768 , 0.77438444, 0.1087799 ,\n",
       "       0.03142452, 0.8144604 , 0.42925656, 0.87952363, 0.12044684,\n",
       "       0.32651398, 0.3073709 , 0.15482455, 0.03003251, 0.5409264 ,\n",
       "       0.06059632, 0.23830052, 0.28520328, 0.5085325 , 0.29540935,\n",
       "       0.17819822, 0.05908529, 0.49207908, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1241, 0.2500, 0.7787, 0.0909, 0.1908, 0.1361, 0.3316, 0.5104, 0.2696,\n",
       "        0.1001, 0.5931, 0.0812, 0.4139, 0.3334, 0.4853, 0.2987],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prob = torch.sigmoid(mask_logits)\n",
    "(mask_prob * context_mask).sum(-1) / context_mask.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9998e-01, 1.3412e-02, 2.1168e-05, 7.2758e-04, 9.5831e-01, 2.8712e-06,\n",
       "         1.9530e-03, 6.8251e-04, 9.6814e-01, 7.6582e-04, 2.2164e-06, 1.7009e-02,\n",
       "         2.4596e-09, 1.4519e-04, 3.0463e-06, 7.9092e-04, 4.0336e-06, 5.2874e-05,\n",
       "         1.4755e-07, 5.3417e-09, 1.0859e-07, 8.2496e-07, 1.0534e-05, 2.1604e-06,\n",
       "         6.6980e-10, 1.8266e-01, 5.4030e-07, 4.0081e-02, 3.5185e-04, 3.1933e-01,\n",
       "         3.2836e-09, 1.5197e-06, 8.2054e-01, 8.0839e-01, 5.4567e-01, 4.8829e-01,\n",
       "         1.0000e+00, 4.3639e-05, 3.5097e-07, 3.8482e-09, 1.9672e-04, 1.1242e-07,\n",
       "         2.7982e-13, 5.4683e-09, 4.5730e-01, 9.5505e-01, 6.7815e-04, 7.4368e-02,\n",
       "         9.9924e-01, 6.6332e-03, 1.0508e-08, 1.8774e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128000, 128006,   9125, 128007,    271,   2675,    527,    264,   6369,\n",
       "          6465,    369,  27065,   6492,     13,   1472,    649,   1520,   3932,\n",
       "           449,    872,   4860,   4669,  64694,  14847,    315,  27592,  45450,\n",
       "            11,    477,  85165,  24093,     13, 128009, 128006,    882, 128007,\n",
       "           271,   2028,   5818,    574,    279,   1888,   5818,    358,    617,\n",
       "          3596,   3970,      0,   1063,  16451,   1051,  27873,     11,    719,\n",
       "         15718,    574,   2294,     13, 128009, 128006,  78191, 128007,    271],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs['input_ids'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ĊĊ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.6432 0.8566 0.5179\n",
      " 0.2417 0.     0.1211 0.3355 0.618  0.5345 0.1401 0.3401 0.4729 0.3531\n",
      " 0.661  0.7049 0.0297 0.1724 0.9905 1.     0.1606 0.1107 0.2363 0.2891\n",
      " 0.116  0.0777 0.     0.     0.     0.     0.     0.     0.     0.    ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.8527, 0.1770, 0.1719, 0.1660, 0.1613, 0.1549, 0.1581, 0.1622, 0.1666,\n",
       "        0.1635, 0.1568, 0.1589, 0.1618, 0.1634, 0.1668, 0.1647, 0.1546, 0.1576,\n",
       "        0.1788, 0.1779, 0.1592, 0.1581, 0.1607, 0.1619, 0.1586, 0.1583, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sigmoid(mask_logits) * context_mask)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4822, 0.4821, 0.4816,  ..., 0.4920, 0.4874, 0.4901],\n",
       "        [0.4843, 0.4851, 0.4855,  ..., 0.4941, 0.4861, 0.4891],\n",
       "        [0.4785, 0.4805, 0.4805,  ..., 0.4918, 0.4823, 0.4864],\n",
       "        ...,\n",
       "        [0.4753, 0.4758, 0.4761,  ..., 0.4847, 0.4761, 0.4802],\n",
       "        [0.4876, 0.4883, 0.4882,  ..., 0.4887, 0.4880, 0.4943],\n",
       "        [0.4843, 0.4851, 0.4852,  ..., 0.4946, 0.4853, 0.4947]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(mask_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskGeneratingModel(\n",
       "  (explain_map): MLP(\n",
       "    (input_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (attention_layers): ModuleList(\n",
       "      (0-1): 2 x MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): PReLU(num_parameters=1)\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (output_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_header_id|>\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(tokens[35])\n",
    "print(expl[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a chatbot for sentimate analysis. You can help users with their questions via concise responses of POSITIVE, or NEGATIVE.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "This movie was the best movie I have ever seen! some scenes were ridiculous, but acting was great.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = \"This movie was the best movie I have ever seen! some scenes were ridiculous, but acting was great.\"\n",
    "# texts = \"I really didn't like this movie. Some of the actors were good, but overall the movie was boring.\"\n",
    "# texts = \"I hate that I love you.\"\n",
    "# texts = \"I don't like this movie.\"\n",
    "# texts = \"I really love this film.\"\n",
    "messages_lambda = lambda texts: [\n",
    "    {\"role\": \"system\", \"content\": \"You are a chatbot for sentimate analysis. You can help users with their questions via concise responses of POSITIVE, or NEGATIVE.\"},\n",
    "    # {\"role\": \"system\", \"content\": \"You are a chatbot for sentimate analysis.\"},\n",
    "    {\"role\": \"user\", \"content\": texts},\n",
    "]\n",
    "messages = messages_lambda(texts)\n",
    "messages_with_template_applied = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "print(messages_with_template_applied)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
