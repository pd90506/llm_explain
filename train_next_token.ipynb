{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring environment parameters\n",
    "import os\n",
    "import json \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='log/app.log',            # Specify the log file name\n",
    "    level=logging.DEBUG,           # Set the log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Set the log format\n",
    ")\n",
    "\n",
    "# Load the environment configuration JSON data\n",
    "json_path = 'env_config.json'\n",
    "with open(json_path, 'r') as file:\n",
    "    env_config = json.load(file)\n",
    "\n",
    "hf_home = env_config['HF_HOME']\n",
    "# Set the HF_HOME environment variable\n",
    "os.environ['HF_HOME'] = hf_home\n",
    "# Set the access token to huggingface hub\n",
    "access_token = env_config['access_token']\n",
    "os.environ['HUGGINGFACE_HUB_TOKEN'] = access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/crc.nd.edu/user/d/dpan/wd/llm_explain/llmexp/next_token_model.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Loading necessary packages\n",
    "import transformers \n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, LlamaForTokenClassification #, LlamaRotaryEmbedding\n",
    "# from transformers import LlamaTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from llmexp.helper import DataHelper\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# TODO 注意load正确的模型\n",
    "from llmexp.next_token_model import MaskGenModelForNextToken, Environment\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ds = load_dataset(\"imdb\")\n",
    "# ds = load_dataset(\"rajpurkar/squad\")\n",
    "ds = load_dataset(\"stanfordnlp/sst2\")\n",
    "train_ds = ds['train']\n",
    "test_ds = ds['test']\n",
    "# test_ds = ds['validation']\n",
    "\n",
    "llm_exp_helper = DataHelper(tokenizer)\n",
    "# collate_fn = llm_exp_helper.get_collate_fun('imdb')\n",
    "collate_fn = llm_exp_helper.get_collate_fun('sst2')\n",
    "# collate_fn = llm_exp_helper.get_collate_fun('squad')\n",
    "\n",
    "# Define batch size here!\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129274ecf5d7432b9dc62928324ab3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure and load model\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B\"  # non-instruct version\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # device_map=\"auto\",\n",
    "    device_map=device,\n",
    "    token=access_token,\n",
    ")\n",
    "\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure mask model and  Training parameters\n",
    "embedding_layer = model.get_input_embeddings()\n",
    "mask_gen_model = MaskGenModelForNextToken(hidden_size=4096, embedding_layer=embedding_layer).to(torch.bfloat16)\n",
    "mask_gen_model.to(device)\n",
    "\n",
    "environment = Environment(model)\n",
    "\n",
    "# Set pad_token_id if it is not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "params_to_update = [param for name, param in mask_gen_model.named_parameters() if \"output_layer.weight\" not in name]\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'autoregressive_predictor.reduce_map.0.weight' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.0.bias' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.2.weight' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.2.bias' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.4.weight' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.4.bias' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.6.weight' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.reduce_map.6.bias' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.linear.weight' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.linear.bias' is in the optimizer.\n",
      "Parameter 'autoregressive_predictor.output_layer.weight' is NOT in the optimizer.\n",
      "Parameter 'autoregressive_predictor.norm.weight' is in the optimizer.\n",
      "Parameter 'value_map.weight' is in the optimizer.\n",
      "Parameter 'value_map.bias' is in the optimizer.\n"
     ]
    }
   ],
   "source": [
    "# 创建一个集合，用于存储所有注册在优化器中的参数 ID\n",
    "optimizer_params_ids = set(id(p) for group in optimizer.param_groups for p in group['params'])\n",
    "\n",
    "# 遍历模型的所有参数，并检查它们是否在优化器中\n",
    "for name, param in mask_gen_model.named_parameters():\n",
    "    if id(param) in optimizer_params_ids:\n",
    "        print(f\"Parameter '{name}' is in the optimizer.\")\n",
    "    else:\n",
    "        print(f\"Parameter '{name}' is NOT in the optimizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1: Loss = 12.5887, Advantage = 0.8426, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7803, mask_loss = 0.0000, :   0%|          | 1/4210 [01:22<96:07:23, 82.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2: Loss = 13.0700, Advantage = -0.1679, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7798, mask_loss = 0.0000, :   0%|          | 2/4210 [01:24<40:52:55, 34.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 3: Loss = 12.9161, Advantage = 0.3482, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7787, mask_loss = 0.0000, :   0%|          | 3/4210 [01:26<23:13:39, 19.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 4: Loss = 14.7738, Advantage = 0.0135, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7799, mask_loss = 0.0000, :   0%|          | 4/4210 [01:27<14:57:12, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 5: Loss = 14.1396, Advantage = -0.2919, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7826, mask_loss = 0.0000, :   0%|          | 5/4210 [01:30<10:26:01,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-3.8116e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-4.1959e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-5.3879e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1215e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 6: Loss = 35.0669, Advantage = -0.3019, Ratio = 1.0000, Entropy = 0.0000, kl_div = 32.1977, mask_loss = 0.0000, :   0%|          | 6/4210 [01:31<7:38:53,  6.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.1309e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-2.3614e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 7: Loss = 13.2668, Advantage = -0.0415, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.8497, mask_loss = 0.0000, :   0%|          | 7/4210 [01:34<5:56:12,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 8: Loss = 13.7325, Advantage = 1.7877, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.8290, mask_loss = 0.0000, :   0%|          | 8/4210 [01:36<4:48:56,  4.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 9: Loss = 12.9491, Advantage = 0.4578, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.8044, mask_loss = 0.0000, :   0%|          | 9/4210 [01:38<4:00:25,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 10: Loss = 15.4988, Advantage = -0.3909, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7952, mask_loss = 0.0000, :   0%|          | 10/4210 [01:40<3:31:35,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.8714e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 11: Loss = 20.1754, Advantage = -3.6724, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7963, mask_loss = 0.0000, :   0%|          | 11/4210 [01:42<3:08:32,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 12: Loss = 14.7922, Advantage = -0.7832, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7856, mask_loss = 0.0000, :   0%|          | 12/4210 [01:43<2:48:41,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 13: Loss = 12.7414, Advantage = 0.7928, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7833, mask_loss = 0.0000, :   0%|          | 13/4210 [01:45<2:35:11,  2.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 14: Loss = 12.3831, Advantage = 0.6883, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7822, mask_loss = 0.0000, :   0%|          | 14/4210 [01:47<2:29:33,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1560e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.7610e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-3.4860e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-4.2807e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-3.9375e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3019e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-6.3849e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 15: Loss = 51.8862, Advantage = -0.0804, Ratio = 1.0000, Entropy = 0.0000, kl_div = 50.4894, mask_loss = 0.0000, :   0%|          | 15/4210 [01:49<2:21:07,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1560e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1560e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-6.5384e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1599e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3129e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.5626e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.4982e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3612e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2001e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 16: Loss = 14.2590, Advantage = -1.1645, Ratio = 1.0000, Entropy = 0.0000, kl_div = 12.0644, mask_loss = 0.0000, :   0%|          | 16/4210 [01:51<2:19:04,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0793e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 17: Loss = 12.7549, Advantage = 0.8542, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.8160, mask_loss = 0.0000, :   0%|          | 17/4210 [01:53<2:21:55,  2.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6698e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 18: Loss = 12.0797, Advantage = 1.8455, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7935, mask_loss = 0.0000, :   0%|          | 18/4210 [01:55<2:20:47,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 19: Loss = 14.6207, Advantage = -0.8855, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7857, mask_loss = 0.0000, :   0%|          | 19/4210 [01:57<2:16:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.4072e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 20: Loss = 15.1684, Advantage = -0.7404, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7943, mask_loss = 0.0000, :   0%|          | 20/4210 [01:59<2:25:52,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 21: Loss = 11.7858, Advantage = 0.9617, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7810, mask_loss = 0.0000, :   0%|          | 21/4210 [02:01<2:22:30,  2.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0310e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 22: Loss = 12.7984, Advantage = 0.2084, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7823, mask_loss = 0.0000, :   1%|          | 22/4210 [02:03<2:19:33,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 23: Loss = 13.4188, Advantage = -0.7316, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7806, mask_loss = 0.0000, :   1%|          | 23/4210 [02:05<2:19:17,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 24: Loss = 13.8429, Advantage = -0.1932, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7786, mask_loss = 0.0000, :   1%|          | 24/4210 [02:07<2:15:03,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3385e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-5.5736e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3385e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3385e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.5832e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3385e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3385e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.4159e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 25: Loss = 39.6739, Advantage = 0.4235, Ratio = 1.0000, Entropy = 0.0000, kl_div = 39.0244, mask_loss = 0.0000, :   1%|          | 25/4210 [02:08<2:07:48,  1.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-7.7695e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.3845e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 26: Loss = 11.9387, Advantage = 1.6933, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7781, mask_loss = 0.0000, :   1%|          | 26/4210 [02:10<2:04:08,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.2110e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 27: Loss = 11.4793, Advantage = 0.9790, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7814, mask_loss = 0.0000, :   1%|          | 27/4210 [02:12<2:09:59,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 28: Loss = 13.8910, Advantage = -0.3278, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7822, mask_loss = 0.0000, :   1%|          | 28/4210 [02:14<2:15:07,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.0826e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 29: Loss = 13.0087, Advantage = -0.1112, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7798, mask_loss = 0.0000, :   1%|          | 29/4210 [02:16<2:11:48,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 30: Loss = 12.9907, Advantage = 0.0069, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7828, mask_loss = 0.0000, :   1%|          | 30/4210 [02:18<2:13:27,  1.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 31: Loss = 12.4542, Advantage = 0.0145, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7787, mask_loss = 0.0000, :   1%|          | 31/4210 [02:20<2:16:30,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.4190e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 32: Loss = 14.6902, Advantage = -0.9374, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7804, mask_loss = 0.0000, :   1%|          | 32/4210 [02:22<2:16:27,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.9083e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 33: Loss = 12.8599, Advantage = -0.2764, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7783, mask_loss = 0.0000, :   1%|          | 33/4210 [02:24<2:19:03,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.3041e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 34: Loss = 12.1272, Advantage = 0.1839, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7786, mask_loss = 0.0000, :   1%|          | 34/4210 [02:26<2:14:31,  1.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1057e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 35: Loss = 11.9851, Advantage = 0.0320, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7744, mask_loss = 0.0000, :   1%|          | 35/4210 [02:27<2:10:52,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 36: Loss = 13.2503, Advantage = -0.3395, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7799, mask_loss = 0.0000, :   1%|          | 36/4210 [02:29<2:12:51,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.5367e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 37: Loss = 12.9828, Advantage = 0.1043, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7795, mask_loss = 0.0000, :   1%|          | 37/4210 [02:31<2:14:01,  1.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 38: Loss = 12.9318, Advantage = 1.6853, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7788, mask_loss = 0.0000, :   1%|          | 38/4210 [02:34<2:18:16,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.7694e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 39: Loss = 13.6107, Advantage = -0.8077, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7765, mask_loss = 0.0000, :   1%|          | 39/4210 [02:35<2:14:20,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 40: Loss = 13.3512, Advantage = -0.8444, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7776, mask_loss = 0.0000, :   1%|          | 40/4210 [02:37<2:17:47,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 41: Loss = 13.1438, Advantage = 0.5027, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7803, mask_loss = 0.0000, :   1%|          | 41/4210 [02:39<2:16:59,  1.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 42: Loss = 11.4805, Advantage = 1.1327, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7749, mask_loss = 0.0000, :   1%|          | 42/4210 [02:41<2:16:20,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 43: Loss = 12.3170, Advantage = 0.3696, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7750, mask_loss = 0.0000, :   1%|          | 43/4210 [02:43<2:15:06,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0451e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.5314e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-3.0738e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.6473e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4180e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 44: Loss = 21.3829, Advantage = -0.1980, Ratio = 1.0000, Entropy = 0.0000, kl_div = 20.1407, mask_loss = 0.0000, :   1%|          | 44/4210 [02:45<2:10:32,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-7.7945e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.9633e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 45: Loss = 18.5555, Advantage = -1.1353, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7836, mask_loss = 0.0000, :   1%|          | 45/4210 [02:47<2:18:23,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 46: Loss = 18.1883, Advantage = -2.0406, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7847, mask_loss = 0.0000, :   1%|          | 46/4210 [02:49<2:17:24,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 47: Loss = 13.7898, Advantage = 2.7368, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7885, mask_loss = 0.0000, :   1%|          | 47/4210 [02:51<2:18:10,  1.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 48: Loss = 12.9107, Advantage = 1.4751, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7875, mask_loss = 0.0000, :   1%|          | 48/4210 [02:53<2:17:44,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.7813e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 49: Loss = 14.5409, Advantage = -0.4541, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7820, mask_loss = 0.0000, :   1%|          | 49/4210 [02:55<2:16:52,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 50: Loss = 14.5564, Advantage = -1.1726, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7829, mask_loss = 0.0000, :   1%|          | 50/4210 [02:57<2:12:20,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1387e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 51: Loss = 11.5403, Advantage = 1.7733, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7807, mask_loss = 0.0000, :   1%|          | 51/4210 [02:59<2:13:06,  1.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 52: Loss = 14.0352, Advantage = -0.5177, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7847, mask_loss = 0.0000, :   1%|          | 52/4210 [03:01<2:13:39,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0039e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 53: Loss = 12.5853, Advantage = -0.4997, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7784, mask_loss = 0.0000, :   1%|▏         | 53/4210 [03:03<2:09:26,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.1738e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 54: Loss = 14.0388, Advantage = -0.6678, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7810, mask_loss = 0.0000, :   1%|▏         | 54/4210 [03:04<2:10:56,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0173e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 55: Loss = 12.3322, Advantage = 0.0979, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7771, mask_loss = 0.0000, :   1%|▏         | 55/4210 [03:06<2:08:57,  1.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0596e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 56: Loss = 19.8826, Advantage = 2.8174, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7877, mask_loss = 0.0000, :   1%|▏         | 56/4210 [03:09<2:17:07,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 57: Loss = 19.9133, Advantage = -2.6078, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7812, mask_loss = 0.0000, :   1%|▏         | 57/4210 [03:11<2:19:29,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-9.1920e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 58: Loss = 15.5102, Advantage = -1.8458, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7863, mask_loss = 0.0000, :   1%|▏         | 58/4210 [03:12<2:14:35,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-1.0899e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 59: Loss = 12.7852, Advantage = -0.3945, Ratio = 1.0000, Entropy = 0.0000, kl_div = 11.7775, mask_loss = 0.0000, :   1%|▏         | 59/4210 [03:15<2:21:02,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "logprob tensor(-8.4771e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "assert mask_gen_model.autoregressive_predictor.output_layer.weight is embedding_layer.weight\n",
    "\n",
    "mask_gen_model.train()\n",
    "for epoch in range(1):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for idx, data in enumerate(pbar):\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        context_mask = data['context_mask'].to(device)\n",
    "        # get generated texts\n",
    "        gen_outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=3,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "\n",
    "        # gen_tokens = gen_outputs.sequences\n",
    "        pad_length = 1 # single token generation\n",
    "        gen_tokens = gen_outputs.sequences[:, :input_ids.size(1) + pad_length]\n",
    "        # get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "        gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "\n",
    "        context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "        loss_dict = mask_gen_model.train_one_batch(model, gen_tokens, gen_attention_mask, context_mask, optimizer,\n",
    "                                                   environment=environment, num_steps=10, alpha=0.1)\n",
    "\n",
    "\n",
    "        log = f\"Epoch {epoch+1}, Step {idx+1}: Loss = {loss_dict['loss']:.4f}, \" \\\n",
    "              f\"Advantage = {loss_dict['advantages']:.4f}, \" \\\n",
    "              f\"Ratio = {loss_dict['ratio']:.4f}, \" \\\n",
    "              f\"Entropy = {loss_dict['entropy']:.4f}, \" \\\n",
    "              f\"kl_div = {loss_dict['kl_div']:.4f}, \" \\\n",
    "              f\"mask_loss = {loss_dict['mask_loss']:.4f}, \" \\\n",
    "            #    f\"Actor Loss = {loss_dict['actor_loss']:.4f}, \" \\\n",
    "            #    f\"Critic Loss = {loss_dict['critic_loss']:.4f}, \" \\\n",
    "               \n",
    "            #    f\"Returns = {loss_dict['returns']:.4f}, \" \\\n",
    "            #    f\"Value = {loss_dict['value']:.4f}, \" \\\n",
    "            #     f\"mask_loss = {loss_dict['mask_loss']:.4f}\" \\\n",
    "            #     f\"std_loss = {loss_dict['std_loss']:.4f}\" \\\n",
    "            #    f\"Cont_loss = {loss_dict['contrast_loss']:.4f}, \"  \\\n",
    "               \n",
    "        pbar.set_description(log)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print()\n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            torch.save(mask_gen_model.state_dict(), f'saved_model/imdb_next_token_model_{epoch}_{idx}.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 84])\n",
      "torch.Size([16, 83])\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a chatbot for sentiment analysis. You can help users with their questions via single word responses of POSITIVE or NEGATIVE.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "most of the information has already appeared in one forum or another and, no matter how broomfield dresses it up, it tends to speculation, conspiracy theories or, at best, circumstantial evidence. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a chatbot for sentiment analysis. You can help users with their questions via single word responses of POSITIVE or NEGATIVE.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "most of the information has already appeared in one forum or another and, no matter how broomfield dresses it up, it tends to speculation, conspiracy theories or, at best, circumstantial evidence. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "NEG\n"
     ]
    }
   ],
   "source": [
    "print(gen_tokens.shape)\n",
    "print(input_ids.shape)\n",
    "print(tokenizer.decode(input_ids[0]))\n",
    "print(tokenizer.decode(gen_tokens[0]))\n",
    "\n",
    "iterator = iter(range(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a chatbot for sentiment analysis. You can help users with their questions via single word responses of POSITIVE or NEGATIVE.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "most of the information has already appeared in one forum or another and, no matter how broomfield dresses it up, it tends to speculation, conspiracy theories or, at best, circumstantial evidence. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a chatbot for sentiment analysis. You can help users with their questions via single word responses of POSITIVE or NEGATIVE.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "most of the information has already appeared in one forum or another and, no matter how broomfield dresses it up, it tends to speculation, conspiracy theories or, at best, circumstantial evidence. <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "NEG\n"
     ]
    }
   ],
   "source": [
    "idx = next(iterator)\n",
    "print(tokenizer.decode(input_ids[idx]))\n",
    "print(tokenizer.decode(gen_tokens[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "\n",
    "# mask_gen_model.load_state_dict(torch.load('saved_model/imdb_mask_gen_model_0_100.pth',map_location=device))\n",
    "\n",
    "mask_gen_model.eval()\n",
    "\n",
    "# test_dataloader = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "# test_inputs = next(iter(test_dataloader)).to(device)\n",
    "# test_inputs = next(iter(train_dataloader)).to(device)\n",
    "\n",
    "# tokens = tokenizer.convert_ids_to_tokens(test_inputs['input_ids'][idx])\n",
    "\n",
    "\n",
    "\n",
    "data_dict = { # sentence, text\n",
    "    'sentence': [\"I absolutely love this product! It exceeded all my expectations.\", \n",
    "             \"The movie was fantastic, and the acting was top-notch.\",\n",
    "             \"This restaurant offers great service and delicious food. Highly recommend!\",\n",
    "             \"The product works as advertised, nothing more, nothing less.\",\n",
    "             \"The event was well-organized, but it didn’t leave a lasting impression.\",\n",
    "             \"t’s an average phone, nothing special but it does the job.\",\n",
    "             \"I’m really disappointed with this purchase. It broke within a week.\",\n",
    "             \"The movie was too long and boring, I wouldn’t recommend it.\",\n",
    "             \"Terrible customer service, I won’t be coming back to this place.\"],\n",
    "    'label': [1, 1, 1, 0, 0, 0, -1, -1, -1]\n",
    "}\n",
    "manual_test_data = Dataset.from_dict(data_dict)\n",
    "\n",
    "manual_test_dataloader = DataLoader(manual_test_data, batch_size=9, collate_fn=collate_fn, shuffle=False)\n",
    "#\n",
    "test_inputs = next(iter(manual_test_dataloader)).to(device)\n",
    "\n",
    "\n",
    "# generate the answer for the test inputs\n",
    "gen_outputs = model.generate(\n",
    "            input_ids=test_inputs['input_ids'],\n",
    "            attention_mask=test_inputs['attention_mask'],\n",
    "            max_new_tokens=128,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "        )\n",
    "input_ids = test_inputs['input_ids']\n",
    "attention_mask = test_inputs['attention_mask']\n",
    "context_mask = test_inputs['context_mask']\n",
    "gen_tokens = gen_outputs.sequences\n",
    "# pad_length = gen_tokens.size(1) - input_ids.size(1)\n",
    "# # get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "# gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "# context_mask = F.pad(test_inputs['context_mask'], (0, pad_length), mode='constant', value=0)\n",
    "# # (gen_tokens != pad_token_id).long() is the tokens mask, 1 for real tokens and 0 for padding tokens\n",
    "# unpaded_token_mask = (gen_tokens != tokenizer.pad_token_id).long()\n",
    "# unpaded_token_mask[:, :-pad_length] = 1\n",
    "# gen_attention_mask = gen_attention_mask * unpaded_token_mask\n",
    "\n",
    "# response_mask = gen_attention_mask.clone()\n",
    "# response_mask[:, :-pad_length] = 0 # TODO: 有问题. 有问题吗？\n",
    "\n",
    "pad_length = 1 # single token generation\n",
    "gen_tokens = gen_outputs.sequences[:, :input_ids.size(1) + pad_length]\n",
    "# get the attention mask for the generated tokens, and also mask the padding tokens\n",
    "gen_attention_mask = F.pad(attention_mask, (0, pad_length), mode='constant', value=1)\n",
    "\n",
    "context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "# context_mask = F.pad(context_mask, (0, pad_length), mode='constant', value=0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # prompt_outputs = model(input_ids=test_inputs['input_ids'], attention_mask=test_inputs['attention_mask'], output_hidden_states=True, return_dict=True)\n",
    "#     prompt_outputs = model(input_ids=gen_tokens, attention_mask=gen_attention_mask, output_hidden_states=True, return_dict=True)\n",
    "\n",
    "#     last_hidden_state = prompt_outputs.hidden_states[-1].float()\n",
    "#     mask_logits = mask_gen_model(last_hidden_state)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    state = gen_tokens, gen_attention_mask, context_mask\n",
    "    dist, value, _ = mask_gen_model.get_dist_critic(model, state)\n",
    "\n",
    "mask_logits = dist.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 59])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/884549.1.gpu/ipykernel_827534/1602045861.py:26: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_non_zero_elements = (non_zero_elements - min_val) / (max_val - min_val)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, 8)\n",
    "# idx = 0\n",
    "test_ids = gen_tokens[idx]\n",
    "test_mask = gen_attention_mask[idx]\n",
    "test_mask_prob = torch.sigmoid(mask_logits[idx])\n",
    "# inverse TODO\n",
    "# test_mask_prob = 1 - test_mask_prob\n",
    "test_context_mask = context_mask[idx]\n",
    "\n",
    "test_tokens = tokenizer.convert_ids_to_tokens(test_ids)\n",
    "scores = test_mask_prob * test_context_mask\n",
    "# scores = test_mask_prob\n",
    "\n",
    "def normalize_except_zeros(array):\n",
    "    # Create a mask to identify non-zero elements\n",
    "    mask = (array > 0)\n",
    "    \n",
    "    # Extract non-zero elements\n",
    "    non_zero_elements = array[mask]\n",
    "    \n",
    "    # Normalize non-zero elements\n",
    "    min_val = np.min(non_zero_elements)\n",
    "    max_val = np.max(non_zero_elements)\n",
    "\n",
    "    normalized_non_zero_elements = (non_zero_elements - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Create a copy of the original array to preserve zero values\n",
    "    normalized_array = np.copy(array)\n",
    "    \n",
    "    # Assign normalized values back to the corresponding positions\n",
    "    normalized_array[mask] = normalized_non_zero_elements\n",
    "    \n",
    "    return normalized_array\n",
    "scores = normalize_except_zeros(scores.detach().cpu().numpy())\n",
    "\n",
    "# # remove special tokens\n",
    "filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) if token not in tokenizer.all_special_tokens]\n",
    "# filtered_token_scores = [(token, score) for token, score in zip(test_tokens, scores) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: system, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: You, Score: 0.0\n",
      "Token: Ġare, Score: 0.0\n",
      "Token: Ġa, Score: 0.0\n",
      "Token: Ġchat, Score: 0.0\n",
      "Token: bot, Score: 0.0\n",
      "Token: Ġfor, Score: 0.0\n",
      "Token: Ġsentiment, Score: 0.0\n",
      "Token: Ġanalysis, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: ĠYou, Score: 0.0\n",
      "Token: Ġcan, Score: 0.0\n",
      "Token: Ġhelp, Score: 0.0\n",
      "Token: Ġusers, Score: 0.0\n",
      "Token: Ġwith, Score: 0.0\n",
      "Token: Ġtheir, Score: 0.0\n",
      "Token: Ġquestions, Score: 0.0\n",
      "Token: Ġvia, Score: 0.0\n",
      "Token: Ġsingle, Score: 0.0\n",
      "Token: Ġword, Score: 0.0\n",
      "Token: Ġresponses, Score: 0.0\n",
      "Token: Ġof, Score: 0.0\n",
      "Token: ĠPOS, Score: 0.0\n",
      "Token: ITIVE, Score: 0.0\n",
      "Token: Ġor, Score: 0.0\n",
      "Token: ĠNEG, Score: 0.0\n",
      "Token: ATIVE, Score: 0.0\n",
      "Token: ., Score: 0.0\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: user, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: This, Score: nan\n",
      "Token: Ġrestaurant, Score: nan\n",
      "Token: Ġoffers, Score: nan\n",
      "Token: Ġgreat, Score: nan\n",
      "Token: Ġservice, Score: nan\n",
      "Token: Ġand, Score: nan\n",
      "Token: Ġdelicious, Score: nan\n",
      "Token: Ġfood, Score: nan\n",
      "Token: ., Score: nan\n",
      "Token: ĠHighly, Score: nan\n",
      "Token: Ġrecommend, Score: nan\n",
      "Token: !, Score: nan\n",
      "Token: <|start_header_id|>, Score: 0.0\n",
      "Token: assistant, Score: 0.0\n",
      "Token: <|end_header_id|>, Score: 0.0\n",
      "Token: ĊĊ, Score: 0.0\n",
      "Token: POS, Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "for token, score in filtered_token_scores:\n",
    "    print(f\"Token: {token}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m highlighted_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token, score \u001b[38;5;129;01min\u001b[39;00m merged_tokens_scores:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# 动态设置背景颜色：score为0时为白色，score为1时为绿色\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     red \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     green \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     77\u001b[0m     blue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m score) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_token(token):\n",
    "    # 移除所有普通的特殊字符，比如 'Ġ' 和 'Ċ'\n",
    "    return token.replace(\"Ġ\", \"\").replace(\"Ċ\", \"\")\n",
    "\n",
    "merged_tokens_scores = []\n",
    "current_token = \"\"\n",
    "current_score = 0\n",
    "count = 0\n",
    "\n",
    "def is_special_token(token):\n",
    "    # 判断是否是特殊的独立 token，例如 '<|start_header_id|>' 这样的 token\n",
    "    return token.startswith(\"<|\") and token.endswith(\"|>\")\n",
    "\n",
    "# 用于合并 token 和 score，取平均值\n",
    "for token, score in filtered_token_scores:\n",
    "    # 检查是否是特殊 token\n",
    "    if is_special_token(token):\n",
    "        # 如果当前有累积的 token，先把它们加入结果\n",
    "        if current_token:\n",
    "            # 确保分数归一化在 [0, 1] 之间\n",
    "            average_score = min(current_score / count, 1.0)\n",
    "            merged_tokens_scores.append((current_token, average_score))\n",
    "            current_token = \"\"\n",
    "            current_score = 0\n",
    "            count = 0\n",
    "\n",
    "        # 特殊 token 直接加入，不合并\n",
    "        merged_tokens_scores.append((token, score))\n",
    "        continue\n",
    "\n",
    "    # 清理 token 中的特殊字符\n",
    "    cleaned_token = clean_token(token)\n",
    "\n",
    "    # 忽略清理后的空 token\n",
    "    if not cleaned_token:\n",
    "        continue\n",
    "\n",
    "    # 判断是否是新单词的开始（以 'Ġ' 或 'Ċ' 开头的通常是新词）\n",
    "    if token.startswith(\"Ġ\") or token.startswith(\"Ċ\"):\n",
    "        if current_token:\n",
    "            # 确保分数归一化在 [0, 1] 之间\n",
    "            average_score = min(current_score / count, 1.0)\n",
    "            merged_tokens_scores.append((current_token, average_score))\n",
    "        \n",
    "        # 初始化新的 token 和 score\n",
    "        current_token = cleaned_token\n",
    "        current_score = score\n",
    "        count = 1\n",
    "    else:\n",
    "        # 如果是子词，则继续合并\n",
    "        current_token += cleaned_token\n",
    "        current_score += score\n",
    "        count += 1\n",
    "\n",
    "# 处理最后一个 token\n",
    "if current_token:\n",
    "    # 确保分数归一化在 [0, 1] 之间\n",
    "    average_score = min(current_score / count, 1.0)\n",
    "    merged_tokens_scores.append((current_token, average_score))\n",
    "\n",
    "# # 输出结果\n",
    "# for token, score in merged_tokens_scores:\n",
    "#     print(f\"Token: {token}, Score: {score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 根据分数高亮文本（示例中使用HTML标签）\n",
    "highlighted_text = \"\"\n",
    "for token, score in merged_tokens_scores:\n",
    "    # 动态设置背景颜色：score为0时为白色，score为1时为绿色\n",
    "    red = int((1 - score) * 255)\n",
    "    green = 255\n",
    "    blue = int((1 - score) * 255)\n",
    "    color = f'rgb({red}, {green}, {blue})'\n",
    "    highlighted_text += f'<span style=\"background-color: {color}; color: black;\">{token}</span> '\n",
    "\n",
    "# 打印高亮后的文本\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(highlighted_text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9033, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_mask_prob * test_context_mask).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs.keys()\n",
    "\n",
    "collate_fn()\n",
    "\n",
    "tokenizer(\"this is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = ds['train'].select(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data_dict = {\n",
    "    'text': [\"This is the first example.\", \"This is the second example.\"],\n",
    "    'label': [0, 1]\n",
    "}\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
